2024-08-17 17:07:10,624:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 17:07:10,624:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 17:07:10,624:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 17:07:10,624:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 17:27:05,688:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 17:27:05,689:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 17:27:05,689:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 17:27:05,689:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 19:42:45,966:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 19:42:45,966:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 19:42:45,966:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 19:42:45,966:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 19:49:21,386:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 19:49:21,386:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 19:49:21,386:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 19:49:21,386:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 20:16:54,426:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 20:16:54,426:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 20:16:54,426:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 20:16:54,426:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 20:25:09,339:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 20:25:09,340:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 20:25:09,340:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 20:25:09,340:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 20:27:44,141:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 20:27:44,141:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 20:27:44,141:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 20:27:44,141:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 22:31:50,031:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 22:31:50,032:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 22:31:50,032:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 22:31:50,032:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:09:35,477:INFO:PyCaret ClassificationExperiment
2024-08-17 23:09:35,477:INFO:Logging name: codepro_model_exp01
2024-08-17 23:09:35,477:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-08-17 23:09:35,477:INFO:version 3.3.2
2024-08-17 23:09:35,477:INFO:Initializing setup()
2024-08-17 23:09:35,478:INFO:self.USI: ed60
2024-08-17 23:09:35,478:INFO:self._variable_keys: {'log_plots_param', 'fold_shuffle_param', 'data', 'html_param', '_available_plots', 'y_test', 'is_multiclass', 'USI', 'logging_param', 'target_param', 'n_jobs_param', '_ml_usecase', 'X_test', 'gpu_param', 'y', 'memory', 'seed', 'X', 'pipeline', 'y_train', 'fix_imbalance', 'gpu_n_jobs_param', 'fold_generator', 'X_train', 'exp_id', 'fold_groups_param', 'exp_name_log', 'idx'}
2024-08-17 23:09:35,478:INFO:Checking environment
2024-08-17 23:09:35,478:INFO:python_version: 3.10.9
2024-08-17 23:09:35,478:INFO:python_build: ('main', 'Mar  1 2023 12:33:47')
2024-08-17 23:09:35,478:INFO:machine: x86_64
2024-08-17 23:09:35,479:INFO:platform: macOS-10.16-x86_64-i386-64bit
2024-08-17 23:09:35,479:INFO:Memory: svmem(total=17179869184, available=5972967424, percent=65.2, used=10006364160, free=38248448, active=5978103808, inactive=5919916032, wired=4028260352)
2024-08-17 23:09:35,479:INFO:Physical Core: 6
2024-08-17 23:09:35,479:INFO:Logical Core: 12
2024-08-17 23:09:35,479:INFO:Checking libraries
2024-08-17 23:09:35,479:INFO:System:
2024-08-17 23:09:35,479:INFO:    python: 3.10.9 (main, Mar  1 2023, 12:33:47) [Clang 14.0.6 ]
2024-08-17 23:09:35,479:INFO:executable: /Users/I500955/anaconda3/bin/python
2024-08-17 23:09:35,479:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2024-08-17 23:09:35,479:INFO:PyCaret required dependencies:
2024-08-17 23:09:35,482:INFO:                 pip: 22.3.1
2024-08-17 23:09:35,482:INFO:          setuptools: 65.6.3
2024-08-17 23:09:35,483:INFO:             pycaret: 3.3.2
2024-08-17 23:09:35,483:INFO:             IPython: 8.10.0
2024-08-17 23:09:35,483:INFO:          ipywidgets: 7.6.5
2024-08-17 23:09:35,483:INFO:                tqdm: 4.64.1
2024-08-17 23:09:35,483:INFO:               numpy: 1.23.5
2024-08-17 23:09:35,483:INFO:              pandas: 2.2.2
2024-08-17 23:09:35,483:INFO:              jinja2: 3.1.2
2024-08-17 23:09:35,483:INFO:               scipy: 1.10.0
2024-08-17 23:09:35,483:INFO:              joblib: 1.3.2
2024-08-17 23:09:35,483:INFO:             sklearn: 1.4.2
2024-08-17 23:09:35,483:INFO:                pyod: 2.0.1
2024-08-17 23:09:35,483:INFO:            imblearn: 0.12.3
2024-08-17 23:09:35,483:INFO:   category_encoders: 2.6.3
2024-08-17 23:09:35,483:INFO:            lightgbm: 4.5.0
2024-08-17 23:09:35,483:INFO:               numba: 0.56.4
2024-08-17 23:09:35,483:INFO:            requests: 2.28.1
2024-08-17 23:09:35,483:INFO:          matplotlib: 3.7.0
2024-08-17 23:09:35,483:INFO:          scikitplot: 0.3.7
2024-08-17 23:09:35,483:INFO:         yellowbrick: 1.5
2024-08-17 23:09:35,483:INFO:              plotly: 5.23.0
2024-08-17 23:09:35,483:INFO:    plotly-resampler: Not installed
2024-08-17 23:09:35,483:INFO:             kaleido: 0.2.1
2024-08-17 23:09:35,483:INFO:           schemdraw: 0.15
2024-08-17 23:09:35,483:INFO:         statsmodels: 0.13.5
2024-08-17 23:09:35,483:INFO:              sktime: 0.26.0
2024-08-17 23:09:35,484:INFO:               tbats: 1.1.3
2024-08-17 23:09:35,484:INFO:            pmdarima: 2.0.4
2024-08-17 23:09:35,484:INFO:              psutil: 5.9.0
2024-08-17 23:09:35,484:INFO:          markupsafe: 2.1.1
2024-08-17 23:09:35,484:INFO:             pickle5: Not installed
2024-08-17 23:09:35,484:INFO:         cloudpickle: 3.0.0
2024-08-17 23:09:35,484:INFO:         deprecation: 2.1.0
2024-08-17 23:09:35,484:INFO:              xxhash: 3.5.0
2024-08-17 23:09:35,484:INFO:           wurlitzer: 3.0.2
2024-08-17 23:09:35,484:INFO:PyCaret optional dependencies:
2024-08-17 23:09:35,514:INFO:                shap: Not installed
2024-08-17 23:09:35,514:INFO:           interpret: Not installed
2024-08-17 23:09:35,514:INFO:                umap: Not installed
2024-08-17 23:09:35,514:INFO:     ydata_profiling: 4.9.0
2024-08-17 23:09:35,514:INFO:  explainerdashboard: Not installed
2024-08-17 23:09:35,515:INFO:             autoviz: Not installed
2024-08-17 23:09:35,515:INFO:           fairlearn: Not installed
2024-08-17 23:09:35,515:INFO:          deepchecks: Not installed
2024-08-17 23:09:35,515:INFO:             xgboost: Not installed
2024-08-17 23:09:35,515:INFO:            catboost: Not installed
2024-08-17 23:09:35,515:INFO:              kmodes: Not installed
2024-08-17 23:09:35,515:INFO:             mlxtend: Not installed
2024-08-17 23:09:35,515:INFO:       statsforecast: Not installed
2024-08-17 23:09:35,515:INFO:        tune_sklearn: Not installed
2024-08-17 23:09:35,515:INFO:                 ray: Not installed
2024-08-17 23:09:35,515:INFO:            hyperopt: Not installed
2024-08-17 23:09:35,515:INFO:              optuna: Not installed
2024-08-17 23:09:35,515:INFO:               skopt: 0.10.2
2024-08-17 23:09:35,515:INFO:              mlflow: 2.15.1
2024-08-17 23:09:35,515:INFO:              gradio: Not installed
2024-08-17 23:09:35,515:INFO:             fastapi: Not installed
2024-08-17 23:09:35,515:INFO:             uvicorn: Not installed
2024-08-17 23:09:35,515:INFO:              m2cgen: Not installed
2024-08-17 23:09:35,515:INFO:           evidently: Not installed
2024-08-17 23:09:35,515:INFO:               fugue: Not installed
2024-08-17 23:09:35,515:INFO:           streamlit: Not installed
2024-08-17 23:09:35,515:INFO:             prophet: Not installed
2024-08-17 23:09:35,515:INFO:None
2024-08-17 23:09:35,515:INFO:Set up GPU usage.
2024-08-17 23:09:35,516:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:09:35,516:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2024-08-17 23:09:35,516:INFO:Set up data.
2024-08-17 23:09:35,645:INFO:Set up folding strategy.
2024-08-17 23:09:35,646:INFO:Set up train/test split.
2024-08-17 23:09:35,765:INFO:Set up index.
2024-08-17 23:09:35,774:INFO:Assigning column types.
2024-08-17 23:11:01,108:INFO:PyCaret ClassificationExperiment
2024-08-17 23:11:01,108:INFO:Logging name: codepro_model_exp01
2024-08-17 23:11:01,108:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-08-17 23:11:01,108:INFO:version 3.3.2
2024-08-17 23:11:01,108:INFO:Initializing setup()
2024-08-17 23:11:01,108:INFO:self.USI: e35a
2024-08-17 23:11:01,108:INFO:self._variable_keys: {'log_plots_param', 'fold_shuffle_param', 'data', 'html_param', '_available_plots', 'y_test', 'is_multiclass', 'USI', 'logging_param', 'target_param', 'n_jobs_param', '_ml_usecase', 'X_test', 'gpu_param', 'y', 'memory', 'seed', 'X', 'pipeline', 'y_train', 'fix_imbalance', 'gpu_n_jobs_param', 'fold_generator', 'X_train', 'exp_id', 'fold_groups_param', 'exp_name_log', 'idx'}
2024-08-17 23:11:01,108:INFO:Checking environment
2024-08-17 23:11:01,108:INFO:python_version: 3.10.9
2024-08-17 23:11:01,108:INFO:python_build: ('main', 'Mar  1 2023 12:33:47')
2024-08-17 23:11:01,108:INFO:machine: x86_64
2024-08-17 23:11:01,108:INFO:platform: macOS-10.16-x86_64-i386-64bit
2024-08-17 23:11:01,108:INFO:Memory: svmem(total=17179869184, available=6084988928, percent=64.6, used=9878081536, free=232898560, active=5855059968, inactive=5849591808, wired=4023021568)
2024-08-17 23:11:01,108:INFO:Physical Core: 6
2024-08-17 23:11:01,108:INFO:Logical Core: 12
2024-08-17 23:11:01,109:INFO:Checking libraries
2024-08-17 23:11:01,109:INFO:System:
2024-08-17 23:11:01,109:INFO:    python: 3.10.9 (main, Mar  1 2023, 12:33:47) [Clang 14.0.6 ]
2024-08-17 23:11:01,109:INFO:executable: /Users/I500955/anaconda3/bin/python
2024-08-17 23:11:01,109:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2024-08-17 23:11:01,109:INFO:PyCaret required dependencies:
2024-08-17 23:11:01,109:INFO:                 pip: 22.3.1
2024-08-17 23:11:01,109:INFO:          setuptools: 65.6.3
2024-08-17 23:11:01,109:INFO:             pycaret: 3.3.2
2024-08-17 23:11:01,109:INFO:             IPython: 8.10.0
2024-08-17 23:11:01,109:INFO:          ipywidgets: 7.6.5
2024-08-17 23:11:01,109:INFO:                tqdm: 4.64.1
2024-08-17 23:11:01,109:INFO:               numpy: 1.23.5
2024-08-17 23:11:01,109:INFO:              pandas: 2.2.2
2024-08-17 23:11:01,109:INFO:              jinja2: 3.1.2
2024-08-17 23:11:01,109:INFO:               scipy: 1.10.0
2024-08-17 23:11:01,109:INFO:              joblib: 1.3.2
2024-08-17 23:11:01,109:INFO:             sklearn: 1.4.2
2024-08-17 23:11:01,109:INFO:                pyod: 2.0.1
2024-08-17 23:11:01,109:INFO:            imblearn: 0.12.3
2024-08-17 23:11:01,109:INFO:   category_encoders: 2.6.3
2024-08-17 23:11:01,109:INFO:            lightgbm: 4.5.0
2024-08-17 23:11:01,109:INFO:               numba: 0.56.4
2024-08-17 23:11:01,110:INFO:            requests: 2.28.1
2024-08-17 23:11:01,110:INFO:          matplotlib: 3.7.0
2024-08-17 23:11:01,110:INFO:          scikitplot: 0.3.7
2024-08-17 23:11:01,110:INFO:         yellowbrick: 1.5
2024-08-17 23:11:01,110:INFO:              plotly: 5.23.0
2024-08-17 23:11:01,110:INFO:    plotly-resampler: Not installed
2024-08-17 23:11:01,110:INFO:             kaleido: 0.2.1
2024-08-17 23:11:01,110:INFO:           schemdraw: 0.15
2024-08-17 23:11:01,110:INFO:         statsmodels: 0.13.5
2024-08-17 23:11:01,110:INFO:              sktime: 0.26.0
2024-08-17 23:11:01,110:INFO:               tbats: 1.1.3
2024-08-17 23:11:01,110:INFO:            pmdarima: 2.0.4
2024-08-17 23:11:01,110:INFO:              psutil: 5.9.0
2024-08-17 23:11:01,110:INFO:          markupsafe: 2.1.1
2024-08-17 23:11:01,110:INFO:             pickle5: Not installed
2024-08-17 23:11:01,110:INFO:         cloudpickle: 3.0.0
2024-08-17 23:11:01,110:INFO:         deprecation: 2.1.0
2024-08-17 23:11:01,110:INFO:              xxhash: 3.5.0
2024-08-17 23:11:01,110:INFO:           wurlitzer: 3.0.2
2024-08-17 23:11:01,110:INFO:PyCaret optional dependencies:
2024-08-17 23:11:01,110:INFO:                shap: Not installed
2024-08-17 23:11:01,110:INFO:           interpret: Not installed
2024-08-17 23:11:01,110:INFO:                umap: Not installed
2024-08-17 23:11:01,111:INFO:     ydata_profiling: 4.9.0
2024-08-17 23:11:01,111:INFO:  explainerdashboard: Not installed
2024-08-17 23:11:01,111:INFO:             autoviz: Not installed
2024-08-17 23:11:01,111:INFO:           fairlearn: Not installed
2024-08-17 23:11:01,111:INFO:          deepchecks: Not installed
2024-08-17 23:11:01,111:INFO:             xgboost: Not installed
2024-08-17 23:11:01,111:INFO:            catboost: Not installed
2024-08-17 23:11:01,111:INFO:              kmodes: Not installed
2024-08-17 23:11:01,111:INFO:             mlxtend: Not installed
2024-08-17 23:11:01,111:INFO:       statsforecast: Not installed
2024-08-17 23:11:01,111:INFO:        tune_sklearn: Not installed
2024-08-17 23:11:01,111:INFO:                 ray: Not installed
2024-08-17 23:11:01,111:INFO:            hyperopt: Not installed
2024-08-17 23:11:01,111:INFO:              optuna: Not installed
2024-08-17 23:11:01,111:INFO:               skopt: 0.10.2
2024-08-17 23:11:01,111:INFO:              mlflow: 2.15.1
2024-08-17 23:11:01,111:INFO:              gradio: Not installed
2024-08-17 23:11:01,111:INFO:             fastapi: Not installed
2024-08-17 23:11:01,111:INFO:             uvicorn: Not installed
2024-08-17 23:11:01,111:INFO:              m2cgen: Not installed
2024-08-17 23:11:01,111:INFO:           evidently: Not installed
2024-08-17 23:11:01,111:INFO:               fugue: Not installed
2024-08-17 23:11:01,111:INFO:           streamlit: Not installed
2024-08-17 23:11:01,111:INFO:             prophet: Not installed
2024-08-17 23:11:01,111:INFO:None
2024-08-17 23:11:01,112:INFO:Set up GPU usage.
2024-08-17 23:11:01,112:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:11:01,112:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2024-08-17 23:11:01,112:INFO:Set up data.
2024-08-17 23:11:01,215:INFO:Set up folding strategy.
2024-08-17 23:11:01,215:INFO:Set up train/test split.
2024-08-17 23:11:01,326:INFO:Set up index.
2024-08-17 23:11:01,335:INFO:Assigning column types.
2024-08-17 23:11:01,390:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-08-17 23:11:01,390:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:11:01,433:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-17 23:11:01,433:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:11:01,442:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:11:01,443:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-17 23:11:01,443:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:11:01,464:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:11:01,468:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:11:01,476:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-17 23:11:01,530:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-17 23:11:01,531:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:11:01,575:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-17 23:11:01,575:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:11:01,576:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:11:01,576:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-17 23:11:01,576:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:11:01,597:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:11:01,601:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:11:01,602:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-17 23:11:01,606:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-17 23:11:01,606:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-08-17 23:11:01,606:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:11:01,650:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:11:01,650:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:11:01,651:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-17 23:11:01,651:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:11:01,670:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:11:01,674:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:11:01,675:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-17 23:11:01,678:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-17 23:11:01,679:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:11:01,718:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:11:01,718:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:11:01,718:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-17 23:11:01,718:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:11:01,738:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:11:01,743:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:11:01,744:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-17 23:11:01,748:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-17 23:11:01,749:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-08-17 23:11:01,749:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:11:01,792:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:11:01,792:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:11:01,792:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:11:01,814:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:11:01,818:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:11:01,819:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-17 23:11:01,822:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-17 23:11:01,822:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:11:01,862:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:11:01,862:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:11:01,863:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:11:01,882:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:11:01,886:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:11:01,887:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-17 23:11:01,890:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-17 23:11:01,900:INFO:Preparing preprocessing pipeline...
2024-08-17 23:11:01,909:INFO:Set up simple imputation.
2024-08-17 23:11:01,935:INFO:Set up encoding of categorical features.
2024-08-17 23:11:01,936:INFO:Set up removing multicollinearity.
2024-08-17 23:11:01,936:INFO:Set up column transformation.
2024-08-17 23:11:01,936:INFO:Set up feature normalization.
2024-08-17 23:11:07,215:INFO:Finished creating preprocessing pipeline.
2024-08-17 23:11:07,227:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['city_tier',
                                             'total_leads_droppped',
                                             'referred_lead',
                                             'assistance_interaction',
                                             'career_interaction',
                                             'payment_interaction',
                                             'social_interaction',
                                             'syllabus_interaction'],
                                    transformer=SimpleImpute...
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.95))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2024-08-17 23:11:07,227:INFO:Creating final display dataframe.
2024-08-17 23:11:09,241:INFO:Setup _display_container:                     Description                Value
0                    Session id                   42
1                        Target    app_complete_flag
2                   Target type               Binary
3           Original data shape         (227016, 12)
4        Transformed data shape         (227016, 44)
5   Transformed train set shape         (158911, 44)
6    Transformed test set shape          (68105, 44)
7              Numeric features                    8
8          Categorical features                    3
9                    Preprocess                 True
10              Imputation type               simple
11           Numeric imputation                 mean
12       Categorical imputation                 mode
13     Maximum one-hot encoding                   25
14              Encoding method                 None
15     Remove multicollinearity                 True
16  Multicollinearity threshold                 0.95
17               Transformation                 True
18        Transformation method          yeo-johnson
19                    Normalize                 True
20             Normalize method               zscore
21               Fold Generator      StratifiedKFold
22                  Fold Number                   10
23                     CPU Jobs                   -1
24                      Use GPU                 True
25               Log Experiment         MlflowLogger
26              Experiment Name  codepro_model_exp01
27                          USI                 e35a
2024-08-17 23:11:09,255:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:11:09,307:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:11:09,307:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:11:09,308:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:11:09,331:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:11:09,336:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:11:09,336:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-17 23:11:09,340:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-17 23:11:09,340:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:11:09,382:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:11:09,382:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:11:09,383:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:11:09,403:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:11:09,407:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:11:09,408:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-17 23:11:09,411:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-17 23:11:09,412:INFO:Logging experiment in loggers
2024-08-17 23:11:12,128:INFO:SubProcess save_model() called ==================================
2024-08-17 23:11:12,145:INFO:Initializing save_model()
2024-08-17 23:11:12,145:INFO:save_model(model=Pipeline(memory=FastMemory(location=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['city_tier',
                                             'total_leads_droppped',
                                             'referred_lead',
                                             'assistance_interaction',
                                             'career_interaction',
                                             'payment_interaction',
                                             'social_interaction',
                                             'syllabus_interaction'],
                                    transformer=SimpleImpute...
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.95))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), model_name=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmp8tm340im/Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['city_tier',
                                             'total_leads_droppped',
                                             'referred_lead',
                                             'assistance_interaction',
                                             'career_interaction',
                                             'payment_interaction',
                                             'social_interaction',
                                             'syllabus_interaction'],
                                    transformer=SimpleImpute...
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.95))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-08-17 23:11:12,145:INFO:Adding model into prep_pipe
2024-08-17 23:11:12,145:WARNING:Only Model saved as it was a pipeline.
2024-08-17 23:11:12,156:INFO:/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmp8tm340im/Transformation Pipeline.pkl saved in current working directory
2024-08-17 23:11:12,164:INFO:Pipeline(memory=FastMemory(location=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['city_tier',
                                             'total_leads_droppped',
                                             'referred_lead',
                                             'assistance_interaction',
                                             'career_interaction',
                                             'payment_interaction',
                                             'social_interaction',
                                             'syllabus_interaction'],
                                    transformer=SimpleImpute...
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.95))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2024-08-17 23:11:12,164:INFO:save_model() successfully completed......................................
2024-08-17 23:11:12,384:INFO:SubProcess save_model() end ==================================
2024-08-17 23:11:13,615:INFO:setup() successfully completed in 8.31s...............
2024-08-17 23:12:26,835:INFO:Initializing compare_models()
2024-08-17 23:12:26,836:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f922114b4c0>, include=None, fold=5, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f922114b4c0>, 'include': None, 'exclude': ['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada'], 'fold': 5, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada'])
2024-08-17 23:12:26,836:INFO:Checking exceptions
2024-08-17 23:12:26,890:INFO:Preparing display monitor
2024-08-17 23:12:26,955:INFO:Initializing Logistic Regression
2024-08-17 23:12:26,955:INFO:Total runtime is 7.764498392740886e-06 minutes
2024-08-17 23:12:26,960:INFO:SubProcess create_model() called ==================================
2024-08-17 23:12:26,961:INFO:Initializing create_model()
2024-08-17 23:12:26,961:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f922114b4c0>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=42, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f922af50760>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-17 23:12:26,961:INFO:Checking exceptions
2024-08-17 23:12:26,961:INFO:Importing libraries
2024-08-17 23:12:26,961:INFO:Copying training dataset
2024-08-17 23:12:27,053:INFO:Defining folds
2024-08-17 23:12:27,053:INFO:Declaring metric variables
2024-08-17 23:12:27,057:INFO:Importing untrained model
2024-08-17 23:12:27,060:INFO:Logistic Regression Imported successfully
2024-08-17 23:12:27,067:INFO:Starting cross validation
2024-08-17 23:12:27,072:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=42, shuffle=True), n_jobs=1
2024-08-17 23:12:49,576:INFO:Calculating mean and std
2024-08-17 23:12:49,578:INFO:Creating metrics dataframe
2024-08-17 23:12:49,580:INFO:Uploading results into container
2024-08-17 23:12:49,580:INFO:Uploading model into container now
2024-08-17 23:12:49,581:INFO:_master_model_container: 1
2024-08-17 23:12:49,581:INFO:_display_container: 2
2024-08-17 23:12:49,581:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-08-17 23:12:49,581:INFO:create_model() successfully completed......................................
2024-08-17 23:12:49,777:INFO:SubProcess create_model() end ==================================
2024-08-17 23:12:49,777:INFO:Creating metrics dataframe
2024-08-17 23:12:49,786:INFO:Initializing Naive Bayes
2024-08-17 23:12:49,786:INFO:Total runtime is 0.380525016784668 minutes
2024-08-17 23:12:49,791:INFO:SubProcess create_model() called ==================================
2024-08-17 23:12:49,791:INFO:Initializing create_model()
2024-08-17 23:12:49,792:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f922114b4c0>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=42, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f922af50760>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-17 23:12:49,792:INFO:Checking exceptions
2024-08-17 23:12:49,792:INFO:Importing libraries
2024-08-17 23:12:49,792:INFO:Copying training dataset
2024-08-17 23:12:49,880:INFO:Defining folds
2024-08-17 23:12:49,880:INFO:Declaring metric variables
2024-08-17 23:12:49,884:INFO:Importing untrained model
2024-08-17 23:12:49,887:INFO:Naive Bayes Imported successfully
2024-08-17 23:12:49,894:INFO:Starting cross validation
2024-08-17 23:12:49,897:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=42, shuffle=True), n_jobs=1
2024-08-17 23:13:13,756:INFO:Calculating mean and std
2024-08-17 23:13:13,758:INFO:Creating metrics dataframe
2024-08-17 23:13:13,760:INFO:Uploading results into container
2024-08-17 23:13:13,760:INFO:Uploading model into container now
2024-08-17 23:13:13,760:INFO:_master_model_container: 2
2024-08-17 23:13:13,760:INFO:_display_container: 2
2024-08-17 23:13:13,761:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-08-17 23:13:13,761:INFO:create_model() successfully completed......................................
2024-08-17 23:13:13,930:INFO:SubProcess create_model() end ==================================
2024-08-17 23:13:13,930:INFO:Creating metrics dataframe
2024-08-17 23:13:13,940:INFO:Initializing Decision Tree Classifier
2024-08-17 23:13:13,940:INFO:Total runtime is 0.783092232545217 minutes
2024-08-17 23:13:13,945:INFO:SubProcess create_model() called ==================================
2024-08-17 23:13:13,945:INFO:Initializing create_model()
2024-08-17 23:13:13,946:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f922114b4c0>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=42, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f922af50760>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-17 23:13:13,946:INFO:Checking exceptions
2024-08-17 23:13:13,946:INFO:Importing libraries
2024-08-17 23:13:13,946:INFO:Copying training dataset
2024-08-17 23:13:14,038:INFO:Defining folds
2024-08-17 23:13:14,038:INFO:Declaring metric variables
2024-08-17 23:13:14,042:INFO:Importing untrained model
2024-08-17 23:13:14,046:INFO:Decision Tree Classifier Imported successfully
2024-08-17 23:13:14,053:INFO:Starting cross validation
2024-08-17 23:13:14,057:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=42, shuffle=True), n_jobs=1
2024-08-17 23:13:38,654:INFO:Calculating mean and std
2024-08-17 23:13:38,655:INFO:Creating metrics dataframe
2024-08-17 23:13:38,656:INFO:Uploading results into container
2024-08-17 23:13:38,657:INFO:Uploading model into container now
2024-08-17 23:13:38,657:INFO:_master_model_container: 3
2024-08-17 23:13:38,657:INFO:_display_container: 2
2024-08-17 23:13:38,658:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2024-08-17 23:13:38,658:INFO:create_model() successfully completed......................................
2024-08-17 23:13:38,811:INFO:SubProcess create_model() end ==================================
2024-08-17 23:13:38,812:INFO:Creating metrics dataframe
2024-08-17 23:13:38,820:INFO:Initializing Ridge Classifier
2024-08-17 23:13:38,820:INFO:Total runtime is 1.1977541009585064 minutes
2024-08-17 23:13:38,824:INFO:SubProcess create_model() called ==================================
2024-08-17 23:13:38,825:INFO:Initializing create_model()
2024-08-17 23:13:38,825:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f922114b4c0>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=42, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f922af50760>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-17 23:13:38,825:INFO:Checking exceptions
2024-08-17 23:13:38,825:INFO:Importing libraries
2024-08-17 23:13:38,825:INFO:Copying training dataset
2024-08-17 23:13:38,913:INFO:Defining folds
2024-08-17 23:13:38,913:INFO:Declaring metric variables
2024-08-17 23:13:38,917:INFO:Importing untrained model
2024-08-17 23:13:38,921:INFO:Ridge Classifier Imported successfully
2024-08-17 23:13:38,928:INFO:Starting cross validation
2024-08-17 23:13:38,931:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=42, shuffle=True), n_jobs=1
2024-08-17 23:13:59,841:INFO:Calculating mean and std
2024-08-17 23:13:59,842:INFO:Creating metrics dataframe
2024-08-17 23:13:59,843:INFO:Uploading results into container
2024-08-17 23:13:59,844:INFO:Uploading model into container now
2024-08-17 23:13:59,844:INFO:_master_model_container: 4
2024-08-17 23:13:59,845:INFO:_display_container: 2
2024-08-17 23:13:59,845:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2024-08-17 23:13:59,845:INFO:create_model() successfully completed......................................
2024-08-17 23:14:00,010:INFO:SubProcess create_model() end ==================================
2024-08-17 23:14:00,010:INFO:Creating metrics dataframe
2024-08-17 23:14:00,020:INFO:Initializing Random Forest Classifier
2024-08-17 23:14:00,020:INFO:Total runtime is 1.551089652379354 minutes
2024-08-17 23:14:00,024:INFO:SubProcess create_model() called ==================================
2024-08-17 23:14:00,025:INFO:Initializing create_model()
2024-08-17 23:14:00,025:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f922114b4c0>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=42, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f922af50760>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-17 23:14:00,025:INFO:Checking exceptions
2024-08-17 23:14:00,025:INFO:Importing libraries
2024-08-17 23:14:00,026:INFO:Copying training dataset
2024-08-17 23:14:00,178:INFO:Defining folds
2024-08-17 23:14:00,178:INFO:Declaring metric variables
2024-08-17 23:14:00,182:INFO:Importing untrained model
2024-08-17 23:14:00,186:INFO:Random Forest Classifier Imported successfully
2024-08-17 23:14:00,194:INFO:Starting cross validation
2024-08-17 23:14:00,197:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=42, shuffle=True), n_jobs=1
2024-08-17 23:14:37,956:INFO:Calculating mean and std
2024-08-17 23:14:37,957:INFO:Creating metrics dataframe
2024-08-17 23:14:37,958:INFO:Uploading results into container
2024-08-17 23:14:37,959:INFO:Uploading model into container now
2024-08-17 23:14:37,959:INFO:_master_model_container: 5
2024-08-17 23:14:37,959:INFO:_display_container: 2
2024-08-17 23:14:37,960:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2024-08-17 23:14:37,960:INFO:create_model() successfully completed......................................
2024-08-17 23:14:38,121:INFO:SubProcess create_model() end ==================================
2024-08-17 23:14:38,122:INFO:Creating metrics dataframe
2024-08-17 23:14:38,133:INFO:Initializing Linear Discriminant Analysis
2024-08-17 23:14:38,133:INFO:Total runtime is 2.1863070170084637 minutes
2024-08-17 23:14:38,138:INFO:SubProcess create_model() called ==================================
2024-08-17 23:14:38,139:INFO:Initializing create_model()
2024-08-17 23:14:38,139:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f922114b4c0>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=42, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f922af50760>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-17 23:14:38,139:INFO:Checking exceptions
2024-08-17 23:14:38,139:INFO:Importing libraries
2024-08-17 23:14:38,140:INFO:Copying training dataset
2024-08-17 23:14:38,228:INFO:Defining folds
2024-08-17 23:14:38,229:INFO:Declaring metric variables
2024-08-17 23:14:38,232:INFO:Importing untrained model
2024-08-17 23:14:38,236:INFO:Linear Discriminant Analysis Imported successfully
2024-08-17 23:14:38,244:INFO:Starting cross validation
2024-08-17 23:14:38,247:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=42, shuffle=True), n_jobs=1
2024-08-17 23:15:02,395:INFO:Calculating mean and std
2024-08-17 23:15:02,397:INFO:Creating metrics dataframe
2024-08-17 23:15:02,398:INFO:Uploading results into container
2024-08-17 23:15:02,399:INFO:Uploading model into container now
2024-08-17 23:15:02,399:INFO:_master_model_container: 6
2024-08-17 23:15:02,400:INFO:_display_container: 2
2024-08-17 23:15:02,400:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-08-17 23:15:02,400:INFO:create_model() successfully completed......................................
2024-08-17 23:15:02,564:INFO:SubProcess create_model() end ==================================
2024-08-17 23:15:02,564:INFO:Creating metrics dataframe
2024-08-17 23:15:02,574:INFO:Initializing Extra Trees Classifier
2024-08-17 23:15:02,574:INFO:Total runtime is 2.593649200598399 minutes
2024-08-17 23:15:02,578:INFO:SubProcess create_model() called ==================================
2024-08-17 23:15:02,578:INFO:Initializing create_model()
2024-08-17 23:15:02,578:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f922114b4c0>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=42, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f922af50760>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-17 23:15:02,578:INFO:Checking exceptions
2024-08-17 23:15:02,578:INFO:Importing libraries
2024-08-17 23:15:02,578:INFO:Copying training dataset
2024-08-17 23:15:02,668:INFO:Defining folds
2024-08-17 23:15:02,668:INFO:Declaring metric variables
2024-08-17 23:15:02,672:INFO:Importing untrained model
2024-08-17 23:15:02,676:INFO:Extra Trees Classifier Imported successfully
2024-08-17 23:15:02,684:INFO:Starting cross validation
2024-08-17 23:15:02,687:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=42, shuffle=True), n_jobs=1
2024-08-17 23:15:40,646:INFO:Calculating mean and std
2024-08-17 23:15:40,648:INFO:Creating metrics dataframe
2024-08-17 23:15:40,650:INFO:Uploading results into container
2024-08-17 23:15:40,650:INFO:Uploading model into container now
2024-08-17 23:15:40,651:INFO:_master_model_container: 7
2024-08-17 23:15:40,651:INFO:_display_container: 2
2024-08-17 23:15:40,651:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2024-08-17 23:15:40,651:INFO:create_model() successfully completed......................................
2024-08-17 23:15:40,831:INFO:SubProcess create_model() end ==================================
2024-08-17 23:15:40,831:INFO:Creating metrics dataframe
2024-08-17 23:15:40,844:INFO:Initializing Light Gradient Boosting Machine
2024-08-17 23:15:40,844:INFO:Total runtime is 3.23148490190506 minutes
2024-08-17 23:15:40,849:INFO:SubProcess create_model() called ==================================
2024-08-17 23:15:40,849:INFO:Initializing create_model()
2024-08-17 23:15:40,849:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f922114b4c0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=42, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f922af50760>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-17 23:15:40,849:INFO:Checking exceptions
2024-08-17 23:15:40,849:INFO:Importing libraries
2024-08-17 23:15:40,850:INFO:Copying training dataset
2024-08-17 23:15:40,937:INFO:Defining folds
2024-08-17 23:15:40,937:INFO:Declaring metric variables
2024-08-17 23:15:40,940:INFO:Importing untrained model
2024-08-17 23:15:40,944:INFO:Light Gradient Boosting Machine Imported successfully
2024-08-17 23:15:40,952:INFO:Starting cross validation
2024-08-17 23:15:40,954:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=42, shuffle=True), n_jobs=1
2024-08-17 23:15:45,305:INFO:[LightGBM] [Info] Number of positive: 63832, number of negative: 63296
2024-08-17 23:15:45,331:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008210 seconds.
2024-08-17 23:15:45,332:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-17 23:15:45,332:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-17 23:15:45,332:INFO:[LightGBM] [Info] Total Bins 161
2024-08-17 23:15:45,333:INFO:[LightGBM] [Info] Number of data points in the train set: 127128, number of used features: 41
2024-08-17 23:15:45,336:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502108 -> initscore=0.008432
2024-08-17 23:15:45,336:INFO:[LightGBM] [Info] Start training from score 0.008432
2024-08-17 23:15:50,121:INFO:[LightGBM] [Info] Number of positive: 63833, number of negative: 63296
2024-08-17 23:15:50,139:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006054 seconds.
2024-08-17 23:15:50,139:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-17 23:15:50,139:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-17 23:15:50,139:INFO:[LightGBM] [Info] Total Bins 159
2024-08-17 23:15:50,139:INFO:[LightGBM] [Info] Number of data points in the train set: 127129, number of used features: 41
2024-08-17 23:15:50,140:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502112 -> initscore=0.008448
2024-08-17 23:15:50,140:INFO:[LightGBM] [Info] Start training from score 0.008448
2024-08-17 23:15:54,726:INFO:[LightGBM] [Info] Number of positive: 63833, number of negative: 63296
2024-08-17 23:15:54,748:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006486 seconds.
2024-08-17 23:15:54,748:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-17 23:15:54,748:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-17 23:15:54,748:INFO:[LightGBM] [Info] Total Bins 158
2024-08-17 23:15:54,749:INFO:[LightGBM] [Info] Number of data points in the train set: 127129, number of used features: 41
2024-08-17 23:15:54,750:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502112 -> initscore=0.008448
2024-08-17 23:15:54,750:INFO:[LightGBM] [Info] Start training from score 0.008448
2024-08-17 23:15:59,421:INFO:[LightGBM] [Info] Number of positive: 63833, number of negative: 63296
2024-08-17 23:15:59,443:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009629 seconds.
2024-08-17 23:15:59,443:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-17 23:15:59,443:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-17 23:15:59,443:INFO:[LightGBM] [Info] Total Bins 160
2024-08-17 23:15:59,443:INFO:[LightGBM] [Info] Number of data points in the train set: 127129, number of used features: 41
2024-08-17 23:15:59,444:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502112 -> initscore=0.008448
2024-08-17 23:15:59,444:INFO:[LightGBM] [Info] Start training from score 0.008448
2024-08-17 23:16:04,360:INFO:[LightGBM] [Info] Number of positive: 63833, number of negative: 63296
2024-08-17 23:16:04,385:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009914 seconds.
2024-08-17 23:16:04,385:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-17 23:16:04,385:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-17 23:16:04,385:INFO:[LightGBM] [Info] Total Bins 160
2024-08-17 23:16:04,385:INFO:[LightGBM] [Info] Number of data points in the train set: 127129, number of used features: 41
2024-08-17 23:16:04,386:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502112 -> initscore=0.008448
2024-08-17 23:16:04,386:INFO:[LightGBM] [Info] Start training from score 0.008448
2024-08-17 23:16:04,896:INFO:Calculating mean and std
2024-08-17 23:16:04,897:INFO:Creating metrics dataframe
2024-08-17 23:16:04,899:INFO:Uploading results into container
2024-08-17 23:16:04,900:INFO:Uploading model into container now
2024-08-17 23:16:04,900:INFO:_master_model_container: 8
2024-08-17 23:16:04,901:INFO:_display_container: 2
2024-08-17 23:16:04,901:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-08-17 23:16:04,901:INFO:create_model() successfully completed......................................
2024-08-17 23:16:05,061:INFO:SubProcess create_model() end ==================================
2024-08-17 23:16:05,061:INFO:Creating metrics dataframe
2024-08-17 23:16:05,082:INFO:Initializing create_model()
2024-08-17 23:16:05,082:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f922114b4c0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=42, shuffle=True), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-17 23:16:05,082:INFO:Checking exceptions
2024-08-17 23:16:05,085:INFO:Importing libraries
2024-08-17 23:16:05,085:INFO:Copying training dataset
2024-08-17 23:16:05,166:INFO:Defining folds
2024-08-17 23:16:05,166:INFO:Declaring metric variables
2024-08-17 23:16:05,167:INFO:Importing untrained model
2024-08-17 23:16:05,167:INFO:Declaring custom model
2024-08-17 23:16:05,167:INFO:Light Gradient Boosting Machine Imported successfully
2024-08-17 23:16:05,170:INFO:Cross validation set to False
2024-08-17 23:16:05,170:INFO:Fitting Model
2024-08-17 23:16:10,743:INFO:[LightGBM] [Info] Number of positive: 79791, number of negative: 79120
2024-08-17 23:16:10,768:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009768 seconds.
2024-08-17 23:16:10,768:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-17 23:16:10,768:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-17 23:16:10,769:INFO:[LightGBM] [Info] Total Bins 166
2024-08-17 23:16:10,769:INFO:[LightGBM] [Info] Number of data points in the train set: 158911, number of used features: 42
2024-08-17 23:16:10,770:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502111 -> initscore=0.008445
2024-08-17 23:16:10,770:INFO:[LightGBM] [Info] Start training from score 0.008445
2024-08-17 23:16:11,008:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-08-17 23:16:11,008:INFO:create_model() successfully completed......................................
2024-08-17 23:16:11,172:INFO:Creating Dashboard logs
2024-08-17 23:16:11,176:INFO:Model: Light Gradient Boosting Machine
2024-08-17 23:16:11,263:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 42, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2024-08-17 23:16:11,511:INFO:Initializing predict_model()
2024-08-17 23:16:11,511:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f922114b4c0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f9217644790>)
2024-08-17 23:16:11,511:INFO:Checking exceptions
2024-08-17 23:16:11,512:INFO:Preloading libraries
2024-08-17 23:16:12,286:INFO:SubProcess plot_model() called ==================================
2024-08-17 23:16:12,287:INFO:Initializing plot_model()
2024-08-17 23:16:12,287:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmpjpyfges_, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f922114b4c0>, system=False)
2024-08-17 23:16:12,287:INFO:Checking exceptions
2024-08-17 23:16:12,321:INFO:Preloading libraries
2024-08-17 23:16:12,326:INFO:Copying training dataset
2024-08-17 23:16:12,326:INFO:Plot type: auc
2024-08-17 23:16:12,918:INFO:Fitting Model
2024-08-17 23:16:12,925:INFO:Scoring test/hold-out set
2024-08-17 23:16:13,130:INFO:Saving '/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmpjpyfges_/AUC.png'
2024-08-17 23:16:13,469:INFO:Visual Rendered Successfully
2024-08-17 23:16:13,662:INFO:plot_model() successfully completed......................................
2024-08-17 23:16:13,666:INFO:Initializing plot_model()
2024-08-17 23:16:13,666:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmpjpyfges_, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f922114b4c0>, system=False)
2024-08-17 23:16:13,666:INFO:Checking exceptions
2024-08-17 23:16:13,708:INFO:Preloading libraries
2024-08-17 23:16:13,712:INFO:Copying training dataset
2024-08-17 23:16:13,712:INFO:Plot type: confusion_matrix
2024-08-17 23:16:14,299:INFO:Fitting Model
2024-08-17 23:16:14,304:INFO:Scoring test/hold-out set
2024-08-17 23:16:14,475:INFO:Saving '/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmpjpyfges_/Confusion Matrix.png'
2024-08-17 23:16:14,619:INFO:Visual Rendered Successfully
2024-08-17 23:16:14,787:INFO:plot_model() successfully completed......................................
2024-08-17 23:16:14,813:INFO:Initializing plot_model()
2024-08-17 23:16:14,813:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmpjpyfges_, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f922114b4c0>, system=False)
2024-08-17 23:16:14,813:INFO:Checking exceptions
2024-08-17 23:16:14,851:INFO:Preloading libraries
2024-08-17 23:16:14,855:INFO:Copying training dataset
2024-08-17 23:16:14,855:INFO:Plot type: feature
2024-08-17 23:16:14,856:WARNING:No coef_ found. Trying feature_importances_
2024-08-17 23:16:15,077:INFO:Saving '/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmpjpyfges_/Feature Importance.png'
2024-08-17 23:16:15,234:INFO:Visual Rendered Successfully
2024-08-17 23:16:15,394:INFO:plot_model() successfully completed......................................
2024-08-17 23:16:15,407:INFO:SubProcess plot_model() end ==================================
2024-08-17 23:16:24,698:INFO:Creating Dashboard logs
2024-08-17 23:16:24,704:INFO:Model: Random Forest Classifier
2024-08-17 23:16:24,765:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
2024-08-17 23:16:25,278:INFO:Creating Dashboard logs
2024-08-17 23:16:25,283:INFO:Model: Naive Bayes
2024-08-17 23:16:25,330:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2024-08-17 23:16:25,875:INFO:Creating Dashboard logs
2024-08-17 23:16:25,879:INFO:Model: Decision Tree Classifier
2024-08-17 23:16:25,934:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 42, 'splitter': 'best'}
2024-08-17 23:16:26,425:INFO:Creating Dashboard logs
2024-08-17 23:16:26,430:INFO:Model: Extra Trees Classifier
2024-08-17 23:16:26,478:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
2024-08-17 23:16:27,007:INFO:Creating Dashboard logs
2024-08-17 23:16:27,012:INFO:Model: Ridge Classifier
2024-08-17 23:16:27,061:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 42, 'solver': 'auto', 'tol': 0.0001}
2024-08-17 23:16:27,596:INFO:Creating Dashboard logs
2024-08-17 23:16:27,601:INFO:Model: Linear Discriminant Analysis
2024-08-17 23:16:27,639:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2024-08-17 23:16:28,203:INFO:Creating Dashboard logs
2024-08-17 23:16:28,208:INFO:Model: Logistic Regression
2024-08-17 23:16:28,261:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2024-08-17 23:16:28,846:INFO:_master_model_container: 8
2024-08-17 23:16:28,846:INFO:_display_container: 2
2024-08-17 23:16:28,847:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-08-17 23:16:28,847:INFO:compare_models() successfully completed......................................
2024-08-17 23:17:48,771:INFO:Initializing create_model()
2024-08-17 23:17:48,772:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f922114b4c0>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-17 23:17:48,773:INFO:Checking exceptions
2024-08-17 23:17:48,797:INFO:Importing libraries
2024-08-17 23:17:48,797:INFO:Copying training dataset
2024-08-17 23:17:48,904:INFO:Defining folds
2024-08-17 23:17:48,904:INFO:Declaring metric variables
2024-08-17 23:17:48,908:INFO:Importing untrained model
2024-08-17 23:17:48,912:INFO:Light Gradient Boosting Machine Imported successfully
2024-08-17 23:17:48,919:INFO:Starting cross validation
2024-08-17 23:17:48,923:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=42, shuffle=True), n_jobs=1
2024-08-17 23:17:53,302:INFO:[LightGBM] [Info] Number of positive: 63832, number of negative: 63296
2024-08-17 23:17:53,317:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006629 seconds.
2024-08-17 23:17:53,318:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-17 23:17:53,318:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-17 23:17:53,318:INFO:[LightGBM] [Info] Total Bins 161
2024-08-17 23:17:53,318:INFO:[LightGBM] [Info] Number of data points in the train set: 127128, number of used features: 41
2024-08-17 23:17:53,319:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502108 -> initscore=0.008432
2024-08-17 23:17:53,319:INFO:[LightGBM] [Info] Start training from score 0.008432
2024-08-17 23:17:58,437:INFO:[LightGBM] [Info] Number of positive: 63833, number of negative: 63296
2024-08-17 23:17:58,461:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007688 seconds.
2024-08-17 23:17:58,462:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-17 23:17:58,462:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-17 23:17:58,462:INFO:[LightGBM] [Info] Total Bins 159
2024-08-17 23:17:58,462:INFO:[LightGBM] [Info] Number of data points in the train set: 127129, number of used features: 41
2024-08-17 23:17:58,463:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502112 -> initscore=0.008448
2024-08-17 23:17:58,463:INFO:[LightGBM] [Info] Start training from score 0.008448
2024-08-17 23:18:03,788:INFO:[LightGBM] [Info] Number of positive: 63833, number of negative: 63296
2024-08-17 23:18:03,803:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006270 seconds.
2024-08-17 23:18:03,803:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-17 23:18:03,803:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-17 23:18:03,804:INFO:[LightGBM] [Info] Total Bins 158
2024-08-17 23:18:03,804:INFO:[LightGBM] [Info] Number of data points in the train set: 127129, number of used features: 41
2024-08-17 23:18:03,805:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502112 -> initscore=0.008448
2024-08-17 23:18:03,805:INFO:[LightGBM] [Info] Start training from score 0.008448
2024-08-17 23:18:08,954:INFO:[LightGBM] [Info] Number of positive: 63833, number of negative: 63296
2024-08-17 23:18:08,981:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008279 seconds.
2024-08-17 23:18:08,981:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-17 23:18:08,982:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-17 23:18:08,982:INFO:[LightGBM] [Info] Total Bins 160
2024-08-17 23:18:08,982:INFO:[LightGBM] [Info] Number of data points in the train set: 127129, number of used features: 41
2024-08-17 23:18:08,983:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502112 -> initscore=0.008448
2024-08-17 23:18:08,983:INFO:[LightGBM] [Info] Start training from score 0.008448
2024-08-17 23:18:14,162:INFO:[LightGBM] [Info] Number of positive: 63833, number of negative: 63296
2024-08-17 23:18:14,176:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005374 seconds.
2024-08-17 23:18:14,177:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-17 23:18:14,177:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-17 23:18:14,177:INFO:[LightGBM] [Info] Total Bins 160
2024-08-17 23:18:14,177:INFO:[LightGBM] [Info] Number of data points in the train set: 127129, number of used features: 41
2024-08-17 23:18:14,178:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502112 -> initscore=0.008448
2024-08-17 23:18:14,178:INFO:[LightGBM] [Info] Start training from score 0.008448
2024-08-17 23:18:14,677:INFO:Calculating mean and std
2024-08-17 23:18:14,678:INFO:Creating metrics dataframe
2024-08-17 23:18:14,684:INFO:Finalizing model
2024-08-17 23:18:20,683:INFO:[LightGBM] [Info] Number of positive: 79791, number of negative: 79120
2024-08-17 23:18:20,708:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009669 seconds.
2024-08-17 23:18:20,708:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-17 23:18:20,708:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-17 23:18:20,708:INFO:[LightGBM] [Info] Total Bins 166
2024-08-17 23:18:20,708:INFO:[LightGBM] [Info] Number of data points in the train set: 158911, number of used features: 42
2024-08-17 23:18:20,709:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502111 -> initscore=0.008445
2024-08-17 23:18:20,710:INFO:[LightGBM] [Info] Start training from score 0.008445
2024-08-17 23:18:20,934:INFO:Creating Dashboard logs
2024-08-17 23:18:20,938:INFO:Model: Light Gradient Boosting Machine
2024-08-17 23:18:20,985:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 42, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2024-08-17 23:18:21,213:INFO:Initializing predict_model()
2024-08-17 23:18:21,213:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f922114b4c0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f921776f520>)
2024-08-17 23:18:21,213:INFO:Checking exceptions
2024-08-17 23:18:21,214:INFO:Preloading libraries
2024-08-17 23:18:22,070:INFO:SubProcess plot_model() called ==================================
2024-08-17 23:18:22,071:INFO:Initializing plot_model()
2024-08-17 23:18:22,071:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmpuoomrf1a, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f922114b4c0>, system=False)
2024-08-17 23:18:22,071:INFO:Checking exceptions
2024-08-17 23:18:22,109:INFO:Preloading libraries
2024-08-17 23:18:22,114:INFO:Copying training dataset
2024-08-17 23:18:22,114:INFO:Plot type: auc
2024-08-17 23:18:22,650:INFO:Fitting Model
2024-08-17 23:18:22,657:INFO:Scoring test/hold-out set
2024-08-17 23:18:22,857:INFO:Saving '/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmpuoomrf1a/AUC.png'
2024-08-17 23:18:23,118:INFO:Visual Rendered Successfully
2024-08-17 23:18:23,286:INFO:plot_model() successfully completed......................................
2024-08-17 23:18:23,288:INFO:Initializing plot_model()
2024-08-17 23:18:23,289:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmpuoomrf1a, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f922114b4c0>, system=False)
2024-08-17 23:18:23,289:INFO:Checking exceptions
2024-08-17 23:18:23,327:INFO:Preloading libraries
2024-08-17 23:18:23,332:INFO:Copying training dataset
2024-08-17 23:18:23,332:INFO:Plot type: confusion_matrix
2024-08-17 23:18:23,923:INFO:Fitting Model
2024-08-17 23:18:23,927:INFO:Scoring test/hold-out set
2024-08-17 23:18:24,104:INFO:Saving '/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmpuoomrf1a/Confusion Matrix.png'
2024-08-17 23:18:24,274:INFO:Visual Rendered Successfully
2024-08-17 23:18:24,444:INFO:plot_model() successfully completed......................................
2024-08-17 23:18:24,458:INFO:Initializing plot_model()
2024-08-17 23:18:24,458:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmpuoomrf1a, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f922114b4c0>, system=False)
2024-08-17 23:18:24,458:INFO:Checking exceptions
2024-08-17 23:18:24,497:INFO:Preloading libraries
2024-08-17 23:18:24,500:INFO:Copying training dataset
2024-08-17 23:18:24,501:INFO:Plot type: feature
2024-08-17 23:18:24,501:WARNING:No coef_ found. Trying feature_importances_
2024-08-17 23:18:24,727:INFO:Saving '/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmpuoomrf1a/Feature Importance.png'
2024-08-17 23:18:24,889:INFO:Visual Rendered Successfully
2024-08-17 23:18:25,042:INFO:plot_model() successfully completed......................................
2024-08-17 23:18:25,058:INFO:SubProcess plot_model() end ==================================
2024-08-17 23:18:25,331:INFO:Uploading results into container
2024-08-17 23:18:25,332:INFO:Uploading model into container now
2024-08-17 23:18:25,341:INFO:_master_model_container: 9
2024-08-17 23:18:25,342:INFO:_display_container: 3
2024-08-17 23:18:25,342:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-08-17 23:18:25,342:INFO:create_model() successfully completed......................................
2024-08-17 23:21:19,587:INFO:Initializing plot_model()
2024-08-17 23:21:19,588:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f922114b4c0>, system=True)
2024-08-17 23:21:19,588:INFO:Checking exceptions
2024-08-17 23:21:19,627:INFO:Preloading libraries
2024-08-17 23:21:19,632:INFO:Copying training dataset
2024-08-17 23:21:19,632:INFO:Plot type: feature
2024-08-17 23:21:19,633:WARNING:No coef_ found. Trying feature_importances_
2024-08-17 23:21:19,991:INFO:Visual Rendered Successfully
2024-08-17 23:21:20,159:INFO:plot_model() successfully completed......................................
2024-08-17 23:35:48,686:INFO:PyCaret ClassificationExperiment
2024-08-17 23:35:48,686:INFO:Logging name: codepro_model_exp02
2024-08-17 23:35:48,686:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-08-17 23:35:48,686:INFO:version 3.3.2
2024-08-17 23:35:48,686:INFO:Initializing setup()
2024-08-17 23:35:48,686:INFO:self.USI: 025e
2024-08-17 23:35:48,686:INFO:self._variable_keys: {'log_plots_param', 'fold_shuffle_param', 'data', 'html_param', '_available_plots', 'y_test', 'is_multiclass', 'USI', 'logging_param', 'target_param', 'n_jobs_param', '_ml_usecase', 'X_test', 'gpu_param', 'y', 'memory', 'seed', 'X', 'pipeline', 'y_train', 'fix_imbalance', 'gpu_n_jobs_param', 'fold_generator', 'X_train', 'exp_id', 'fold_groups_param', 'exp_name_log', 'idx'}
2024-08-17 23:35:48,686:INFO:Checking environment
2024-08-17 23:35:48,686:INFO:python_version: 3.10.9
2024-08-17 23:35:48,686:INFO:python_build: ('main', 'Mar  1 2023 12:33:47')
2024-08-17 23:35:48,686:INFO:machine: x86_64
2024-08-17 23:35:48,686:INFO:platform: macOS-10.16-x86_64-i386-64bit
2024-08-17 23:35:48,686:INFO:Memory: svmem(total=17179869184, available=5787373568, percent=66.3, used=9603641344, free=283312128, active=5516746752, inactive=5502881792, wired=4086894592)
2024-08-17 23:35:48,686:INFO:Physical Core: 6
2024-08-17 23:35:48,686:INFO:Logical Core: 12
2024-08-17 23:35:48,686:INFO:Checking libraries
2024-08-17 23:35:48,686:INFO:System:
2024-08-17 23:35:48,687:INFO:    python: 3.10.9 (main, Mar  1 2023, 12:33:47) [Clang 14.0.6 ]
2024-08-17 23:35:48,687:INFO:executable: /Users/I500955/anaconda3/bin/python
2024-08-17 23:35:48,687:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2024-08-17 23:35:48,687:INFO:PyCaret required dependencies:
2024-08-17 23:35:48,687:INFO:                 pip: 22.3.1
2024-08-17 23:35:48,687:INFO:          setuptools: 65.6.3
2024-08-17 23:35:48,687:INFO:             pycaret: 3.3.2
2024-08-17 23:35:48,687:INFO:             IPython: 8.10.0
2024-08-17 23:35:48,687:INFO:          ipywidgets: 7.6.5
2024-08-17 23:35:48,687:INFO:                tqdm: 4.64.1
2024-08-17 23:35:48,687:INFO:               numpy: 1.23.5
2024-08-17 23:35:48,687:INFO:              pandas: 2.2.2
2024-08-17 23:35:48,687:INFO:              jinja2: 3.1.2
2024-08-17 23:35:48,687:INFO:               scipy: 1.10.0
2024-08-17 23:35:48,687:INFO:              joblib: 1.3.2
2024-08-17 23:35:48,687:INFO:             sklearn: 1.4.2
2024-08-17 23:35:48,687:INFO:                pyod: 2.0.1
2024-08-17 23:35:48,687:INFO:            imblearn: 0.12.3
2024-08-17 23:35:48,687:INFO:   category_encoders: 2.6.3
2024-08-17 23:35:48,687:INFO:            lightgbm: 4.5.0
2024-08-17 23:35:48,687:INFO:               numba: 0.56.4
2024-08-17 23:35:48,687:INFO:            requests: 2.28.1
2024-08-17 23:35:48,687:INFO:          matplotlib: 3.7.0
2024-08-17 23:35:48,687:INFO:          scikitplot: 0.3.7
2024-08-17 23:35:48,687:INFO:         yellowbrick: 1.5
2024-08-17 23:35:48,688:INFO:              plotly: 5.23.0
2024-08-17 23:35:48,688:INFO:    plotly-resampler: Not installed
2024-08-17 23:35:48,688:INFO:             kaleido: 0.2.1
2024-08-17 23:35:48,688:INFO:           schemdraw: 0.15
2024-08-17 23:35:48,688:INFO:         statsmodels: 0.13.5
2024-08-17 23:35:48,688:INFO:              sktime: 0.26.0
2024-08-17 23:35:48,688:INFO:               tbats: 1.1.3
2024-08-17 23:35:48,688:INFO:            pmdarima: 2.0.4
2024-08-17 23:35:48,688:INFO:              psutil: 5.9.0
2024-08-17 23:35:48,688:INFO:          markupsafe: 2.1.1
2024-08-17 23:35:48,688:INFO:             pickle5: Not installed
2024-08-17 23:35:48,688:INFO:         cloudpickle: 3.0.0
2024-08-17 23:35:48,688:INFO:         deprecation: 2.1.0
2024-08-17 23:35:48,688:INFO:              xxhash: 3.5.0
2024-08-17 23:35:48,688:INFO:           wurlitzer: 3.0.2
2024-08-17 23:35:48,688:INFO:PyCaret optional dependencies:
2024-08-17 23:35:48,688:INFO:                shap: Not installed
2024-08-17 23:35:48,688:INFO:           interpret: Not installed
2024-08-17 23:35:48,688:INFO:                umap: Not installed
2024-08-17 23:35:48,688:INFO:     ydata_profiling: 4.9.0
2024-08-17 23:35:48,688:INFO:  explainerdashboard: Not installed
2024-08-17 23:35:48,688:INFO:             autoviz: Not installed
2024-08-17 23:35:48,689:INFO:           fairlearn: Not installed
2024-08-17 23:35:48,689:INFO:          deepchecks: Not installed
2024-08-17 23:35:48,689:INFO:             xgboost: Not installed
2024-08-17 23:35:48,689:INFO:            catboost: Not installed
2024-08-17 23:35:48,689:INFO:              kmodes: Not installed
2024-08-17 23:35:48,689:INFO:             mlxtend: Not installed
2024-08-17 23:35:48,689:INFO:       statsforecast: Not installed
2024-08-17 23:35:48,689:INFO:        tune_sklearn: Not installed
2024-08-17 23:35:48,689:INFO:                 ray: Not installed
2024-08-17 23:35:48,689:INFO:            hyperopt: Not installed
2024-08-17 23:35:48,689:INFO:              optuna: Not installed
2024-08-17 23:35:48,689:INFO:               skopt: 0.10.2
2024-08-17 23:35:48,689:INFO:              mlflow: 2.15.1
2024-08-17 23:35:48,689:INFO:              gradio: Not installed
2024-08-17 23:35:48,689:INFO:             fastapi: Not installed
2024-08-17 23:35:48,689:INFO:             uvicorn: Not installed
2024-08-17 23:35:48,689:INFO:              m2cgen: Not installed
2024-08-17 23:35:48,689:INFO:           evidently: Not installed
2024-08-17 23:35:48,689:INFO:               fugue: Not installed
2024-08-17 23:35:48,689:INFO:           streamlit: Not installed
2024-08-17 23:35:48,689:INFO:             prophet: Not installed
2024-08-17 23:35:48,689:INFO:None
2024-08-17 23:35:48,689:INFO:Set up GPU usage.
2024-08-17 23:35:48,690:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:35:48,690:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2024-08-17 23:35:48,690:INFO:Set up data.
2024-08-17 23:35:48,760:INFO:Set up folding strategy.
2024-08-17 23:35:48,760:INFO:Set up train/test split.
2024-08-17 23:35:48,844:INFO:Set up index.
2024-08-17 23:35:48,851:INFO:Assigning column types.
2024-08-17 23:35:48,868:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-08-17 23:35:48,868:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:35:48,909:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-17 23:35:48,909:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:35:48,909:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:35:48,910:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-17 23:35:48,910:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:35:48,933:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:35:48,937:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:35:48,939:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-17 23:35:48,943:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-17 23:35:48,944:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:35:48,987:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-17 23:35:48,988:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:35:48,988:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:35:48,988:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-17 23:35:48,988:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:35:49,010:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:35:49,014:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:35:49,016:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-17 23:35:49,019:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-17 23:35:49,019:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-08-17 23:35:49,019:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:35:49,064:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:35:49,065:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:35:49,065:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-17 23:35:49,065:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:35:49,085:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:35:49,090:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:35:49,091:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-17 23:35:49,094:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-17 23:35:49,094:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:35:49,139:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:35:49,139:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:35:49,140:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-17 23:35:49,140:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:35:49,162:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:35:49,166:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:35:49,167:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-17 23:35:49,172:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-17 23:35:49,173:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-08-17 23:35:49,173:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:35:49,221:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:35:49,221:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:35:49,221:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:35:49,243:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:35:49,247:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:35:49,248:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-17 23:35:49,251:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-17 23:35:49,252:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:35:49,293:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:35:49,293:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:35:49,294:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:35:49,316:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:35:49,322:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:35:49,323:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-17 23:35:49,327:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-17 23:35:49,329:INFO:Preparing preprocessing pipeline...
2024-08-17 23:35:49,334:INFO:Set up simple imputation.
2024-08-17 23:35:49,354:INFO:Set up encoding of categorical features.
2024-08-17 23:35:49,354:INFO:Set up removing multicollinearity.
2024-08-17 23:35:51,476:INFO:Finished creating preprocessing pipeline.
2024-08-17 23:35:51,484:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_droppped',
                                             'city_tier', 'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),...
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.95)))],
         verbose=False)
2024-08-17 23:35:51,484:INFO:Creating final display dataframe.
2024-08-17 23:35:52,717:INFO:Setup _display_container:                     Description                Value
0                    Session id                 2814
1                        Target    app_complete_flag
2                   Target type               Binary
3           Original data shape          (227016, 7)
4        Transformed data shape         (227016, 39)
5   Transformed train set shape         (158911, 39)
6    Transformed test set shape          (68105, 39)
7              Numeric features                    3
8          Categorical features                    3
9                    Preprocess                 True
10              Imputation type               simple
11           Numeric imputation                 mean
12       Categorical imputation                 mode
13     Maximum one-hot encoding                   25
14              Encoding method                 None
15     Remove multicollinearity                 True
16  Multicollinearity threshold                 0.95
17               Fold Generator      StratifiedKFold
18                  Fold Number                   10
19                     CPU Jobs                   -1
20                      Use GPU                 True
21               Log Experiment         MlflowLogger
22              Experiment Name  codepro_model_exp02
23                          USI                 025e
2024-08-17 23:35:52,724:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:35:52,775:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:35:52,775:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:35:52,776:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:35:52,799:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:35:52,804:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:35:52,804:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-17 23:35:52,808:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-17 23:35:52,808:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:35:52,852:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:35:52,852:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:35:52,853:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:35:52,874:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:35:52,878:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:35:52,879:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-17 23:35:52,882:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-17 23:35:52,883:INFO:Logging experiment in loggers
2024-08-17 23:35:53,002:INFO:SubProcess save_model() called ==================================
2024-08-17 23:35:53,014:INFO:Initializing save_model()
2024-08-17 23:35:53,015:INFO:save_model(model=Pipeline(memory=FastMemory(location=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_droppped',
                                             'city_tier', 'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),...
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.95)))],
         verbose=False), model_name=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmptwdgkvu6/Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_droppped',
                                             'city_tier', 'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),...
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.95)))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-08-17 23:35:53,015:INFO:Adding model into prep_pipe
2024-08-17 23:35:53,015:WARNING:Only Model saved as it was a pipeline.
2024-08-17 23:35:53,024:INFO:/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmptwdgkvu6/Transformation Pipeline.pkl saved in current working directory
2024-08-17 23:35:53,030:INFO:Pipeline(memory=FastMemory(location=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_droppped',
                                             'city_tier', 'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),...
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.95)))],
         verbose=False)
2024-08-17 23:35:53,030:INFO:save_model() successfully completed......................................
2024-08-17 23:35:53,180:INFO:SubProcess save_model() end ==================================
2024-08-17 23:35:53,825:INFO:setup() successfully completed in 4.22s...............
2024-08-17 23:37:03,813:INFO:PyCaret ClassificationExperiment
2024-08-17 23:37:03,814:INFO:Logging name: codepro_model_exp02
2024-08-17 23:37:03,814:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-08-17 23:37:03,814:INFO:version 3.3.2
2024-08-17 23:37:03,814:INFO:Initializing setup()
2024-08-17 23:37:03,814:INFO:self.USI: bcba
2024-08-17 23:37:03,814:INFO:self._variable_keys: {'log_plots_param', 'fold_shuffle_param', 'data', 'html_param', '_available_plots', 'y_test', 'is_multiclass', 'USI', 'logging_param', 'target_param', 'n_jobs_param', '_ml_usecase', 'X_test', 'gpu_param', 'y', 'memory', 'seed', 'X', 'pipeline', 'y_train', 'fix_imbalance', 'gpu_n_jobs_param', 'fold_generator', 'X_train', 'exp_id', 'fold_groups_param', 'exp_name_log', 'idx'}
2024-08-17 23:37:03,814:INFO:Checking environment
2024-08-17 23:37:03,814:INFO:python_version: 3.10.9
2024-08-17 23:37:03,814:INFO:python_build: ('main', 'Mar  1 2023 12:33:47')
2024-08-17 23:37:03,814:INFO:machine: x86_64
2024-08-17 23:37:03,815:INFO:platform: macOS-10.16-x86_64-i386-64bit
2024-08-17 23:37:03,815:INFO:Memory: svmem(total=17179869184, available=5610209280, percent=67.3, used=9655287808, free=236314624, active=5379989504, inactive=5330137088, wired=4275298304)
2024-08-17 23:37:03,815:INFO:Physical Core: 6
2024-08-17 23:37:03,815:INFO:Logical Core: 12
2024-08-17 23:37:03,815:INFO:Checking libraries
2024-08-17 23:37:03,815:INFO:System:
2024-08-17 23:37:03,815:INFO:    python: 3.10.9 (main, Mar  1 2023, 12:33:47) [Clang 14.0.6 ]
2024-08-17 23:37:03,815:INFO:executable: /Users/I500955/anaconda3/bin/python
2024-08-17 23:37:03,815:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2024-08-17 23:37:03,815:INFO:PyCaret required dependencies:
2024-08-17 23:37:03,815:INFO:                 pip: 22.3.1
2024-08-17 23:37:03,815:INFO:          setuptools: 65.6.3
2024-08-17 23:37:03,816:INFO:             pycaret: 3.3.2
2024-08-17 23:37:03,816:INFO:             IPython: 8.10.0
2024-08-17 23:37:03,816:INFO:          ipywidgets: 7.6.5
2024-08-17 23:37:03,816:INFO:                tqdm: 4.64.1
2024-08-17 23:37:03,816:INFO:               numpy: 1.23.5
2024-08-17 23:37:03,816:INFO:              pandas: 2.2.2
2024-08-17 23:37:03,816:INFO:              jinja2: 3.1.2
2024-08-17 23:37:03,816:INFO:               scipy: 1.10.0
2024-08-17 23:37:03,816:INFO:              joblib: 1.3.2
2024-08-17 23:37:03,817:INFO:             sklearn: 1.4.2
2024-08-17 23:37:03,817:INFO:                pyod: 2.0.1
2024-08-17 23:37:03,817:INFO:            imblearn: 0.12.3
2024-08-17 23:37:03,817:INFO:   category_encoders: 2.6.3
2024-08-17 23:37:03,817:INFO:            lightgbm: 4.5.0
2024-08-17 23:37:03,817:INFO:               numba: 0.56.4
2024-08-17 23:37:03,817:INFO:            requests: 2.28.1
2024-08-17 23:37:03,817:INFO:          matplotlib: 3.7.0
2024-08-17 23:37:03,817:INFO:          scikitplot: 0.3.7
2024-08-17 23:37:03,817:INFO:         yellowbrick: 1.5
2024-08-17 23:37:03,817:INFO:              plotly: 5.23.0
2024-08-17 23:37:03,817:INFO:    plotly-resampler: Not installed
2024-08-17 23:37:03,818:INFO:             kaleido: 0.2.1
2024-08-17 23:37:03,818:INFO:           schemdraw: 0.15
2024-08-17 23:37:03,818:INFO:         statsmodels: 0.13.5
2024-08-17 23:37:03,818:INFO:              sktime: 0.26.0
2024-08-17 23:37:03,818:INFO:               tbats: 1.1.3
2024-08-17 23:37:03,818:INFO:            pmdarima: 2.0.4
2024-08-17 23:37:03,818:INFO:              psutil: 5.9.0
2024-08-17 23:37:03,818:INFO:          markupsafe: 2.1.1
2024-08-17 23:37:03,818:INFO:             pickle5: Not installed
2024-08-17 23:37:03,818:INFO:         cloudpickle: 3.0.0
2024-08-17 23:37:03,818:INFO:         deprecation: 2.1.0
2024-08-17 23:37:03,818:INFO:              xxhash: 3.5.0
2024-08-17 23:37:03,818:INFO:           wurlitzer: 3.0.2
2024-08-17 23:37:03,818:INFO:PyCaret optional dependencies:
2024-08-17 23:37:03,819:INFO:                shap: Not installed
2024-08-17 23:37:03,819:INFO:           interpret: Not installed
2024-08-17 23:37:03,819:INFO:                umap: Not installed
2024-08-17 23:37:03,819:INFO:     ydata_profiling: 4.9.0
2024-08-17 23:37:03,819:INFO:  explainerdashboard: Not installed
2024-08-17 23:37:03,819:INFO:             autoviz: Not installed
2024-08-17 23:37:03,819:INFO:           fairlearn: Not installed
2024-08-17 23:37:03,819:INFO:          deepchecks: Not installed
2024-08-17 23:37:03,819:INFO:             xgboost: Not installed
2024-08-17 23:37:03,819:INFO:            catboost: Not installed
2024-08-17 23:37:03,819:INFO:              kmodes: Not installed
2024-08-17 23:37:03,819:INFO:             mlxtend: Not installed
2024-08-17 23:37:03,819:INFO:       statsforecast: Not installed
2024-08-17 23:37:03,819:INFO:        tune_sklearn: Not installed
2024-08-17 23:37:03,819:INFO:                 ray: Not installed
2024-08-17 23:37:03,819:INFO:            hyperopt: Not installed
2024-08-17 23:37:03,819:INFO:              optuna: Not installed
2024-08-17 23:37:03,820:INFO:               skopt: 0.10.2
2024-08-17 23:37:03,820:INFO:              mlflow: 2.15.1
2024-08-17 23:37:03,820:INFO:              gradio: Not installed
2024-08-17 23:37:03,820:INFO:             fastapi: Not installed
2024-08-17 23:37:03,820:INFO:             uvicorn: Not installed
2024-08-17 23:37:03,820:INFO:              m2cgen: Not installed
2024-08-17 23:37:03,820:INFO:           evidently: Not installed
2024-08-17 23:37:03,820:INFO:               fugue: Not installed
2024-08-17 23:37:03,820:INFO:           streamlit: Not installed
2024-08-17 23:37:03,821:INFO:             prophet: Not installed
2024-08-17 23:37:03,821:INFO:None
2024-08-17 23:37:03,821:INFO:Set up GPU usage.
2024-08-17 23:37:03,821:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:37:03,821:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2024-08-17 23:37:03,821:INFO:Set up data.
2024-08-17 23:37:03,898:INFO:Set up folding strategy.
2024-08-17 23:37:03,899:INFO:Set up train/test split.
2024-08-17 23:37:03,994:INFO:Set up index.
2024-08-17 23:37:04,003:INFO:Assigning column types.
2024-08-17 23:37:04,025:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-08-17 23:37:04,025:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:37:04,118:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-17 23:37:04,118:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:37:04,118:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:37:04,118:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-17 23:37:04,119:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:37:04,145:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:37:04,149:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:37:04,151:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-17 23:37:04,155:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-17 23:37:04,155:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:37:04,217:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-17 23:37:04,217:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:37:04,217:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:37:04,218:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-17 23:37:04,218:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:37:04,246:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:37:04,250:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:37:04,252:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-17 23:37:04,255:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-17 23:37:04,255:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-08-17 23:37:04,255:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:37:04,311:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:37:04,311:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:37:04,312:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-17 23:37:04,312:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:37:04,336:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:37:04,344:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:37:04,345:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-17 23:37:04,349:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-17 23:37:04,350:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:37:04,403:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:37:04,404:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:37:04,405:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-17 23:37:04,405:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:37:04,433:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:37:04,441:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:37:04,442:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-17 23:37:04,447:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-17 23:37:04,448:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-08-17 23:37:04,448:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:37:04,499:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:37:04,499:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:37:04,500:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:37:04,522:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:37:04,526:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:37:04,527:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-17 23:37:04,531:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-17 23:37:04,531:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:37:04,580:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:37:04,580:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:37:04,581:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:37:04,605:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:37:04,609:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:37:04,610:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-17 23:37:04,614:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-17 23:37:04,615:INFO:Preparing preprocessing pipeline...
2024-08-17 23:37:04,619:INFO:Set up simple imputation.
2024-08-17 23:37:04,636:INFO:Set up encoding of categorical features.
2024-08-17 23:37:04,636:INFO:Set up removing multicollinearity.
2024-08-17 23:37:06,722:INFO:Finished creating preprocessing pipeline.
2024-08-17 23:37:06,733:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_droppped',
                                             'city_tier', 'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),...
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.95)))],
         verbose=False)
2024-08-17 23:37:06,733:INFO:Creating final display dataframe.
2024-08-17 23:37:07,983:INFO:Setup _display_container:                     Description                Value
0                    Session id                 3006
1                        Target    app_complete_flag
2                   Target type               Binary
3           Original data shape          (227016, 7)
4        Transformed data shape         (227016, 39)
5   Transformed train set shape         (158911, 39)
6    Transformed test set shape          (68105, 39)
7              Numeric features                    3
8          Categorical features                    3
9                    Preprocess                 True
10              Imputation type               simple
11           Numeric imputation                 mean
12       Categorical imputation                 mode
13     Maximum one-hot encoding                   25
14              Encoding method                 None
15     Remove multicollinearity                 True
16  Multicollinearity threshold                 0.95
17               Fold Generator      StratifiedKFold
18                  Fold Number                   10
19                     CPU Jobs                   -1
20                      Use GPU                 True
21               Log Experiment         MlflowLogger
22              Experiment Name  codepro_model_exp02
23                          USI                 bcba
2024-08-17 23:37:07,989:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:37:08,040:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:37:08,040:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:37:08,040:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:37:08,064:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:37:08,068:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:37:08,069:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-17 23:37:08,073:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-17 23:37:08,073:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:37:08,116:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:37:08,116:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:37:08,117:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:37:08,139:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:37:08,143:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:37:08,144:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-17 23:37:08,147:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-17 23:37:08,149:INFO:Logging experiment in loggers
2024-08-17 23:37:08,244:INFO:SubProcess save_model() called ==================================
2024-08-17 23:37:08,256:INFO:Initializing save_model()
2024-08-17 23:37:08,256:INFO:save_model(model=Pipeline(memory=FastMemory(location=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_droppped',
                                             'city_tier', 'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),...
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.95)))],
         verbose=False), model_name=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmpdsh69rv_/Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_droppped',
                                             'city_tier', 'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),...
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.95)))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-08-17 23:37:08,256:INFO:Adding model into prep_pipe
2024-08-17 23:37:08,256:WARNING:Only Model saved as it was a pipeline.
2024-08-17 23:37:08,266:INFO:/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmpdsh69rv_/Transformation Pipeline.pkl saved in current working directory
2024-08-17 23:37:08,272:INFO:Pipeline(memory=FastMemory(location=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_droppped',
                                             'city_tier', 'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),...
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.95)))],
         verbose=False)
2024-08-17 23:37:08,272:INFO:save_model() successfully completed......................................
2024-08-17 23:37:08,432:INFO:SubProcess save_model() end ==================================
2024-08-17 23:37:09,114:INFO:setup() successfully completed in 4.37s...............
2024-08-17 23:37:41,950:INFO:Initializing compare_models()
2024-08-17 23:37:41,951:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f92177d2c50>, include=None, fold=5, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f92177d2c50>, 'include': None, 'exclude': ['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada'], 'fold': 5, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada'])
2024-08-17 23:37:41,951:INFO:Checking exceptions
2024-08-17 23:37:41,982:INFO:Preparing display monitor
2024-08-17 23:37:42,021:INFO:Initializing Logistic Regression
2024-08-17 23:37:42,022:INFO:Total runtime is 4.466374715169271e-06 minutes
2024-08-17 23:37:42,027:INFO:SubProcess create_model() called ==================================
2024-08-17 23:37:42,027:INFO:Initializing create_model()
2024-08-17 23:37:42,027:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f92177d2c50>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f92405f1660>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-17 23:37:42,027:INFO:Checking exceptions
2024-08-17 23:37:42,027:INFO:Importing libraries
2024-08-17 23:37:42,028:INFO:Copying training dataset
2024-08-17 23:37:42,083:INFO:Defining folds
2024-08-17 23:37:42,083:INFO:Declaring metric variables
2024-08-17 23:37:42,087:INFO:Importing untrained model
2024-08-17 23:37:42,091:INFO:Logistic Regression Imported successfully
2024-08-17 23:37:42,100:INFO:Starting cross validation
2024-08-17 23:37:42,103:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-08-17 23:37:51,257:INFO:Calculating mean and std
2024-08-17 23:37:51,258:INFO:Creating metrics dataframe
2024-08-17 23:37:51,260:INFO:Uploading results into container
2024-08-17 23:37:51,261:INFO:Uploading model into container now
2024-08-17 23:37:51,261:INFO:_master_model_container: 1
2024-08-17 23:37:51,261:INFO:_display_container: 2
2024-08-17 23:37:51,262:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3006, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-08-17 23:37:51,262:INFO:create_model() successfully completed......................................
2024-08-17 23:37:51,435:INFO:SubProcess create_model() end ==================================
2024-08-17 23:37:51,435:INFO:Creating metrics dataframe
2024-08-17 23:37:51,444:INFO:Initializing Naive Bayes
2024-08-17 23:37:51,444:INFO:Total runtime is 0.15704766909281412 minutes
2024-08-17 23:37:51,449:INFO:SubProcess create_model() called ==================================
2024-08-17 23:37:51,449:INFO:Initializing create_model()
2024-08-17 23:37:51,449:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f92177d2c50>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f92405f1660>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-17 23:37:51,449:INFO:Checking exceptions
2024-08-17 23:37:51,449:INFO:Importing libraries
2024-08-17 23:37:51,449:INFO:Copying training dataset
2024-08-17 23:37:51,568:INFO:Defining folds
2024-08-17 23:37:51,569:INFO:Declaring metric variables
2024-08-17 23:37:51,573:INFO:Importing untrained model
2024-08-17 23:37:51,577:INFO:Naive Bayes Imported successfully
2024-08-17 23:37:51,585:INFO:Starting cross validation
2024-08-17 23:37:51,589:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-08-17 23:38:01,112:INFO:Calculating mean and std
2024-08-17 23:38:01,114:INFO:Creating metrics dataframe
2024-08-17 23:38:01,116:INFO:Uploading results into container
2024-08-17 23:38:01,116:INFO:Uploading model into container now
2024-08-17 23:38:01,117:INFO:_master_model_container: 2
2024-08-17 23:38:01,117:INFO:_display_container: 2
2024-08-17 23:38:01,117:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-08-17 23:38:01,117:INFO:create_model() successfully completed......................................
2024-08-17 23:38:01,281:INFO:SubProcess create_model() end ==================================
2024-08-17 23:38:01,281:INFO:Creating metrics dataframe
2024-08-17 23:38:01,292:INFO:Initializing Decision Tree Classifier
2024-08-17 23:38:01,292:INFO:Total runtime is 0.321176016330719 minutes
2024-08-17 23:38:01,297:INFO:SubProcess create_model() called ==================================
2024-08-17 23:38:01,297:INFO:Initializing create_model()
2024-08-17 23:38:01,297:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f92177d2c50>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f92405f1660>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-17 23:38:01,298:INFO:Checking exceptions
2024-08-17 23:38:01,298:INFO:Importing libraries
2024-08-17 23:38:01,298:INFO:Copying training dataset
2024-08-17 23:38:01,346:INFO:Defining folds
2024-08-17 23:38:01,346:INFO:Declaring metric variables
2024-08-17 23:38:01,351:INFO:Importing untrained model
2024-08-17 23:38:01,355:INFO:Decision Tree Classifier Imported successfully
2024-08-17 23:38:01,362:INFO:Starting cross validation
2024-08-17 23:38:01,364:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-08-17 23:38:11,442:INFO:Calculating mean and std
2024-08-17 23:38:11,443:INFO:Creating metrics dataframe
2024-08-17 23:38:11,445:INFO:Uploading results into container
2024-08-17 23:38:11,445:INFO:Uploading model into container now
2024-08-17 23:38:11,446:INFO:_master_model_container: 3
2024-08-17 23:38:11,446:INFO:_display_container: 2
2024-08-17 23:38:11,446:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=3006, splitter='best')
2024-08-17 23:38:11,446:INFO:create_model() successfully completed......................................
2024-08-17 23:38:11,607:INFO:SubProcess create_model() end ==================================
2024-08-17 23:38:11,607:INFO:Creating metrics dataframe
2024-08-17 23:38:11,616:INFO:Initializing Ridge Classifier
2024-08-17 23:38:11,616:INFO:Total runtime is 0.4932452996571859 minutes
2024-08-17 23:38:11,620:INFO:SubProcess create_model() called ==================================
2024-08-17 23:38:11,620:INFO:Initializing create_model()
2024-08-17 23:38:11,620:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f92177d2c50>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f92405f1660>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-17 23:38:11,620:INFO:Checking exceptions
2024-08-17 23:38:11,620:INFO:Importing libraries
2024-08-17 23:38:11,621:INFO:Copying training dataset
2024-08-17 23:38:11,664:INFO:Defining folds
2024-08-17 23:38:11,664:INFO:Declaring metric variables
2024-08-17 23:38:11,668:INFO:Importing untrained model
2024-08-17 23:38:11,671:INFO:Ridge Classifier Imported successfully
2024-08-17 23:38:11,678:INFO:Starting cross validation
2024-08-17 23:38:11,680:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-08-17 23:38:20,636:INFO:Calculating mean and std
2024-08-17 23:38:20,637:INFO:Creating metrics dataframe
2024-08-17 23:38:20,639:INFO:Uploading results into container
2024-08-17 23:38:20,640:INFO:Uploading model into container now
2024-08-17 23:38:20,641:INFO:_master_model_container: 4
2024-08-17 23:38:20,641:INFO:_display_container: 2
2024-08-17 23:38:20,641:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=3006, solver='auto',
                tol=0.0001)
2024-08-17 23:38:20,641:INFO:create_model() successfully completed......................................
2024-08-17 23:38:20,805:INFO:SubProcess create_model() end ==================================
2024-08-17 23:38:20,805:INFO:Creating metrics dataframe
2024-08-17 23:38:20,816:INFO:Initializing Random Forest Classifier
2024-08-17 23:38:20,816:INFO:Total runtime is 0.6465722997983296 minutes
2024-08-17 23:38:20,820:INFO:SubProcess create_model() called ==================================
2024-08-17 23:38:20,820:INFO:Initializing create_model()
2024-08-17 23:38:20,821:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f92177d2c50>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f92405f1660>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-17 23:38:20,821:INFO:Checking exceptions
2024-08-17 23:38:20,821:INFO:Importing libraries
2024-08-17 23:38:20,821:INFO:Copying training dataset
2024-08-17 23:38:20,869:INFO:Defining folds
2024-08-17 23:38:20,870:INFO:Declaring metric variables
2024-08-17 23:38:20,874:INFO:Importing untrained model
2024-08-17 23:38:20,878:INFO:Random Forest Classifier Imported successfully
2024-08-17 23:38:20,887:INFO:Starting cross validation
2024-08-17 23:38:20,890:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-08-17 23:38:47,297:INFO:Calculating mean and std
2024-08-17 23:38:47,299:INFO:Creating metrics dataframe
2024-08-17 23:38:47,300:INFO:Uploading results into container
2024-08-17 23:38:47,301:INFO:Uploading model into container now
2024-08-17 23:38:47,302:INFO:_master_model_container: 5
2024-08-17 23:38:47,302:INFO:_display_container: 2
2024-08-17 23:38:47,302:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=3006, verbose=0,
                       warm_start=False)
2024-08-17 23:38:47,302:INFO:create_model() successfully completed......................................
2024-08-17 23:38:47,465:INFO:SubProcess create_model() end ==================================
2024-08-17 23:38:47,466:INFO:Creating metrics dataframe
2024-08-17 23:38:47,476:INFO:Initializing Linear Discriminant Analysis
2024-08-17 23:38:47,476:INFO:Total runtime is 1.0909133156140645 minutes
2024-08-17 23:38:47,480:INFO:SubProcess create_model() called ==================================
2024-08-17 23:38:47,480:INFO:Initializing create_model()
2024-08-17 23:38:47,481:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f92177d2c50>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f92405f1660>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-17 23:38:47,481:INFO:Checking exceptions
2024-08-17 23:38:47,481:INFO:Importing libraries
2024-08-17 23:38:47,481:INFO:Copying training dataset
2024-08-17 23:38:47,529:INFO:Defining folds
2024-08-17 23:38:47,529:INFO:Declaring metric variables
2024-08-17 23:38:47,533:INFO:Importing untrained model
2024-08-17 23:38:47,538:INFO:Linear Discriminant Analysis Imported successfully
2024-08-17 23:38:47,546:INFO:Starting cross validation
2024-08-17 23:38:47,548:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-08-17 23:39:00,316:INFO:Calculating mean and std
2024-08-17 23:39:00,319:INFO:Creating metrics dataframe
2024-08-17 23:39:00,321:INFO:Uploading results into container
2024-08-17 23:39:00,322:INFO:Uploading model into container now
2024-08-17 23:39:00,322:INFO:_master_model_container: 6
2024-08-17 23:39:00,322:INFO:_display_container: 2
2024-08-17 23:39:00,323:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-08-17 23:39:00,323:INFO:create_model() successfully completed......................................
2024-08-17 23:39:00,499:INFO:SubProcess create_model() end ==================================
2024-08-17 23:39:00,499:INFO:Creating metrics dataframe
2024-08-17 23:39:00,510:INFO:Initializing Extra Trees Classifier
2024-08-17 23:39:00,510:INFO:Total runtime is 1.3081413984298704 minutes
2024-08-17 23:39:00,514:INFO:SubProcess create_model() called ==================================
2024-08-17 23:39:00,515:INFO:Initializing create_model()
2024-08-17 23:39:00,515:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f92177d2c50>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f92405f1660>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-17 23:39:00,515:INFO:Checking exceptions
2024-08-17 23:39:00,516:INFO:Importing libraries
2024-08-17 23:39:00,516:INFO:Copying training dataset
2024-08-17 23:39:00,563:INFO:Defining folds
2024-08-17 23:39:00,563:INFO:Declaring metric variables
2024-08-17 23:39:00,567:INFO:Importing untrained model
2024-08-17 23:39:00,571:INFO:Extra Trees Classifier Imported successfully
2024-08-17 23:39:00,578:INFO:Starting cross validation
2024-08-17 23:39:00,580:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-08-17 23:39:32,552:INFO:Calculating mean and std
2024-08-17 23:39:32,553:INFO:Creating metrics dataframe
2024-08-17 23:39:32,555:INFO:Uploading results into container
2024-08-17 23:39:32,556:INFO:Uploading model into container now
2024-08-17 23:39:32,557:INFO:_master_model_container: 7
2024-08-17 23:39:32,557:INFO:_display_container: 2
2024-08-17 23:39:32,557:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=3006, verbose=0,
                     warm_start=False)
2024-08-17 23:39:32,557:INFO:create_model() successfully completed......................................
2024-08-17 23:39:32,724:INFO:SubProcess create_model() end ==================================
2024-08-17 23:39:32,724:INFO:Creating metrics dataframe
2024-08-17 23:39:32,734:INFO:Initializing Light Gradient Boosting Machine
2024-08-17 23:39:32,734:INFO:Total runtime is 1.8452172676722207 minutes
2024-08-17 23:39:32,739:INFO:SubProcess create_model() called ==================================
2024-08-17 23:39:32,740:INFO:Initializing create_model()
2024-08-17 23:39:32,740:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f92177d2c50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f92405f1660>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-17 23:39:32,740:INFO:Checking exceptions
2024-08-17 23:39:32,740:INFO:Importing libraries
2024-08-17 23:39:32,740:INFO:Copying training dataset
2024-08-17 23:39:32,791:INFO:Defining folds
2024-08-17 23:39:32,791:INFO:Declaring metric variables
2024-08-17 23:39:32,795:INFO:Importing untrained model
2024-08-17 23:39:32,800:INFO:Light Gradient Boosting Machine Imported successfully
2024-08-17 23:39:32,808:INFO:Starting cross validation
2024-08-17 23:39:32,811:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-08-17 23:39:34,521:INFO:[LightGBM] [Info] Number of positive: 63832, number of negative: 63296
2024-08-17 23:39:34,525:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000927 seconds.
2024-08-17 23:39:34,525:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-17 23:39:34,525:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-17 23:39:34,525:INFO:[LightGBM] [Info] Total Bins 114
2024-08-17 23:39:34,525:INFO:[LightGBM] [Info] Number of data points in the train set: 127128, number of used features: 38
2024-08-17 23:39:34,526:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502108 -> initscore=0.008432
2024-08-17 23:39:34,526:INFO:[LightGBM] [Info] Start training from score 0.008432
2024-08-17 23:39:36,427:INFO:[LightGBM] [Info] Number of positive: 63833, number of negative: 63296
2024-08-17 23:39:36,430:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000772 seconds.
2024-08-17 23:39:36,430:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-17 23:39:36,430:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-17 23:39:36,430:INFO:[LightGBM] [Info] Total Bins 112
2024-08-17 23:39:36,431:INFO:[LightGBM] [Info] Number of data points in the train set: 127129, number of used features: 38
2024-08-17 23:39:36,432:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502112 -> initscore=0.008448
2024-08-17 23:39:36,432:INFO:[LightGBM] [Info] Start training from score 0.008448
2024-08-17 23:39:38,506:INFO:[LightGBM] [Info] Number of positive: 63833, number of negative: 63296
2024-08-17 23:39:38,510:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000996 seconds.
2024-08-17 23:39:38,510:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-17 23:39:38,510:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-17 23:39:38,510:INFO:[LightGBM] [Info] Total Bins 111
2024-08-17 23:39:38,510:INFO:[LightGBM] [Info] Number of data points in the train set: 127129, number of used features: 38
2024-08-17 23:39:38,511:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502112 -> initscore=0.008448
2024-08-17 23:39:38,511:INFO:[LightGBM] [Info] Start training from score 0.008448
2024-08-17 23:39:41,037:INFO:[LightGBM] [Info] Number of positive: 63833, number of negative: 63296
2024-08-17 23:39:41,040:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000673 seconds.
2024-08-17 23:39:41,040:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-17 23:39:41,040:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-17 23:39:41,040:INFO:[LightGBM] [Info] Total Bins 112
2024-08-17 23:39:41,040:INFO:[LightGBM] [Info] Number of data points in the train set: 127129, number of used features: 38
2024-08-17 23:39:41,041:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502112 -> initscore=0.008448
2024-08-17 23:39:41,041:INFO:[LightGBM] [Info] Start training from score 0.008448
2024-08-17 23:39:43,432:INFO:[LightGBM] [Info] Number of positive: 63833, number of negative: 63296
2024-08-17 23:39:43,435:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000671 seconds.
2024-08-17 23:39:43,435:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-17 23:39:43,435:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-17 23:39:43,435:INFO:[LightGBM] [Info] Total Bins 112
2024-08-17 23:39:43,435:INFO:[LightGBM] [Info] Number of data points in the train set: 127129, number of used features: 38
2024-08-17 23:39:43,436:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502112 -> initscore=0.008448
2024-08-17 23:39:43,436:INFO:[LightGBM] [Info] Start training from score 0.008448
2024-08-17 23:39:43,874:INFO:Calculating mean and std
2024-08-17 23:39:43,876:INFO:Creating metrics dataframe
2024-08-17 23:39:43,878:INFO:Uploading results into container
2024-08-17 23:39:43,878:INFO:Uploading model into container now
2024-08-17 23:39:43,879:INFO:_master_model_container: 8
2024-08-17 23:39:43,879:INFO:_display_container: 2
2024-08-17 23:39:43,879:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3006, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-08-17 23:39:43,879:INFO:create_model() successfully completed......................................
2024-08-17 23:39:44,050:INFO:SubProcess create_model() end ==================================
2024-08-17 23:39:44,050:INFO:Creating metrics dataframe
2024-08-17 23:39:44,072:INFO:Initializing create_model()
2024-08-17 23:39:44,072:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f92177d2c50>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=3006, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-17 23:39:44,073:INFO:Checking exceptions
2024-08-17 23:39:44,075:INFO:Importing libraries
2024-08-17 23:39:44,075:INFO:Copying training dataset
2024-08-17 23:39:44,121:INFO:Defining folds
2024-08-17 23:39:44,121:INFO:Declaring metric variables
2024-08-17 23:39:44,122:INFO:Importing untrained model
2024-08-17 23:39:44,122:INFO:Declaring custom model
2024-08-17 23:39:44,123:INFO:Random Forest Classifier Imported successfully
2024-08-17 23:39:44,125:INFO:Cross validation set to False
2024-08-17 23:39:44,125:INFO:Fitting Model
2024-08-17 23:39:50,889:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=3006, verbose=0,
                       warm_start=False)
2024-08-17 23:39:50,889:INFO:create_model() successfully completed......................................
2024-08-17 23:39:51,056:INFO:Creating Dashboard logs
2024-08-17 23:39:51,060:INFO:Model: Random Forest Classifier
2024-08-17 23:39:51,113:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 3006, 'verbose': 0, 'warm_start': False}
2024-08-17 23:39:51,339:INFO:Initializing predict_model()
2024-08-17 23:39:51,339:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f92177d2c50>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=3006, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f9217646560>)
2024-08-17 23:39:51,339:INFO:Checking exceptions
2024-08-17 23:39:51,339:INFO:Preloading libraries
2024-08-17 23:39:52,133:INFO:SubProcess plot_model() called ==================================
2024-08-17 23:39:52,133:INFO:Initializing plot_model()
2024-08-17 23:39:52,133:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=3006, verbose=0,
                       warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmp92lye4_k, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f92177d2c50>, system=False)
2024-08-17 23:39:52,133:INFO:Checking exceptions
2024-08-17 23:39:52,181:INFO:Preloading libraries
2024-08-17 23:39:52,248:INFO:Copying training dataset
2024-08-17 23:39:52,248:INFO:Plot type: auc
2024-08-17 23:39:52,656:INFO:Fitting Model
2024-08-17 23:39:52,664:INFO:Scoring test/hold-out set
2024-08-17 23:39:53,058:INFO:Saving '/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmp92lye4_k/AUC.png'
2024-08-17 23:39:53,291:INFO:Visual Rendered Successfully
2024-08-17 23:39:53,477:INFO:plot_model() successfully completed......................................
2024-08-17 23:39:53,489:INFO:Initializing plot_model()
2024-08-17 23:39:53,489:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=3006, verbose=0,
                       warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmp92lye4_k, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f92177d2c50>, system=False)
2024-08-17 23:39:53,489:INFO:Checking exceptions
2024-08-17 23:39:53,535:INFO:Preloading libraries
2024-08-17 23:39:53,598:INFO:Copying training dataset
2024-08-17 23:39:53,598:INFO:Plot type: confusion_matrix
2024-08-17 23:39:53,980:INFO:Fitting Model
2024-08-17 23:39:53,984:INFO:Scoring test/hold-out set
2024-08-17 23:39:54,314:INFO:Saving '/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmp92lye4_k/Confusion Matrix.png'
2024-08-17 23:39:54,436:INFO:Visual Rendered Successfully
2024-08-17 23:39:54,599:INFO:plot_model() successfully completed......................................
2024-08-17 23:39:54,614:INFO:Initializing plot_model()
2024-08-17 23:39:54,614:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=3006, verbose=0,
                       warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmp92lye4_k, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f92177d2c50>, system=False)
2024-08-17 23:39:54,614:INFO:Checking exceptions
2024-08-17 23:39:54,660:INFO:Preloading libraries
2024-08-17 23:39:54,722:INFO:Copying training dataset
2024-08-17 23:39:54,722:INFO:Plot type: feature
2024-08-17 23:39:54,723:WARNING:No coef_ found. Trying feature_importances_
2024-08-17 23:39:54,906:INFO:Saving '/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmp92lye4_k/Feature Importance.png'
2024-08-17 23:39:55,061:INFO:Visual Rendered Successfully
2024-08-17 23:39:55,232:INFO:plot_model() successfully completed......................................
2024-08-17 23:39:55,264:INFO:SubProcess plot_model() end ==================================
2024-08-17 23:39:55,678:INFO:Creating Dashboard logs
2024-08-17 23:39:55,682:INFO:Model: Extra Trees Classifier
2024-08-17 23:39:55,714:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 3006, 'verbose': 0, 'warm_start': False}
2024-08-17 23:39:56,235:INFO:Creating Dashboard logs
2024-08-17 23:39:56,239:INFO:Model: Decision Tree Classifier
2024-08-17 23:39:56,285:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 3006, 'splitter': 'best'}
2024-08-17 23:39:56,781:INFO:Creating Dashboard logs
2024-08-17 23:39:56,786:INFO:Model: Light Gradient Boosting Machine
2024-08-17 23:39:56,831:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 3006, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2024-08-17 23:39:57,467:INFO:Creating Dashboard logs
2024-08-17 23:39:57,473:INFO:Model: Logistic Regression
2024-08-17 23:39:57,515:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 3006, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2024-08-17 23:39:58,030:INFO:Creating Dashboard logs
2024-08-17 23:39:58,035:INFO:Model: Linear Discriminant Analysis
2024-08-17 23:39:58,086:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2024-08-17 23:39:58,578:INFO:Creating Dashboard logs
2024-08-17 23:39:58,583:INFO:Model: Ridge Classifier
2024-08-17 23:39:58,614:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 3006, 'solver': 'auto', 'tol': 0.0001}
2024-08-17 23:39:59,130:INFO:Creating Dashboard logs
2024-08-17 23:39:59,135:INFO:Model: Naive Bayes
2024-08-17 23:39:59,169:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2024-08-17 23:39:59,700:INFO:_master_model_container: 8
2024-08-17 23:39:59,700:INFO:_display_container: 2
2024-08-17 23:39:59,701:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=3006, verbose=0,
                       warm_start=False)
2024-08-17 23:39:59,701:INFO:compare_models() successfully completed......................................
2024-08-17 23:56:32,299:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:56:32,299:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:56:32,299:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-17 23:56:32,299:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:03:02,450:INFO:PyCaret ClassificationExperiment
2024-08-18 00:03:02,450:INFO:Logging name: codepro_model_exp01
2024-08-18 00:03:02,450:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-08-18 00:03:02,451:INFO:version 3.3.2
2024-08-18 00:03:02,451:INFO:Initializing setup()
2024-08-18 00:03:02,451:INFO:self.USI: f5c2
2024-08-18 00:03:02,451:INFO:self._variable_keys: {'log_plots_param', 'gpu_param', 'exp_id', 'fold_generator', 'pipeline', 'seed', '_available_plots', 'memory', 'html_param', 'y', 'fix_imbalance', 'is_multiclass', 'idx', 'y_test', 'n_jobs_param', 'X_test', 'target_param', 'fold_groups_param', 'exp_name_log', '_ml_usecase', 'gpu_n_jobs_param', 'logging_param', 'y_train', 'fold_shuffle_param', 'USI', 'X_train', 'data', 'X'}
2024-08-18 00:03:02,451:INFO:Checking environment
2024-08-18 00:03:02,451:INFO:python_version: 3.10.9
2024-08-18 00:03:02,451:INFO:python_build: ('main', 'Mar  1 2023 12:33:47')
2024-08-18 00:03:02,451:INFO:machine: x86_64
2024-08-18 00:03:02,451:INFO:platform: macOS-10.16-x86_64-i386-64bit
2024-08-18 00:03:02,452:INFO:Memory: svmem(total=17179869184, available=6009151488, percent=65.0, used=10035912704, free=267792384, active=5746036736, inactive=5737635840, wired=4289875968)
2024-08-18 00:03:02,452:INFO:Physical Core: 6
2024-08-18 00:03:02,452:INFO:Logical Core: 12
2024-08-18 00:03:02,452:INFO:Checking libraries
2024-08-18 00:03:02,452:INFO:System:
2024-08-18 00:03:02,452:INFO:    python: 3.10.9 (main, Mar  1 2023, 12:33:47) [Clang 14.0.6 ]
2024-08-18 00:03:02,452:INFO:executable: /Users/I500955/anaconda3/bin/python
2024-08-18 00:03:02,453:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2024-08-18 00:03:02,453:INFO:PyCaret required dependencies:
2024-08-18 00:03:02,458:INFO:                 pip: 22.3.1
2024-08-18 00:03:02,458:INFO:          setuptools: 65.6.3
2024-08-18 00:03:02,458:INFO:             pycaret: 3.3.2
2024-08-18 00:03:02,458:INFO:             IPython: 8.10.0
2024-08-18 00:03:02,458:INFO:          ipywidgets: 7.6.5
2024-08-18 00:03:02,459:INFO:                tqdm: 4.64.1
2024-08-18 00:03:02,459:INFO:               numpy: 1.23.5
2024-08-18 00:03:02,459:INFO:              pandas: 2.2.2
2024-08-18 00:03:02,459:INFO:              jinja2: 3.1.2
2024-08-18 00:03:02,459:INFO:               scipy: 1.10.0
2024-08-18 00:03:02,459:INFO:              joblib: 1.3.2
2024-08-18 00:03:02,459:INFO:             sklearn: 1.4.2
2024-08-18 00:03:02,459:INFO:                pyod: 2.0.1
2024-08-18 00:03:02,459:INFO:            imblearn: 0.12.3
2024-08-18 00:03:02,459:INFO:   category_encoders: 2.6.3
2024-08-18 00:03:02,459:INFO:            lightgbm: 4.5.0
2024-08-18 00:03:02,459:INFO:               numba: 0.56.4
2024-08-18 00:03:02,459:INFO:            requests: 2.28.1
2024-08-18 00:03:02,459:INFO:          matplotlib: 3.7.0
2024-08-18 00:03:02,459:INFO:          scikitplot: 0.3.7
2024-08-18 00:03:02,459:INFO:         yellowbrick: 1.5
2024-08-18 00:03:02,459:INFO:              plotly: 5.23.0
2024-08-18 00:03:02,459:INFO:    plotly-resampler: Not installed
2024-08-18 00:03:02,459:INFO:             kaleido: 0.2.1
2024-08-18 00:03:02,459:INFO:           schemdraw: 0.15
2024-08-18 00:03:02,459:INFO:         statsmodels: 0.13.5
2024-08-18 00:03:02,459:INFO:              sktime: 0.26.0
2024-08-18 00:03:02,460:INFO:               tbats: 1.1.3
2024-08-18 00:03:02,460:INFO:            pmdarima: 2.0.4
2024-08-18 00:03:02,460:INFO:              psutil: 5.9.0
2024-08-18 00:03:02,460:INFO:          markupsafe: 2.1.1
2024-08-18 00:03:02,460:INFO:             pickle5: Not installed
2024-08-18 00:03:02,460:INFO:         cloudpickle: 3.0.0
2024-08-18 00:03:02,460:INFO:         deprecation: 2.1.0
2024-08-18 00:03:02,460:INFO:              xxhash: 3.5.0
2024-08-18 00:03:02,460:INFO:           wurlitzer: 3.0.2
2024-08-18 00:03:02,460:INFO:PyCaret optional dependencies:
2024-08-18 00:03:02,480:INFO:                shap: Not installed
2024-08-18 00:03:02,480:INFO:           interpret: Not installed
2024-08-18 00:03:02,480:INFO:                umap: Not installed
2024-08-18 00:03:02,480:INFO:     ydata_profiling: 4.9.0
2024-08-18 00:03:02,480:INFO:  explainerdashboard: Not installed
2024-08-18 00:03:02,480:INFO:             autoviz: Not installed
2024-08-18 00:03:02,480:INFO:           fairlearn: Not installed
2024-08-18 00:03:02,480:INFO:          deepchecks: Not installed
2024-08-18 00:03:02,480:INFO:             xgboost: Not installed
2024-08-18 00:03:02,480:INFO:            catboost: Not installed
2024-08-18 00:03:02,480:INFO:              kmodes: Not installed
2024-08-18 00:03:02,480:INFO:             mlxtend: Not installed
2024-08-18 00:03:02,480:INFO:       statsforecast: Not installed
2024-08-18 00:03:02,480:INFO:        tune_sklearn: Not installed
2024-08-18 00:03:02,480:INFO:                 ray: Not installed
2024-08-18 00:03:02,480:INFO:            hyperopt: Not installed
2024-08-18 00:03:02,480:INFO:              optuna: Not installed
2024-08-18 00:03:02,481:INFO:               skopt: 0.10.2
2024-08-18 00:03:02,481:INFO:              mlflow: 2.15.1
2024-08-18 00:03:02,481:INFO:              gradio: Not installed
2024-08-18 00:03:02,481:INFO:             fastapi: Not installed
2024-08-18 00:03:02,481:INFO:             uvicorn: Not installed
2024-08-18 00:03:02,481:INFO:              m2cgen: Not installed
2024-08-18 00:03:02,481:INFO:           evidently: Not installed
2024-08-18 00:03:02,481:INFO:               fugue: Not installed
2024-08-18 00:03:02,481:INFO:           streamlit: Not installed
2024-08-18 00:03:02,481:INFO:             prophet: Not installed
2024-08-18 00:03:02,481:INFO:None
2024-08-18 00:03:02,481:INFO:Set up GPU usage.
2024-08-18 00:03:02,481:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:03:02,481:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2024-08-18 00:03:02,481:INFO:Set up data.
2024-08-18 00:03:02,572:INFO:Set up folding strategy.
2024-08-18 00:03:02,573:INFO:Set up train/test split.
2024-08-18 00:03:02,695:INFO:Set up index.
2024-08-18 00:03:02,707:INFO:Assigning column types.
2024-08-18 00:03:02,761:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-08-18 00:03:02,761:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:03:02,805:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-18 00:03:02,805:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:03:02,827:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:03:02,828:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-18 00:03:02,828:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:03:02,853:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:03:02,858:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:03:02,872:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-18 00:03:02,907:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-18 00:03:02,908:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:03:02,952:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-18 00:03:02,952:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:03:02,953:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:03:02,953:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-18 00:03:02,953:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:03:02,975:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:03:02,979:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:03:02,984:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-18 00:03:02,988:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-18 00:03:02,988:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-08-18 00:03:02,988:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:03:03,032:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:03:03,032:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:03:03,033:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-18 00:03:03,033:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:03:03,054:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:03:03,058:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:03:03,059:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-18 00:03:03,062:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-18 00:03:03,062:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:03:03,102:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:03:03,103:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:03:03,103:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-18 00:03:03,104:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:03:03,124:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:03:03,128:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:03:03,129:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-18 00:03:03,134:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-18 00:03:03,134:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-08-18 00:03:03,134:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:03:03,180:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:03:03,180:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:03:03,181:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:03:03,204:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:03:03,208:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:03:03,209:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-18 00:03:03,212:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-18 00:03:03,213:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:03:03,260:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:03:03,261:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:03:03,261:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:03:03,285:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:03:03,289:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:03:03,290:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-18 00:03:03,293:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-18 00:03:03,303:INFO:Preparing preprocessing pipeline...
2024-08-18 00:03:03,312:INFO:Set up simple imputation.
2024-08-18 00:03:03,342:INFO:Set up encoding of categorical features.
2024-08-18 00:03:04,134:INFO:Finished creating preprocessing pipeline.
2024-08-18 00:03:04,141:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['city_tier',
                                             'total_leads_droppped',
                                             'referred_lead',
                                             'assistance_interaction',
                                             'career_interaction',
                                             'payment_interaction',
                                             'social_interaction',
                                             'syllabus_interaction'],
                                    transformer=SimpleImpute...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-08-18 00:03:04,141:INFO:Creating final display dataframe.
2024-08-18 00:03:05,871:INFO:Setup _display_container:                     Description                Value
0                    Session id                  123
1                        Target    app_complete_flag
2                   Target type               Binary
3           Original data shape         (227016, 12)
4        Transformed data shape         (227016, 44)
5   Transformed train set shape         (158911, 44)
6    Transformed test set shape          (68105, 44)
7              Numeric features                    8
8          Categorical features                    3
9                    Preprocess                 True
10              Imputation type               simple
11           Numeric imputation                 mean
12       Categorical imputation                 mode
13     Maximum one-hot encoding                   25
14              Encoding method                 None
15               Fold Generator      StratifiedKFold
16                  Fold Number                   10
17                     CPU Jobs                   -1
18                      Use GPU                 True
19               Log Experiment         MlflowLogger
20              Experiment Name  codepro_model_exp01
21                          USI                 f5c2
2024-08-18 00:03:05,882:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:03:05,932:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:03:05,933:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:03:05,933:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:03:05,954:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:03:05,958:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:03:05,959:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-18 00:03:05,963:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-18 00:03:05,963:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:03:06,012:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:03:06,013:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:03:06,013:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:03:06,038:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:03:06,044:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:03:06,045:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-18 00:03:06,048:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-18 00:03:06,050:INFO:Logging experiment in loggers
2024-08-18 00:03:10,317:INFO:SubProcess save_model() called ==================================
2024-08-18 00:03:10,330:INFO:Initializing save_model()
2024-08-18 00:03:10,330:INFO:save_model(model=Pipeline(memory=FastMemory(location=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['city_tier',
                                             'total_leads_droppped',
                                             'referred_lead',
                                             'assistance_interaction',
                                             'career_interaction',
                                             'payment_interaction',
                                             'social_interaction',
                                             'syllabus_interaction'],
                                    transformer=SimpleImpute...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), model_name=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmpa3b_uiz9/Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['city_tier',
                                             'total_leads_droppped',
                                             'referred_lead',
                                             'assistance_interaction',
                                             'career_interaction',
                                             'payment_interaction',
                                             'social_interaction',
                                             'syllabus_interaction'],
                                    transformer=SimpleImpute...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-08-18 00:03:10,330:INFO:Adding model into prep_pipe
2024-08-18 00:03:10,330:WARNING:Only Model saved as it was a pipeline.
2024-08-18 00:03:10,340:INFO:/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmpa3b_uiz9/Transformation Pipeline.pkl saved in current working directory
2024-08-18 00:03:10,346:INFO:Pipeline(memory=FastMemory(location=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['city_tier',
                                             'total_leads_droppped',
                                             'referred_lead',
                                             'assistance_interaction',
                                             'career_interaction',
                                             'payment_interaction',
                                             'social_interaction',
                                             'syllabus_interaction'],
                                    transformer=SimpleImpute...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-08-18 00:03:10,346:INFO:save_model() successfully completed......................................
2024-08-18 00:03:10,734:INFO:SubProcess save_model() end ==================================
2024-08-18 00:03:11,894:INFO:setup() successfully completed in 3.66s...............
2024-08-18 00:03:22,558:INFO:Initializing compare_models()
2024-08-18 00:03:22,559:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f805dfa99f0>, include=None, fold=5, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f805dfa99f0>, 'include': None, 'exclude': ['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada'], 'fold': 5, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada'])
2024-08-18 00:03:22,559:INFO:Checking exceptions
2024-08-18 00:03:22,621:INFO:Preparing display monitor
2024-08-18 00:03:22,684:INFO:Initializing Logistic Regression
2024-08-18 00:03:22,685:INFO:Total runtime is 8.551279703776042e-06 minutes
2024-08-18 00:03:22,690:INFO:SubProcess create_model() called ==================================
2024-08-18 00:03:22,690:INFO:Initializing create_model()
2024-08-18 00:03:22,691:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f805dfa99f0>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f805e3ccf10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-18 00:03:22,691:INFO:Checking exceptions
2024-08-18 00:03:22,691:INFO:Importing libraries
2024-08-18 00:03:22,691:INFO:Copying training dataset
2024-08-18 00:03:22,784:INFO:Defining folds
2024-08-18 00:03:22,784:INFO:Declaring metric variables
2024-08-18 00:03:22,788:INFO:Importing untrained model
2024-08-18 00:03:22,791:INFO:Logistic Regression Imported successfully
2024-08-18 00:03:22,798:INFO:Starting cross validation
2024-08-18 00:03:22,801:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-08-18 00:03:33,433:INFO:Calculating mean and std
2024-08-18 00:03:33,434:INFO:Creating metrics dataframe
2024-08-18 00:03:33,436:INFO:Uploading results into container
2024-08-18 00:03:33,436:INFO:Uploading model into container now
2024-08-18 00:03:33,437:INFO:_master_model_container: 1
2024-08-18 00:03:33,437:INFO:_display_container: 2
2024-08-18 00:03:33,438:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-08-18 00:03:33,438:INFO:create_model() successfully completed......................................
2024-08-18 00:03:33,575:INFO:SubProcess create_model() end ==================================
2024-08-18 00:03:33,575:INFO:Creating metrics dataframe
2024-08-18 00:03:33,584:INFO:Initializing Naive Bayes
2024-08-18 00:03:33,584:INFO:Total runtime is 0.18165730237960817 minutes
2024-08-18 00:03:33,588:INFO:SubProcess create_model() called ==================================
2024-08-18 00:03:33,588:INFO:Initializing create_model()
2024-08-18 00:03:33,588:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f805dfa99f0>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f805e3ccf10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-18 00:03:33,588:INFO:Checking exceptions
2024-08-18 00:03:33,588:INFO:Importing libraries
2024-08-18 00:03:33,588:INFO:Copying training dataset
2024-08-18 00:03:33,675:INFO:Defining folds
2024-08-18 00:03:33,675:INFO:Declaring metric variables
2024-08-18 00:03:33,679:INFO:Importing untrained model
2024-08-18 00:03:33,682:INFO:Naive Bayes Imported successfully
2024-08-18 00:03:33,689:INFO:Starting cross validation
2024-08-18 00:03:33,691:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-08-18 00:03:40,207:INFO:Calculating mean and std
2024-08-18 00:03:40,208:INFO:Creating metrics dataframe
2024-08-18 00:03:40,210:INFO:Uploading results into container
2024-08-18 00:03:40,210:INFO:Uploading model into container now
2024-08-18 00:03:40,211:INFO:_master_model_container: 2
2024-08-18 00:03:40,211:INFO:_display_container: 2
2024-08-18 00:03:40,211:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-08-18 00:03:40,211:INFO:create_model() successfully completed......................................
2024-08-18 00:03:40,326:INFO:SubProcess create_model() end ==================================
2024-08-18 00:03:40,326:INFO:Creating metrics dataframe
2024-08-18 00:03:40,336:INFO:Initializing Decision Tree Classifier
2024-08-18 00:03:40,336:INFO:Total runtime is 0.294193955262502 minutes
2024-08-18 00:03:40,340:INFO:SubProcess create_model() called ==================================
2024-08-18 00:03:40,341:INFO:Initializing create_model()
2024-08-18 00:03:40,341:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f805dfa99f0>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f805e3ccf10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-18 00:03:40,341:INFO:Checking exceptions
2024-08-18 00:03:40,341:INFO:Importing libraries
2024-08-18 00:03:40,342:INFO:Copying training dataset
2024-08-18 00:03:40,423:INFO:Defining folds
2024-08-18 00:03:40,423:INFO:Declaring metric variables
2024-08-18 00:03:40,427:INFO:Importing untrained model
2024-08-18 00:03:40,430:INFO:Decision Tree Classifier Imported successfully
2024-08-18 00:03:40,437:INFO:Starting cross validation
2024-08-18 00:03:40,439:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-08-18 00:03:48,912:INFO:Calculating mean and std
2024-08-18 00:03:48,913:INFO:Creating metrics dataframe
2024-08-18 00:03:48,915:INFO:Uploading results into container
2024-08-18 00:03:48,915:INFO:Uploading model into container now
2024-08-18 00:03:48,916:INFO:_master_model_container: 3
2024-08-18 00:03:48,916:INFO:_display_container: 2
2024-08-18 00:03:48,916:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2024-08-18 00:03:48,916:INFO:create_model() successfully completed......................................
2024-08-18 00:03:49,052:INFO:SubProcess create_model() end ==================================
2024-08-18 00:03:49,052:INFO:Creating metrics dataframe
2024-08-18 00:03:49,063:INFO:Initializing Ridge Classifier
2024-08-18 00:03:49,063:INFO:Total runtime is 0.4396416703859965 minutes
2024-08-18 00:03:49,067:INFO:SubProcess create_model() called ==================================
2024-08-18 00:03:49,068:INFO:Initializing create_model()
2024-08-18 00:03:49,068:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f805dfa99f0>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f805e3ccf10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-18 00:03:49,068:INFO:Checking exceptions
2024-08-18 00:03:49,068:INFO:Importing libraries
2024-08-18 00:03:49,068:INFO:Copying training dataset
2024-08-18 00:03:49,162:INFO:Defining folds
2024-08-18 00:03:49,162:INFO:Declaring metric variables
2024-08-18 00:03:49,166:INFO:Importing untrained model
2024-08-18 00:03:49,170:INFO:Ridge Classifier Imported successfully
2024-08-18 00:03:49,178:INFO:Starting cross validation
2024-08-18 00:03:49,181:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-08-18 00:03:55,990:INFO:Calculating mean and std
2024-08-18 00:03:55,992:INFO:Creating metrics dataframe
2024-08-18 00:03:55,994:INFO:Uploading results into container
2024-08-18 00:03:55,995:INFO:Uploading model into container now
2024-08-18 00:03:55,995:INFO:_master_model_container: 4
2024-08-18 00:03:55,996:INFO:_display_container: 2
2024-08-18 00:03:55,996:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-08-18 00:03:55,996:INFO:create_model() successfully completed......................................
2024-08-18 00:03:56,110:INFO:SubProcess create_model() end ==================================
2024-08-18 00:03:56,110:INFO:Creating metrics dataframe
2024-08-18 00:03:56,119:INFO:Initializing Random Forest Classifier
2024-08-18 00:03:56,120:INFO:Total runtime is 0.5572535196940104 minutes
2024-08-18 00:03:56,124:INFO:SubProcess create_model() called ==================================
2024-08-18 00:03:56,125:INFO:Initializing create_model()
2024-08-18 00:03:56,125:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f805dfa99f0>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f805e3ccf10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-18 00:03:56,125:INFO:Checking exceptions
2024-08-18 00:03:56,125:INFO:Importing libraries
2024-08-18 00:03:56,126:INFO:Copying training dataset
2024-08-18 00:03:56,208:INFO:Defining folds
2024-08-18 00:03:56,208:INFO:Declaring metric variables
2024-08-18 00:03:56,212:INFO:Importing untrained model
2024-08-18 00:03:56,216:INFO:Random Forest Classifier Imported successfully
2024-08-18 00:03:56,223:INFO:Starting cross validation
2024-08-18 00:03:56,226:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-08-18 00:04:24,647:INFO:Calculating mean and std
2024-08-18 00:04:24,649:INFO:Creating metrics dataframe
2024-08-18 00:04:24,651:INFO:Uploading results into container
2024-08-18 00:04:24,652:INFO:Uploading model into container now
2024-08-18 00:04:24,652:INFO:_master_model_container: 5
2024-08-18 00:04:24,652:INFO:_display_container: 2
2024-08-18 00:04:24,653:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-08-18 00:04:24,653:INFO:create_model() successfully completed......................................
2024-08-18 00:04:24,769:INFO:SubProcess create_model() end ==================================
2024-08-18 00:04:24,769:INFO:Creating metrics dataframe
2024-08-18 00:04:24,779:INFO:Initializing Linear Discriminant Analysis
2024-08-18 00:04:24,779:INFO:Total runtime is 1.0349074522654216 minutes
2024-08-18 00:04:24,783:INFO:SubProcess create_model() called ==================================
2024-08-18 00:04:24,783:INFO:Initializing create_model()
2024-08-18 00:04:24,783:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f805dfa99f0>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f805e3ccf10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-18 00:04:24,783:INFO:Checking exceptions
2024-08-18 00:04:24,783:INFO:Importing libraries
2024-08-18 00:04:24,784:INFO:Copying training dataset
2024-08-18 00:04:24,910:INFO:Defining folds
2024-08-18 00:04:24,910:INFO:Declaring metric variables
2024-08-18 00:04:24,914:INFO:Importing untrained model
2024-08-18 00:04:24,918:INFO:Linear Discriminant Analysis Imported successfully
2024-08-18 00:04:24,927:INFO:Starting cross validation
2024-08-18 00:04:24,930:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-08-18 00:04:36,314:INFO:Calculating mean and std
2024-08-18 00:04:36,316:INFO:Creating metrics dataframe
2024-08-18 00:04:36,319:INFO:Uploading results into container
2024-08-18 00:04:36,319:INFO:Uploading model into container now
2024-08-18 00:04:36,319:INFO:_master_model_container: 6
2024-08-18 00:04:36,320:INFO:_display_container: 2
2024-08-18 00:04:36,320:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-08-18 00:04:36,320:INFO:create_model() successfully completed......................................
2024-08-18 00:04:36,447:INFO:SubProcess create_model() end ==================================
2024-08-18 00:04:36,447:INFO:Creating metrics dataframe
2024-08-18 00:04:36,460:INFO:Initializing Extra Trees Classifier
2024-08-18 00:04:36,460:INFO:Total runtime is 1.2295936187108358 minutes
2024-08-18 00:04:36,464:INFO:SubProcess create_model() called ==================================
2024-08-18 00:04:36,465:INFO:Initializing create_model()
2024-08-18 00:04:36,465:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f805dfa99f0>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f805e3ccf10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-18 00:04:36,465:INFO:Checking exceptions
2024-08-18 00:04:36,465:INFO:Importing libraries
2024-08-18 00:04:36,466:INFO:Copying training dataset
2024-08-18 00:04:36,555:INFO:Defining folds
2024-08-18 00:04:36,556:INFO:Declaring metric variables
2024-08-18 00:04:36,559:INFO:Importing untrained model
2024-08-18 00:04:36,563:INFO:Extra Trees Classifier Imported successfully
2024-08-18 00:04:36,571:INFO:Starting cross validation
2024-08-18 00:04:36,574:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-08-18 00:05:04,807:INFO:Calculating mean and std
2024-08-18 00:05:04,809:INFO:Creating metrics dataframe
2024-08-18 00:05:04,811:INFO:Uploading results into container
2024-08-18 00:05:04,811:INFO:Uploading model into container now
2024-08-18 00:05:04,812:INFO:_master_model_container: 7
2024-08-18 00:05:04,812:INFO:_display_container: 2
2024-08-18 00:05:04,812:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2024-08-18 00:05:04,812:INFO:create_model() successfully completed......................................
2024-08-18 00:05:04,929:INFO:SubProcess create_model() end ==================================
2024-08-18 00:05:04,929:INFO:Creating metrics dataframe
2024-08-18 00:05:04,942:INFO:Initializing Light Gradient Boosting Machine
2024-08-18 00:05:04,942:INFO:Total runtime is 1.7042979677518209 minutes
2024-08-18 00:05:04,948:INFO:SubProcess create_model() called ==================================
2024-08-18 00:05:04,949:INFO:Initializing create_model()
2024-08-18 00:05:04,949:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f805dfa99f0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f805e3ccf10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-18 00:05:04,949:INFO:Checking exceptions
2024-08-18 00:05:04,950:INFO:Importing libraries
2024-08-18 00:05:04,950:INFO:Copying training dataset
2024-08-18 00:05:05,033:INFO:Defining folds
2024-08-18 00:05:05,033:INFO:Declaring metric variables
2024-08-18 00:05:05,037:INFO:Importing untrained model
2024-08-18 00:05:05,041:INFO:Light Gradient Boosting Machine Imported successfully
2024-08-18 00:05:05,047:INFO:Starting cross validation
2024-08-18 00:05:05,050:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-08-18 00:05:06,101:INFO:[LightGBM] [Info] Number of positive: 63832, number of negative: 63296
2024-08-18 00:05:06,109:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001746 seconds.
2024-08-18 00:05:06,109:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-18 00:05:06,109:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-18 00:05:06,109:INFO:[LightGBM] [Info] Total Bins 149
2024-08-18 00:05:06,109:INFO:[LightGBM] [Info] Number of data points in the train set: 127128, number of used features: 41
2024-08-18 00:05:06,111:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502108 -> initscore=0.008432
2024-08-18 00:05:06,111:INFO:[LightGBM] [Info] Start training from score 0.008432
2024-08-18 00:05:07,810:INFO:[LightGBM] [Info] Number of positive: 63833, number of negative: 63296
2024-08-18 00:05:07,821:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002305 seconds.
2024-08-18 00:05:07,821:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-18 00:05:07,821:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-18 00:05:07,821:INFO:[LightGBM] [Info] Total Bins 152
2024-08-18 00:05:07,821:INFO:[LightGBM] [Info] Number of data points in the train set: 127129, number of used features: 41
2024-08-18 00:05:07,822:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502112 -> initscore=0.008448
2024-08-18 00:05:07,823:INFO:[LightGBM] [Info] Start training from score 0.008448
2024-08-18 00:05:09,557:INFO:[LightGBM] [Info] Number of positive: 63833, number of negative: 63296
2024-08-18 00:05:09,569:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002679 seconds.
2024-08-18 00:05:09,569:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-18 00:05:09,569:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-18 00:05:09,570:INFO:[LightGBM] [Info] Total Bins 159
2024-08-18 00:05:09,570:INFO:[LightGBM] [Info] Number of data points in the train set: 127129, number of used features: 42
2024-08-18 00:05:09,572:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502112 -> initscore=0.008448
2024-08-18 00:05:09,572:INFO:[LightGBM] [Info] Start training from score 0.008448
2024-08-18 00:05:11,095:INFO:[LightGBM] [Info] Number of positive: 63833, number of negative: 63296
2024-08-18 00:05:11,105:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001899 seconds.
2024-08-18 00:05:11,105:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-18 00:05:11,105:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-18 00:05:11,105:INFO:[LightGBM] [Info] Total Bins 162
2024-08-18 00:05:11,105:INFO:[LightGBM] [Info] Number of data points in the train set: 127129, number of used features: 42
2024-08-18 00:05:11,106:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502112 -> initscore=0.008448
2024-08-18 00:05:11,107:INFO:[LightGBM] [Info] Start training from score 0.008448
2024-08-18 00:05:12,609:INFO:[LightGBM] [Info] Number of positive: 63833, number of negative: 63296
2024-08-18 00:05:12,617:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001718 seconds.
2024-08-18 00:05:12,617:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-18 00:05:12,617:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-18 00:05:12,617:INFO:[LightGBM] [Info] Total Bins 152
2024-08-18 00:05:12,617:INFO:[LightGBM] [Info] Number of data points in the train set: 127129, number of used features: 41
2024-08-18 00:05:12,619:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502112 -> initscore=0.008448
2024-08-18 00:05:12,619:INFO:[LightGBM] [Info] Start training from score 0.008448
2024-08-18 00:05:13,091:INFO:Calculating mean and std
2024-08-18 00:05:13,092:INFO:Creating metrics dataframe
2024-08-18 00:05:13,094:INFO:Uploading results into container
2024-08-18 00:05:13,095:INFO:Uploading model into container now
2024-08-18 00:05:13,095:INFO:_master_model_container: 8
2024-08-18 00:05:13,096:INFO:_display_container: 2
2024-08-18 00:05:13,096:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-08-18 00:05:13,096:INFO:create_model() successfully completed......................................
2024-08-18 00:05:13,212:INFO:SubProcess create_model() end ==================================
2024-08-18 00:05:13,213:INFO:Creating metrics dataframe
2024-08-18 00:05:13,233:INFO:Initializing create_model()
2024-08-18 00:05:13,233:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f805dfa99f0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-18 00:05:13,233:INFO:Checking exceptions
2024-08-18 00:05:13,235:INFO:Importing libraries
2024-08-18 00:05:13,235:INFO:Copying training dataset
2024-08-18 00:05:13,313:INFO:Defining folds
2024-08-18 00:05:13,314:INFO:Declaring metric variables
2024-08-18 00:05:13,314:INFO:Importing untrained model
2024-08-18 00:05:13,314:INFO:Declaring custom model
2024-08-18 00:05:13,315:INFO:Random Forest Classifier Imported successfully
2024-08-18 00:05:13,316:INFO:Cross validation set to False
2024-08-18 00:05:13,317:INFO:Fitting Model
2024-08-18 00:05:20,269:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-08-18 00:05:20,269:INFO:create_model() successfully completed......................................
2024-08-18 00:05:20,399:INFO:Creating Dashboard logs
2024-08-18 00:05:20,404:INFO:Model: Random Forest Classifier
2024-08-18 00:05:20,473:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2024-08-18 00:05:20,722:INFO:Initializing predict_model()
2024-08-18 00:05:20,722:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f805dfa99f0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f805fe42dd0>)
2024-08-18 00:05:20,722:INFO:Checking exceptions
2024-08-18 00:05:20,722:INFO:Preloading libraries
2024-08-18 00:05:21,670:INFO:SubProcess plot_model() called ==================================
2024-08-18 00:05:21,671:INFO:Initializing plot_model()
2024-08-18 00:05:21,671:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmploy9klo4, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f805dfa99f0>, system=False)
2024-08-18 00:05:21,671:INFO:Checking exceptions
2024-08-18 00:05:21,733:INFO:Preloading libraries
2024-08-18 00:05:21,797:INFO:Copying training dataset
2024-08-18 00:05:21,797:INFO:Plot type: auc
2024-08-18 00:05:22,310:INFO:Fitting Model
2024-08-18 00:05:22,317:INFO:Scoring test/hold-out set
2024-08-18 00:05:22,703:INFO:Saving '/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmploy9klo4/AUC.png'
2024-08-18 00:05:23,023:INFO:Visual Rendered Successfully
2024-08-18 00:05:23,145:INFO:plot_model() successfully completed......................................
2024-08-18 00:05:23,168:INFO:Initializing plot_model()
2024-08-18 00:05:23,168:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmploy9klo4, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f805dfa99f0>, system=False)
2024-08-18 00:05:23,168:INFO:Checking exceptions
2024-08-18 00:05:23,230:INFO:Preloading libraries
2024-08-18 00:05:23,292:INFO:Copying training dataset
2024-08-18 00:05:23,292:INFO:Plot type: confusion_matrix
2024-08-18 00:05:23,794:INFO:Fitting Model
2024-08-18 00:05:23,798:INFO:Scoring test/hold-out set
2024-08-18 00:05:24,148:INFO:Saving '/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmploy9klo4/Confusion Matrix.png'
2024-08-18 00:05:24,263:INFO:Visual Rendered Successfully
2024-08-18 00:05:24,383:INFO:plot_model() successfully completed......................................
2024-08-18 00:05:24,400:INFO:Initializing plot_model()
2024-08-18 00:05:24,400:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmploy9klo4, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f805dfa99f0>, system=False)
2024-08-18 00:05:24,400:INFO:Checking exceptions
2024-08-18 00:05:24,465:INFO:Preloading libraries
2024-08-18 00:05:24,527:INFO:Copying training dataset
2024-08-18 00:05:24,527:INFO:Plot type: feature
2024-08-18 00:05:24,528:WARNING:No coef_ found. Trying feature_importances_
2024-08-18 00:05:24,743:INFO:Saving '/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmploy9klo4/Feature Importance.png'
2024-08-18 00:05:24,916:INFO:Visual Rendered Successfully
2024-08-18 00:05:25,049:INFO:plot_model() successfully completed......................................
2024-08-18 00:05:25,067:INFO:SubProcess plot_model() end ==================================
2024-08-18 00:05:33,042:INFO:Creating Dashboard logs
2024-08-18 00:05:33,047:INFO:Model: Naive Bayes
2024-08-18 00:05:33,091:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2024-08-18 00:05:33,543:INFO:Creating Dashboard logs
2024-08-18 00:05:33,548:INFO:Model: Extra Trees Classifier
2024-08-18 00:05:33,592:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2024-08-18 00:05:34,071:INFO:Creating Dashboard logs
2024-08-18 00:05:34,076:INFO:Model: Decision Tree Classifier
2024-08-18 00:05:34,121:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 123, 'splitter': 'best'}
2024-08-18 00:05:34,592:INFO:Creating Dashboard logs
2024-08-18 00:05:34,597:INFO:Model: Logistic Regression
2024-08-18 00:05:34,639:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 123, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2024-08-18 00:05:35,096:INFO:Creating Dashboard logs
2024-08-18 00:05:35,103:INFO:Model: Light Gradient Boosting Machine
2024-08-18 00:05:35,139:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2024-08-18 00:05:35,620:INFO:Creating Dashboard logs
2024-08-18 00:05:35,625:INFO:Model: Ridge Classifier
2024-08-18 00:05:35,671:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 123, 'solver': 'auto', 'tol': 0.0001}
2024-08-18 00:05:36,111:INFO:Creating Dashboard logs
2024-08-18 00:05:36,116:INFO:Model: Linear Discriminant Analysis
2024-08-18 00:05:36,146:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2024-08-18 00:05:36,626:INFO:_master_model_container: 8
2024-08-18 00:05:36,626:INFO:_display_container: 2
2024-08-18 00:05:36,626:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-08-18 00:05:36,627:INFO:compare_models() successfully completed......................................
2024-08-18 00:06:22,498:INFO:Initializing create_model()
2024-08-18 00:06:22,499:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f805dfa99f0>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-18 00:06:22,499:INFO:Checking exceptions
2024-08-18 00:06:22,520:INFO:Importing libraries
2024-08-18 00:06:22,520:INFO:Copying training dataset
2024-08-18 00:06:22,632:INFO:Defining folds
2024-08-18 00:06:22,633:INFO:Declaring metric variables
2024-08-18 00:06:22,636:INFO:Importing untrained model
2024-08-18 00:06:22,640:INFO:Light Gradient Boosting Machine Imported successfully
2024-08-18 00:06:22,648:INFO:Starting cross validation
2024-08-18 00:06:22,650:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-08-18 00:06:23,707:INFO:[LightGBM] [Info] Number of positive: 63832, number of negative: 63296
2024-08-18 00:06:23,714:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001276 seconds.
2024-08-18 00:06:23,715:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-18 00:06:23,715:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-18 00:06:23,715:INFO:[LightGBM] [Info] Total Bins 149
2024-08-18 00:06:23,715:INFO:[LightGBM] [Info] Number of data points in the train set: 127128, number of used features: 41
2024-08-18 00:06:23,716:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502108 -> initscore=0.008432
2024-08-18 00:06:23,716:INFO:[LightGBM] [Info] Start training from score 0.008432
2024-08-18 00:06:25,250:INFO:[LightGBM] [Info] Number of positive: 63833, number of negative: 63296
2024-08-18 00:06:25,257:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001558 seconds.
2024-08-18 00:06:25,257:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-18 00:06:25,257:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-18 00:06:25,257:INFO:[LightGBM] [Info] Total Bins 152
2024-08-18 00:06:25,257:INFO:[LightGBM] [Info] Number of data points in the train set: 127129, number of used features: 41
2024-08-18 00:06:25,258:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502112 -> initscore=0.008448
2024-08-18 00:06:25,258:INFO:[LightGBM] [Info] Start training from score 0.008448
2024-08-18 00:06:26,823:INFO:[LightGBM] [Info] Number of positive: 63833, number of negative: 63296
2024-08-18 00:06:26,830:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001366 seconds.
2024-08-18 00:06:26,830:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-18 00:06:26,830:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-18 00:06:26,830:INFO:[LightGBM] [Info] Total Bins 159
2024-08-18 00:06:26,830:INFO:[LightGBM] [Info] Number of data points in the train set: 127129, number of used features: 42
2024-08-18 00:06:26,831:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502112 -> initscore=0.008448
2024-08-18 00:06:26,832:INFO:[LightGBM] [Info] Start training from score 0.008448
2024-08-18 00:06:28,309:INFO:[LightGBM] [Info] Number of positive: 63833, number of negative: 63296
2024-08-18 00:06:28,316:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001738 seconds.
2024-08-18 00:06:28,316:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-18 00:06:28,316:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-18 00:06:28,317:INFO:[LightGBM] [Info] Total Bins 162
2024-08-18 00:06:28,317:INFO:[LightGBM] [Info] Number of data points in the train set: 127129, number of used features: 42
2024-08-18 00:06:28,318:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502112 -> initscore=0.008448
2024-08-18 00:06:28,318:INFO:[LightGBM] [Info] Start training from score 0.008448
2024-08-18 00:06:29,731:INFO:[LightGBM] [Info] Number of positive: 63833, number of negative: 63296
2024-08-18 00:06:29,741:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002172 seconds.
2024-08-18 00:06:29,741:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-18 00:06:29,741:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-18 00:06:29,741:INFO:[LightGBM] [Info] Total Bins 152
2024-08-18 00:06:29,742:INFO:[LightGBM] [Info] Number of data points in the train set: 127129, number of used features: 41
2024-08-18 00:06:29,743:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502112 -> initscore=0.008448
2024-08-18 00:06:29,743:INFO:[LightGBM] [Info] Start training from score 0.008448
2024-08-18 00:06:30,221:INFO:Calculating mean and std
2024-08-18 00:06:30,222:INFO:Creating metrics dataframe
2024-08-18 00:06:30,228:INFO:Finalizing model
2024-08-18 00:06:31,514:INFO:[LightGBM] [Info] Number of positive: 79791, number of negative: 79120
2024-08-18 00:06:31,526:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002017 seconds.
2024-08-18 00:06:31,526:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-18 00:06:31,526:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-18 00:06:31,526:INFO:[LightGBM] [Info] Total Bins 168
2024-08-18 00:06:31,526:INFO:[LightGBM] [Info] Number of data points in the train set: 158911, number of used features: 42
2024-08-18 00:06:31,528:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502111 -> initscore=0.008445
2024-08-18 00:06:31,528:INFO:[LightGBM] [Info] Start training from score 0.008445
2024-08-18 00:06:31,686:INFO:Creating Dashboard logs
2024-08-18 00:06:31,690:INFO:Model: Light Gradient Boosting Machine
2024-08-18 00:06:31,722:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2024-08-18 00:06:31,924:INFO:Initializing predict_model()
2024-08-18 00:06:31,924:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f805dfa99f0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f803a9e9480>)
2024-08-18 00:06:31,924:INFO:Checking exceptions
2024-08-18 00:06:31,924:INFO:Preloading libraries
2024-08-18 00:06:32,689:INFO:SubProcess plot_model() called ==================================
2024-08-18 00:06:32,690:INFO:Initializing plot_model()
2024-08-18 00:06:32,690:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmpab_2kl8f, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f805dfa99f0>, system=False)
2024-08-18 00:06:32,690:INFO:Checking exceptions
2024-08-18 00:06:32,726:INFO:Preloading libraries
2024-08-18 00:06:32,730:INFO:Copying training dataset
2024-08-18 00:06:32,730:INFO:Plot type: auc
2024-08-18 00:06:33,231:INFO:Fitting Model
2024-08-18 00:06:33,238:INFO:Scoring test/hold-out set
2024-08-18 00:06:33,472:INFO:Saving '/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmpab_2kl8f/AUC.png'
2024-08-18 00:06:33,741:INFO:Visual Rendered Successfully
2024-08-18 00:06:33,861:INFO:plot_model() successfully completed......................................
2024-08-18 00:06:33,872:INFO:Initializing plot_model()
2024-08-18 00:06:33,872:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmpab_2kl8f, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f805dfa99f0>, system=False)
2024-08-18 00:06:33,872:INFO:Checking exceptions
2024-08-18 00:06:33,913:INFO:Preloading libraries
2024-08-18 00:06:33,917:INFO:Copying training dataset
2024-08-18 00:06:33,917:INFO:Plot type: confusion_matrix
2024-08-18 00:06:34,422:INFO:Fitting Model
2024-08-18 00:06:34,426:INFO:Scoring test/hold-out set
2024-08-18 00:06:34,617:INFO:Saving '/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmpab_2kl8f/Confusion Matrix.png'
2024-08-18 00:06:34,752:INFO:Visual Rendered Successfully
2024-08-18 00:06:34,875:INFO:plot_model() successfully completed......................................
2024-08-18 00:06:34,881:INFO:Initializing plot_model()
2024-08-18 00:06:34,882:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmpab_2kl8f, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f805dfa99f0>, system=False)
2024-08-18 00:06:34,882:INFO:Checking exceptions
2024-08-18 00:06:34,921:INFO:Preloading libraries
2024-08-18 00:06:34,925:INFO:Copying training dataset
2024-08-18 00:06:34,925:INFO:Plot type: feature
2024-08-18 00:06:34,926:WARNING:No coef_ found. Trying feature_importances_
2024-08-18 00:06:35,131:INFO:Saving '/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmpab_2kl8f/Feature Importance.png'
2024-08-18 00:06:35,283:INFO:Visual Rendered Successfully
2024-08-18 00:06:35,401:INFO:plot_model() successfully completed......................................
2024-08-18 00:06:35,421:INFO:SubProcess plot_model() end ==================================
2024-08-18 00:06:35,681:INFO:Uploading results into container
2024-08-18 00:06:35,682:INFO:Uploading model into container now
2024-08-18 00:06:35,692:INFO:_master_model_container: 9
2024-08-18 00:06:35,692:INFO:_display_container: 3
2024-08-18 00:06:35,693:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-08-18 00:06:35,693:INFO:create_model() successfully completed......................................
2024-08-18 00:07:20,458:INFO:Initializing create_model()
2024-08-18 00:07:20,458:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f805dfa99f0>, estimator=rf, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-18 00:07:20,458:INFO:Checking exceptions
2024-08-18 00:07:20,480:INFO:Importing libraries
2024-08-18 00:07:20,480:INFO:Copying training dataset
2024-08-18 00:07:20,591:INFO:Defining folds
2024-08-18 00:07:20,591:INFO:Declaring metric variables
2024-08-18 00:07:20,595:INFO:Importing untrained model
2024-08-18 00:07:20,599:INFO:Random Forest Classifier Imported successfully
2024-08-18 00:07:20,607:INFO:Starting cross validation
2024-08-18 00:07:20,609:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-08-18 00:07:47,446:INFO:Calculating mean and std
2024-08-18 00:07:47,447:INFO:Creating metrics dataframe
2024-08-18 00:07:47,452:INFO:Finalizing model
2024-08-18 00:07:54,084:INFO:Creating Dashboard logs
2024-08-18 00:07:54,088:INFO:Model: Random Forest Classifier
2024-08-18 00:07:54,121:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2024-08-18 00:07:54,335:INFO:Initializing predict_model()
2024-08-18 00:07:54,335:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f805dfa99f0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f803a9e8c10>)
2024-08-18 00:07:54,335:INFO:Checking exceptions
2024-08-18 00:07:54,336:INFO:Preloading libraries
2024-08-18 00:07:55,227:INFO:SubProcess plot_model() called ==================================
2024-08-18 00:07:55,228:INFO:Initializing plot_model()
2024-08-18 00:07:55,228:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmp4rdkbg4x, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f805dfa99f0>, system=False)
2024-08-18 00:07:55,228:INFO:Checking exceptions
2024-08-18 00:07:55,289:INFO:Preloading libraries
2024-08-18 00:07:55,353:INFO:Copying training dataset
2024-08-18 00:07:55,353:INFO:Plot type: auc
2024-08-18 00:07:55,836:INFO:Fitting Model
2024-08-18 00:07:55,843:INFO:Scoring test/hold-out set
2024-08-18 00:07:56,231:INFO:Saving '/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmp4rdkbg4x/AUC.png'
2024-08-18 00:07:56,442:INFO:Visual Rendered Successfully
2024-08-18 00:07:56,563:INFO:plot_model() successfully completed......................................
2024-08-18 00:07:56,575:INFO:Initializing plot_model()
2024-08-18 00:07:56,575:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmp4rdkbg4x, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f805dfa99f0>, system=False)
2024-08-18 00:07:56,575:INFO:Checking exceptions
2024-08-18 00:07:56,636:INFO:Preloading libraries
2024-08-18 00:07:56,699:INFO:Copying training dataset
2024-08-18 00:07:56,699:INFO:Plot type: confusion_matrix
2024-08-18 00:07:57,216:INFO:Fitting Model
2024-08-18 00:07:57,220:INFO:Scoring test/hold-out set
2024-08-18 00:07:57,578:INFO:Saving '/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmp4rdkbg4x/Confusion Matrix.png'
2024-08-18 00:07:57,687:INFO:Visual Rendered Successfully
2024-08-18 00:07:57,805:INFO:plot_model() successfully completed......................................
2024-08-18 00:07:57,820:INFO:Initializing plot_model()
2024-08-18 00:07:57,820:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmp4rdkbg4x, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f805dfa99f0>, system=False)
2024-08-18 00:07:57,820:INFO:Checking exceptions
2024-08-18 00:07:57,882:INFO:Preloading libraries
2024-08-18 00:07:57,943:INFO:Copying training dataset
2024-08-18 00:07:57,943:INFO:Plot type: feature
2024-08-18 00:07:57,944:WARNING:No coef_ found. Trying feature_importances_
2024-08-18 00:07:58,155:INFO:Saving '/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmp4rdkbg4x/Feature Importance.png'
2024-08-18 00:07:58,318:INFO:Visual Rendered Successfully
2024-08-18 00:07:58,437:INFO:plot_model() successfully completed......................................
2024-08-18 00:07:58,472:INFO:SubProcess plot_model() end ==================================
2024-08-18 00:07:58,789:INFO:Uploading results into container
2024-08-18 00:07:58,789:INFO:Uploading model into container now
2024-08-18 00:07:58,799:INFO:_master_model_container: 10
2024-08-18 00:07:58,799:INFO:_display_container: 4
2024-08-18 00:07:58,799:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-08-18 00:07:58,799:INFO:create_model() successfully completed......................................
2024-08-18 00:08:54,875:INFO:Initializing plot_model()
2024-08-18 00:08:54,875:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f805dfa99f0>, system=True)
2024-08-18 00:08:54,875:INFO:Checking exceptions
2024-08-18 00:08:54,943:INFO:Preloading libraries
2024-08-18 00:08:55,021:INFO:Copying training dataset
2024-08-18 00:08:55,021:INFO:Plot type: feature
2024-08-18 00:08:55,022:WARNING:No coef_ found. Trying feature_importances_
2024-08-18 00:08:55,370:INFO:Visual Rendered Successfully
2024-08-18 00:08:55,497:INFO:plot_model() successfully completed......................................
2024-08-18 00:10:33,137:INFO:PyCaret ClassificationExperiment
2024-08-18 00:10:33,137:INFO:Logging name: codepro_model_exp02
2024-08-18 00:10:33,137:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-08-18 00:10:33,137:INFO:version 3.3.2
2024-08-18 00:10:33,137:INFO:Initializing setup()
2024-08-18 00:10:33,137:INFO:self.USI: 4957
2024-08-18 00:10:33,137:INFO:self._variable_keys: {'log_plots_param', 'gpu_param', 'exp_id', 'fold_generator', 'pipeline', 'seed', '_available_plots', 'memory', 'html_param', 'y', 'fix_imbalance', 'is_multiclass', 'idx', 'y_test', 'n_jobs_param', 'X_test', 'target_param', 'fold_groups_param', 'exp_name_log', '_ml_usecase', 'gpu_n_jobs_param', 'logging_param', 'y_train', 'fold_shuffle_param', 'USI', 'X_train', 'data', 'X'}
2024-08-18 00:10:33,137:INFO:Checking environment
2024-08-18 00:10:33,137:INFO:python_version: 3.10.9
2024-08-18 00:10:33,137:INFO:python_build: ('main', 'Mar  1 2023 12:33:47')
2024-08-18 00:10:33,137:INFO:machine: x86_64
2024-08-18 00:10:33,138:INFO:platform: macOS-10.16-x86_64-i386-64bit
2024-08-18 00:10:33,138:INFO:Memory: svmem(total=17179869184, available=5974335488, percent=65.2, used=9961062400, free=118571008, active=5851258880, inactive=5850664960, wired=4109803520)
2024-08-18 00:10:33,138:INFO:Physical Core: 6
2024-08-18 00:10:33,138:INFO:Logical Core: 12
2024-08-18 00:10:33,138:INFO:Checking libraries
2024-08-18 00:10:33,138:INFO:System:
2024-08-18 00:10:33,138:INFO:    python: 3.10.9 (main, Mar  1 2023, 12:33:47) [Clang 14.0.6 ]
2024-08-18 00:10:33,138:INFO:executable: /Users/I500955/anaconda3/bin/python
2024-08-18 00:10:33,138:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2024-08-18 00:10:33,138:INFO:PyCaret required dependencies:
2024-08-18 00:10:33,138:INFO:                 pip: 22.3.1
2024-08-18 00:10:33,138:INFO:          setuptools: 65.6.3
2024-08-18 00:10:33,138:INFO:             pycaret: 3.3.2
2024-08-18 00:10:33,139:INFO:             IPython: 8.10.0
2024-08-18 00:10:33,139:INFO:          ipywidgets: 7.6.5
2024-08-18 00:10:33,139:INFO:                tqdm: 4.64.1
2024-08-18 00:10:33,139:INFO:               numpy: 1.23.5
2024-08-18 00:10:33,139:INFO:              pandas: 2.2.2
2024-08-18 00:10:33,139:INFO:              jinja2: 3.1.2
2024-08-18 00:10:33,139:INFO:               scipy: 1.10.0
2024-08-18 00:10:33,139:INFO:              joblib: 1.3.2
2024-08-18 00:10:33,139:INFO:             sklearn: 1.4.2
2024-08-18 00:10:33,139:INFO:                pyod: 2.0.1
2024-08-18 00:10:33,139:INFO:            imblearn: 0.12.3
2024-08-18 00:10:33,139:INFO:   category_encoders: 2.6.3
2024-08-18 00:10:33,139:INFO:            lightgbm: 4.5.0
2024-08-18 00:10:33,139:INFO:               numba: 0.56.4
2024-08-18 00:10:33,139:INFO:            requests: 2.28.1
2024-08-18 00:10:33,139:INFO:          matplotlib: 3.7.0
2024-08-18 00:10:33,139:INFO:          scikitplot: 0.3.7
2024-08-18 00:10:33,139:INFO:         yellowbrick: 1.5
2024-08-18 00:10:33,139:INFO:              plotly: 5.23.0
2024-08-18 00:10:33,140:INFO:    plotly-resampler: Not installed
2024-08-18 00:10:33,140:INFO:             kaleido: 0.2.1
2024-08-18 00:10:33,140:INFO:           schemdraw: 0.15
2024-08-18 00:10:33,140:INFO:         statsmodels: 0.13.5
2024-08-18 00:10:33,140:INFO:              sktime: 0.26.0
2024-08-18 00:10:33,140:INFO:               tbats: 1.1.3
2024-08-18 00:10:33,140:INFO:            pmdarima: 2.0.4
2024-08-18 00:10:33,140:INFO:              psutil: 5.9.0
2024-08-18 00:10:33,140:INFO:          markupsafe: 2.1.1
2024-08-18 00:10:33,140:INFO:             pickle5: Not installed
2024-08-18 00:10:33,140:INFO:         cloudpickle: 3.0.0
2024-08-18 00:10:33,140:INFO:         deprecation: 2.1.0
2024-08-18 00:10:33,140:INFO:              xxhash: 3.5.0
2024-08-18 00:10:33,140:INFO:           wurlitzer: 3.0.2
2024-08-18 00:10:33,140:INFO:PyCaret optional dependencies:
2024-08-18 00:10:33,140:INFO:                shap: Not installed
2024-08-18 00:10:33,140:INFO:           interpret: Not installed
2024-08-18 00:10:33,140:INFO:                umap: Not installed
2024-08-18 00:10:33,140:INFO:     ydata_profiling: 4.9.0
2024-08-18 00:10:33,141:INFO:  explainerdashboard: Not installed
2024-08-18 00:10:33,141:INFO:             autoviz: Not installed
2024-08-18 00:10:33,141:INFO:           fairlearn: Not installed
2024-08-18 00:10:33,141:INFO:          deepchecks: Not installed
2024-08-18 00:10:33,141:INFO:             xgboost: Not installed
2024-08-18 00:10:33,141:INFO:            catboost: Not installed
2024-08-18 00:10:33,141:INFO:              kmodes: Not installed
2024-08-18 00:10:33,141:INFO:             mlxtend: Not installed
2024-08-18 00:10:33,141:INFO:       statsforecast: Not installed
2024-08-18 00:10:33,141:INFO:        tune_sklearn: Not installed
2024-08-18 00:10:33,141:INFO:                 ray: Not installed
2024-08-18 00:10:33,141:INFO:            hyperopt: Not installed
2024-08-18 00:10:33,141:INFO:              optuna: Not installed
2024-08-18 00:10:33,141:INFO:               skopt: 0.10.2
2024-08-18 00:10:33,141:INFO:              mlflow: 2.15.1
2024-08-18 00:10:33,141:INFO:              gradio: Not installed
2024-08-18 00:10:33,141:INFO:             fastapi: Not installed
2024-08-18 00:10:33,141:INFO:             uvicorn: Not installed
2024-08-18 00:10:33,141:INFO:              m2cgen: Not installed
2024-08-18 00:10:33,141:INFO:           evidently: Not installed
2024-08-18 00:10:33,141:INFO:               fugue: Not installed
2024-08-18 00:10:33,141:INFO:           streamlit: Not installed
2024-08-18 00:10:33,141:INFO:             prophet: Not installed
2024-08-18 00:10:33,142:INFO:None
2024-08-18 00:10:33,142:INFO:Set up GPU usage.
2024-08-18 00:10:33,142:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:10:33,142:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2024-08-18 00:10:33,142:INFO:Set up data.
2024-08-18 00:10:33,200:INFO:Set up folding strategy.
2024-08-18 00:10:33,200:INFO:Set up train/test split.
2024-08-18 00:10:33,283:INFO:Set up index.
2024-08-18 00:10:33,292:INFO:Assigning column types.
2024-08-18 00:10:33,312:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-08-18 00:10:33,312:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:10:33,355:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-18 00:10:33,355:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:10:33,355:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:10:33,356:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-18 00:10:33,356:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:10:33,376:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:10:33,380:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:10:33,380:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-18 00:10:33,384:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-18 00:10:33,385:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:10:33,425:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-18 00:10:33,425:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:10:33,426:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:10:33,426:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-18 00:10:33,426:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:10:33,446:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:10:33,451:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:10:33,451:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-18 00:10:33,454:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-18 00:10:33,455:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-08-18 00:10:33,455:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:10:33,495:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:10:33,495:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:10:33,496:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-18 00:10:33,496:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:10:33,515:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:10:33,519:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:10:33,520:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-18 00:10:33,523:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-18 00:10:33,524:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:10:33,563:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:10:33,564:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:10:33,564:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-18 00:10:33,564:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:10:33,585:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:10:33,590:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:10:33,591:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-18 00:10:33,595:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-18 00:10:33,595:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-08-18 00:10:33,596:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:10:33,638:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:10:33,638:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:10:33,639:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:10:33,660:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:10:33,664:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:10:33,664:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-18 00:10:33,667:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-18 00:10:33,668:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:10:33,710:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:10:33,710:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:10:33,711:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:10:33,731:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:10:33,735:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:10:33,736:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-18 00:10:33,739:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-18 00:10:33,739:INFO:Preparing preprocessing pipeline...
2024-08-18 00:10:33,743:INFO:Set up simple imputation.
2024-08-18 00:10:33,760:INFO:Set up encoding of categorical features.
2024-08-18 00:10:34,491:INFO:Finished creating preprocessing pipeline.
2024-08-18 00:10:34,498:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_droppped',
                                             'city_tier', 'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-08-18 00:10:34,498:INFO:Creating final display dataframe.
2024-08-18 00:10:36,216:INFO:Setup _display_container:                     Description                Value
0                    Session id                 5031
1                        Target    app_complete_flag
2                   Target type               Binary
3           Original data shape          (227016, 7)
4        Transformed data shape         (227016, 39)
5   Transformed train set shape         (158911, 39)
6    Transformed test set shape          (68105, 39)
7              Numeric features                    3
8          Categorical features                    3
9                    Preprocess                 True
10              Imputation type               simple
11           Numeric imputation                 mean
12       Categorical imputation                 mode
13     Maximum one-hot encoding                   25
14              Encoding method                 None
15               Fold Generator      StratifiedKFold
16                  Fold Number                   10
17                     CPU Jobs                   -1
18                      Use GPU                 True
19               Log Experiment         MlflowLogger
20              Experiment Name  codepro_model_exp02
21                          USI                 4957
2024-08-18 00:10:36,222:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:10:36,271:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:10:36,272:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:10:36,272:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:10:36,294:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:10:36,298:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:10:36,299:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-18 00:10:36,303:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-18 00:10:36,303:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:10:36,345:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:10:36,345:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:10:36,346:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:10:36,367:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:10:36,371:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:10:36,372:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-18 00:10:36,375:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-18 00:10:36,376:INFO:Logging experiment in loggers
2024-08-18 00:10:36,534:INFO:SubProcess save_model() called ==================================
2024-08-18 00:10:36,543:INFO:Initializing save_model()
2024-08-18 00:10:36,543:INFO:save_model(model=Pipeline(memory=FastMemory(location=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_droppped',
                                             'city_tier', 'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), model_name=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmp01meinfz/Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_droppped',
                                             'city_tier', 'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-08-18 00:10:36,543:INFO:Adding model into prep_pipe
2024-08-18 00:10:36,543:WARNING:Only Model saved as it was a pipeline.
2024-08-18 00:10:36,557:INFO:/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmp01meinfz/Transformation Pipeline.pkl saved in current working directory
2024-08-18 00:10:36,562:INFO:Pipeline(memory=FastMemory(location=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_droppped',
                                             'city_tier', 'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-08-18 00:10:36,562:INFO:save_model() successfully completed......................................
2024-08-18 00:10:36,671:INFO:SubProcess save_model() end ==================================
2024-08-18 00:10:37,338:INFO:setup() successfully completed in 3.33s...............
2024-08-18 00:11:28,112:INFO:Initializing compare_models()
2024-08-18 00:11:28,112:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f805e6b7820>, include=None, fold=5, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f805e6b7820>, 'include': None, 'exclude': ['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada'], 'fold': 5, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada'])
2024-08-18 00:11:28,112:INFO:Checking exceptions
2024-08-18 00:11:28,145:INFO:Preparing display monitor
2024-08-18 00:11:28,183:INFO:Initializing Logistic Regression
2024-08-18 00:11:28,183:INFO:Total runtime is 4.982948303222656e-06 minutes
2024-08-18 00:11:28,187:INFO:SubProcess create_model() called ==================================
2024-08-18 00:11:28,188:INFO:Initializing create_model()
2024-08-18 00:11:28,188:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f805e6b7820>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f805c621c00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-18 00:11:28,189:INFO:Checking exceptions
2024-08-18 00:11:28,189:INFO:Importing libraries
2024-08-18 00:11:28,189:INFO:Copying training dataset
2024-08-18 00:11:28,255:INFO:Defining folds
2024-08-18 00:11:28,256:INFO:Declaring metric variables
2024-08-18 00:11:28,259:INFO:Importing untrained model
2024-08-18 00:11:28,263:INFO:Logistic Regression Imported successfully
2024-08-18 00:11:28,272:INFO:Starting cross validation
2024-08-18 00:11:28,275:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-08-18 00:11:35,194:INFO:Calculating mean and std
2024-08-18 00:11:35,196:INFO:Creating metrics dataframe
2024-08-18 00:11:35,197:INFO:Uploading results into container
2024-08-18 00:11:35,198:INFO:Uploading model into container now
2024-08-18 00:11:35,198:INFO:_master_model_container: 1
2024-08-18 00:11:35,199:INFO:_display_container: 2
2024-08-18 00:11:35,199:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5031, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-08-18 00:11:35,199:INFO:create_model() successfully completed......................................
2024-08-18 00:11:35,322:INFO:SubProcess create_model() end ==================================
2024-08-18 00:11:35,322:INFO:Creating metrics dataframe
2024-08-18 00:11:35,331:INFO:Initializing Naive Bayes
2024-08-18 00:11:35,331:INFO:Total runtime is 0.11913763284683228 minutes
2024-08-18 00:11:35,335:INFO:SubProcess create_model() called ==================================
2024-08-18 00:11:35,336:INFO:Initializing create_model()
2024-08-18 00:11:35,336:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f805e6b7820>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f805c621c00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-18 00:11:35,336:INFO:Checking exceptions
2024-08-18 00:11:35,336:INFO:Importing libraries
2024-08-18 00:11:35,336:INFO:Copying training dataset
2024-08-18 00:11:35,386:INFO:Defining folds
2024-08-18 00:11:35,386:INFO:Declaring metric variables
2024-08-18 00:11:35,390:INFO:Importing untrained model
2024-08-18 00:11:35,394:INFO:Naive Bayes Imported successfully
2024-08-18 00:11:35,401:INFO:Starting cross validation
2024-08-18 00:11:35,403:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-08-18 00:11:41,612:INFO:Calculating mean and std
2024-08-18 00:11:41,613:INFO:Creating metrics dataframe
2024-08-18 00:11:41,614:INFO:Uploading results into container
2024-08-18 00:11:41,615:INFO:Uploading model into container now
2024-08-18 00:11:41,615:INFO:_master_model_container: 2
2024-08-18 00:11:41,615:INFO:_display_container: 2
2024-08-18 00:11:41,616:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-08-18 00:11:41,616:INFO:create_model() successfully completed......................................
2024-08-18 00:11:41,739:INFO:SubProcess create_model() end ==================================
2024-08-18 00:11:41,739:INFO:Creating metrics dataframe
2024-08-18 00:11:41,749:INFO:Initializing Decision Tree Classifier
2024-08-18 00:11:41,749:INFO:Total runtime is 0.22611078421274822 minutes
2024-08-18 00:11:41,754:INFO:SubProcess create_model() called ==================================
2024-08-18 00:11:41,754:INFO:Initializing create_model()
2024-08-18 00:11:41,754:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f805e6b7820>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f805c621c00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-18 00:11:41,754:INFO:Checking exceptions
2024-08-18 00:11:41,755:INFO:Importing libraries
2024-08-18 00:11:41,755:INFO:Copying training dataset
2024-08-18 00:11:41,803:INFO:Defining folds
2024-08-18 00:11:41,803:INFO:Declaring metric variables
2024-08-18 00:11:41,807:INFO:Importing untrained model
2024-08-18 00:11:41,812:INFO:Decision Tree Classifier Imported successfully
2024-08-18 00:11:41,819:INFO:Starting cross validation
2024-08-18 00:11:41,821:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-08-18 00:11:49,458:INFO:Calculating mean and std
2024-08-18 00:11:49,459:INFO:Creating metrics dataframe
2024-08-18 00:11:49,461:INFO:Uploading results into container
2024-08-18 00:11:49,461:INFO:Uploading model into container now
2024-08-18 00:11:49,462:INFO:_master_model_container: 3
2024-08-18 00:11:49,462:INFO:_display_container: 2
2024-08-18 00:11:49,462:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=5031, splitter='best')
2024-08-18 00:11:49,462:INFO:create_model() successfully completed......................................
2024-08-18 00:11:49,578:INFO:SubProcess create_model() end ==================================
2024-08-18 00:11:49,578:INFO:Creating metrics dataframe
2024-08-18 00:11:49,588:INFO:Initializing Ridge Classifier
2024-08-18 00:11:49,588:INFO:Total runtime is 0.35675541559855145 minutes
2024-08-18 00:11:49,592:INFO:SubProcess create_model() called ==================================
2024-08-18 00:11:49,593:INFO:Initializing create_model()
2024-08-18 00:11:49,593:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f805e6b7820>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f805c621c00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-18 00:11:49,593:INFO:Checking exceptions
2024-08-18 00:11:49,593:INFO:Importing libraries
2024-08-18 00:11:49,593:INFO:Copying training dataset
2024-08-18 00:11:49,641:INFO:Defining folds
2024-08-18 00:11:49,642:INFO:Declaring metric variables
2024-08-18 00:11:49,645:INFO:Importing untrained model
2024-08-18 00:11:49,650:INFO:Ridge Classifier Imported successfully
2024-08-18 00:11:49,657:INFO:Starting cross validation
2024-08-18 00:11:49,659:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-08-18 00:11:55,830:INFO:Calculating mean and std
2024-08-18 00:11:55,831:INFO:Creating metrics dataframe
2024-08-18 00:11:55,833:INFO:Uploading results into container
2024-08-18 00:11:55,834:INFO:Uploading model into container now
2024-08-18 00:11:55,834:INFO:_master_model_container: 4
2024-08-18 00:11:55,835:INFO:_display_container: 2
2024-08-18 00:11:55,835:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=5031, solver='auto',
                tol=0.0001)
2024-08-18 00:11:55,835:INFO:create_model() successfully completed......................................
2024-08-18 00:11:55,972:INFO:SubProcess create_model() end ==================================
2024-08-18 00:11:55,972:INFO:Creating metrics dataframe
2024-08-18 00:11:55,982:INFO:Initializing Random Forest Classifier
2024-08-18 00:11:55,982:INFO:Total runtime is 0.46333090066909793 minutes
2024-08-18 00:11:55,987:INFO:SubProcess create_model() called ==================================
2024-08-18 00:11:55,988:INFO:Initializing create_model()
2024-08-18 00:11:55,988:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f805e6b7820>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f805c621c00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-18 00:11:55,988:INFO:Checking exceptions
2024-08-18 00:11:55,988:INFO:Importing libraries
2024-08-18 00:11:55,988:INFO:Copying training dataset
2024-08-18 00:11:56,042:INFO:Defining folds
2024-08-18 00:11:56,042:INFO:Declaring metric variables
2024-08-18 00:11:56,047:INFO:Importing untrained model
2024-08-18 00:11:56,052:INFO:Random Forest Classifier Imported successfully
2024-08-18 00:11:56,060:INFO:Starting cross validation
2024-08-18 00:11:56,063:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-08-18 00:12:19,552:INFO:Calculating mean and std
2024-08-18 00:12:19,553:INFO:Creating metrics dataframe
2024-08-18 00:12:19,555:INFO:Uploading results into container
2024-08-18 00:12:19,555:INFO:Uploading model into container now
2024-08-18 00:12:19,556:INFO:_master_model_container: 5
2024-08-18 00:12:19,556:INFO:_display_container: 2
2024-08-18 00:12:19,557:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=5031, verbose=0,
                       warm_start=False)
2024-08-18 00:12:19,557:INFO:create_model() successfully completed......................................
2024-08-18 00:12:19,674:INFO:SubProcess create_model() end ==================================
2024-08-18 00:12:19,674:INFO:Creating metrics dataframe
2024-08-18 00:12:19,684:INFO:Initializing Linear Discriminant Analysis
2024-08-18 00:12:19,684:INFO:Total runtime is 0.8583564996719361 minutes
2024-08-18 00:12:19,688:INFO:SubProcess create_model() called ==================================
2024-08-18 00:12:19,689:INFO:Initializing create_model()
2024-08-18 00:12:19,689:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f805e6b7820>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f805c621c00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-18 00:12:19,689:INFO:Checking exceptions
2024-08-18 00:12:19,689:INFO:Importing libraries
2024-08-18 00:12:19,689:INFO:Copying training dataset
2024-08-18 00:12:19,737:INFO:Defining folds
2024-08-18 00:12:19,737:INFO:Declaring metric variables
2024-08-18 00:12:19,741:INFO:Importing untrained model
2024-08-18 00:12:19,746:INFO:Linear Discriminant Analysis Imported successfully
2024-08-18 00:12:19,753:INFO:Starting cross validation
2024-08-18 00:12:19,756:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-08-18 00:12:29,741:INFO:Calculating mean and std
2024-08-18 00:12:29,742:INFO:Creating metrics dataframe
2024-08-18 00:12:29,744:INFO:Uploading results into container
2024-08-18 00:12:29,745:INFO:Uploading model into container now
2024-08-18 00:12:29,745:INFO:_master_model_container: 6
2024-08-18 00:12:29,745:INFO:_display_container: 2
2024-08-18 00:12:29,746:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-08-18 00:12:29,746:INFO:create_model() successfully completed......................................
2024-08-18 00:12:29,859:INFO:SubProcess create_model() end ==================================
2024-08-18 00:12:29,859:INFO:Creating metrics dataframe
2024-08-18 00:12:29,870:INFO:Initializing Extra Trees Classifier
2024-08-18 00:12:29,871:INFO:Total runtime is 1.028133797645569 minutes
2024-08-18 00:12:29,875:INFO:SubProcess create_model() called ==================================
2024-08-18 00:12:29,875:INFO:Initializing create_model()
2024-08-18 00:12:29,875:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f805e6b7820>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f805c621c00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-18 00:12:29,876:INFO:Checking exceptions
2024-08-18 00:12:29,876:INFO:Importing libraries
2024-08-18 00:12:29,876:INFO:Copying training dataset
2024-08-18 00:12:29,925:INFO:Defining folds
2024-08-18 00:12:29,925:INFO:Declaring metric variables
2024-08-18 00:12:29,929:INFO:Importing untrained model
2024-08-18 00:12:29,933:INFO:Extra Trees Classifier Imported successfully
2024-08-18 00:12:29,941:INFO:Starting cross validation
2024-08-18 00:12:29,943:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-08-18 00:12:54,399:INFO:Calculating mean and std
2024-08-18 00:12:54,400:INFO:Creating metrics dataframe
2024-08-18 00:12:54,402:INFO:Uploading results into container
2024-08-18 00:12:54,403:INFO:Uploading model into container now
2024-08-18 00:12:54,403:INFO:_master_model_container: 7
2024-08-18 00:12:54,404:INFO:_display_container: 2
2024-08-18 00:12:54,404:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=5031, verbose=0,
                     warm_start=False)
2024-08-18 00:12:54,404:INFO:create_model() successfully completed......................................
2024-08-18 00:12:54,527:INFO:SubProcess create_model() end ==================================
2024-08-18 00:12:54,527:INFO:Creating metrics dataframe
2024-08-18 00:12:54,538:INFO:Initializing Light Gradient Boosting Machine
2024-08-18 00:12:54,539:INFO:Total runtime is 1.4392670313517253 minutes
2024-08-18 00:12:54,543:INFO:SubProcess create_model() called ==================================
2024-08-18 00:12:54,544:INFO:Initializing create_model()
2024-08-18 00:12:54,544:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f805e6b7820>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f805c621c00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-18 00:12:54,544:INFO:Checking exceptions
2024-08-18 00:12:54,544:INFO:Importing libraries
2024-08-18 00:12:54,545:INFO:Copying training dataset
2024-08-18 00:12:54,602:INFO:Defining folds
2024-08-18 00:12:54,602:INFO:Declaring metric variables
2024-08-18 00:12:54,606:INFO:Importing untrained model
2024-08-18 00:12:54,611:INFO:Light Gradient Boosting Machine Imported successfully
2024-08-18 00:12:54,619:INFO:Starting cross validation
2024-08-18 00:12:54,622:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-08-18 00:12:55,699:INFO:[LightGBM] [Info] Number of positive: 63832, number of negative: 63296
2024-08-18 00:12:55,702:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000867 seconds.
2024-08-18 00:12:55,703:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-18 00:12:55,703:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-18 00:12:55,703:INFO:[LightGBM] [Info] Total Bins 115
2024-08-18 00:12:55,703:INFO:[LightGBM] [Info] Number of data points in the train set: 127128, number of used features: 38
2024-08-18 00:12:55,704:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502108 -> initscore=0.008432
2024-08-18 00:12:55,704:INFO:[LightGBM] [Info] Start training from score 0.008432
2024-08-18 00:12:58,223:INFO:[LightGBM] [Info] Number of positive: 63833, number of negative: 63296
2024-08-18 00:12:58,228:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001105 seconds.
2024-08-18 00:12:58,228:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-18 00:12:58,228:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-18 00:12:58,228:INFO:[LightGBM] [Info] Total Bins 113
2024-08-18 00:12:58,228:INFO:[LightGBM] [Info] Number of data points in the train set: 127129, number of used features: 38
2024-08-18 00:12:58,230:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502112 -> initscore=0.008448
2024-08-18 00:12:58,230:INFO:[LightGBM] [Info] Start training from score 0.008448
2024-08-18 00:13:00,511:INFO:[LightGBM] [Info] Number of positive: 63833, number of negative: 63296
2024-08-18 00:13:00,514:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000898 seconds.
2024-08-18 00:13:00,514:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-18 00:13:00,515:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-18 00:13:00,515:INFO:[LightGBM] [Info] Total Bins 114
2024-08-18 00:13:00,515:INFO:[LightGBM] [Info] Number of data points in the train set: 127129, number of used features: 38
2024-08-18 00:13:00,516:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502112 -> initscore=0.008448
2024-08-18 00:13:00,516:INFO:[LightGBM] [Info] Start training from score 0.008448
2024-08-18 00:13:02,730:INFO:[LightGBM] [Info] Number of positive: 63833, number of negative: 63296
2024-08-18 00:13:02,734:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001085 seconds.
2024-08-18 00:13:02,734:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-18 00:13:02,735:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-18 00:13:02,735:INFO:[LightGBM] [Info] Total Bins 114
2024-08-18 00:13:02,735:INFO:[LightGBM] [Info] Number of data points in the train set: 127129, number of used features: 38
2024-08-18 00:13:02,736:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502112 -> initscore=0.008448
2024-08-18 00:13:02,736:INFO:[LightGBM] [Info] Start training from score 0.008448
2024-08-18 00:13:04,960:INFO:[LightGBM] [Info] Number of positive: 63833, number of negative: 63296
2024-08-18 00:13:04,964:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001003 seconds.
2024-08-18 00:13:04,965:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-18 00:13:04,965:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-18 00:13:04,965:INFO:[LightGBM] [Info] Total Bins 115
2024-08-18 00:13:04,965:INFO:[LightGBM] [Info] Number of data points in the train set: 127129, number of used features: 38
2024-08-18 00:13:04,966:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502112 -> initscore=0.008448
2024-08-18 00:13:04,966:INFO:[LightGBM] [Info] Start training from score 0.008448
2024-08-18 00:13:06,276:INFO:Calculating mean and std
2024-08-18 00:13:06,278:INFO:Creating metrics dataframe
2024-08-18 00:13:06,281:INFO:Uploading results into container
2024-08-18 00:13:06,281:INFO:Uploading model into container now
2024-08-18 00:13:06,282:INFO:_master_model_container: 8
2024-08-18 00:13:06,283:INFO:_display_container: 2
2024-08-18 00:13:06,283:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5031, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-08-18 00:13:06,284:INFO:create_model() successfully completed......................................
2024-08-18 00:13:06,415:INFO:SubProcess create_model() end ==================================
2024-08-18 00:13:06,416:INFO:Creating metrics dataframe
2024-08-18 00:13:06,438:INFO:Initializing create_model()
2024-08-18 00:13:06,439:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f805e6b7820>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5031, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-18 00:13:06,439:INFO:Checking exceptions
2024-08-18 00:13:06,442:INFO:Importing libraries
2024-08-18 00:13:06,442:INFO:Copying training dataset
2024-08-18 00:13:06,495:INFO:Defining folds
2024-08-18 00:13:06,496:INFO:Declaring metric variables
2024-08-18 00:13:06,496:INFO:Importing untrained model
2024-08-18 00:13:06,496:INFO:Declaring custom model
2024-08-18 00:13:06,498:INFO:Light Gradient Boosting Machine Imported successfully
2024-08-18 00:13:06,500:INFO:Cross validation set to False
2024-08-18 00:13:06,500:INFO:Fitting Model
2024-08-18 00:13:07,816:INFO:[LightGBM] [Info] Number of positive: 79791, number of negative: 79120
2024-08-18 00:13:07,822:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001245 seconds.
2024-08-18 00:13:07,822:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-18 00:13:07,822:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-18 00:13:07,822:INFO:[LightGBM] [Info] Total Bins 117
2024-08-18 00:13:07,822:INFO:[LightGBM] [Info] Number of data points in the train set: 158911, number of used features: 38
2024-08-18 00:13:07,824:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502111 -> initscore=0.008445
2024-08-18 00:13:07,824:INFO:[LightGBM] [Info] Start training from score 0.008445
2024-08-18 00:13:08,802:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5031, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-08-18 00:13:08,802:INFO:create_model() successfully completed......................................
2024-08-18 00:13:08,936:INFO:Creating Dashboard logs
2024-08-18 00:13:08,941:INFO:Model: Light Gradient Boosting Machine
2024-08-18 00:13:08,977:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 5031, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2024-08-18 00:13:09,196:INFO:Initializing predict_model()
2024-08-18 00:13:09,196:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f805e6b7820>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5031, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f805df036d0>)
2024-08-18 00:13:09,196:INFO:Checking exceptions
2024-08-18 00:13:09,196:INFO:Preloading libraries
2024-08-18 00:13:09,972:INFO:SubProcess plot_model() called ==================================
2024-08-18 00:13:09,972:INFO:Initializing plot_model()
2024-08-18 00:13:09,972:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5031, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmp06638wbp, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f805e6b7820>, system=False)
2024-08-18 00:13:09,972:INFO:Checking exceptions
2024-08-18 00:13:09,992:INFO:Preloading libraries
2024-08-18 00:13:09,997:INFO:Copying training dataset
2024-08-18 00:13:09,997:INFO:Plot type: auc
2024-08-18 00:13:10,420:INFO:Fitting Model
2024-08-18 00:13:10,427:INFO:Scoring test/hold-out set
2024-08-18 00:13:10,715:INFO:Saving '/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmp06638wbp/AUC.png'
2024-08-18 00:13:10,972:INFO:Visual Rendered Successfully
2024-08-18 00:13:11,092:INFO:plot_model() successfully completed......................................
2024-08-18 00:13:11,097:INFO:Initializing plot_model()
2024-08-18 00:13:11,097:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5031, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmp06638wbp, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f805e6b7820>, system=False)
2024-08-18 00:13:11,097:INFO:Checking exceptions
2024-08-18 00:13:11,120:INFO:Preloading libraries
2024-08-18 00:13:11,125:INFO:Copying training dataset
2024-08-18 00:13:11,125:INFO:Plot type: confusion_matrix
2024-08-18 00:13:11,571:INFO:Fitting Model
2024-08-18 00:13:11,575:INFO:Scoring test/hold-out set
2024-08-18 00:13:11,806:INFO:Saving '/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmp06638wbp/Confusion Matrix.png'
2024-08-18 00:13:11,969:INFO:Visual Rendered Successfully
2024-08-18 00:13:12,089:INFO:plot_model() successfully completed......................................
2024-08-18 00:13:12,095:INFO:Initializing plot_model()
2024-08-18 00:13:12,095:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5031, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmp06638wbp, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f805e6b7820>, system=False)
2024-08-18 00:13:12,095:INFO:Checking exceptions
2024-08-18 00:13:12,119:INFO:Preloading libraries
2024-08-18 00:13:12,124:INFO:Copying training dataset
2024-08-18 00:13:12,124:INFO:Plot type: feature
2024-08-18 00:13:12,125:WARNING:No coef_ found. Trying feature_importances_
2024-08-18 00:13:12,326:INFO:Saving '/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmp06638wbp/Feature Importance.png'
2024-08-18 00:13:12,498:INFO:Visual Rendered Successfully
2024-08-18 00:13:12,613:INFO:plot_model() successfully completed......................................
2024-08-18 00:13:12,621:INFO:SubProcess plot_model() end ==================================
2024-08-18 00:13:12,884:INFO:Creating Dashboard logs
2024-08-18 00:13:12,888:INFO:Model: Random Forest Classifier
2024-08-18 00:13:12,922:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 5031, 'verbose': 0, 'warm_start': False}
2024-08-18 00:13:13,400:INFO:Creating Dashboard logs
2024-08-18 00:13:13,404:INFO:Model: Ridge Classifier
2024-08-18 00:13:13,441:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 5031, 'solver': 'auto', 'tol': 0.0001}
2024-08-18 00:13:13,888:INFO:Creating Dashboard logs
2024-08-18 00:13:13,892:INFO:Model: Linear Discriminant Analysis
2024-08-18 00:13:13,922:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2024-08-18 00:13:14,398:INFO:Creating Dashboard logs
2024-08-18 00:13:14,403:INFO:Model: Logistic Regression
2024-08-18 00:13:14,442:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 5031, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2024-08-18 00:13:14,911:INFO:Creating Dashboard logs
2024-08-18 00:13:14,915:INFO:Model: Naive Bayes
2024-08-18 00:13:14,946:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2024-08-18 00:13:15,479:INFO:Creating Dashboard logs
2024-08-18 00:13:15,484:INFO:Model: Decision Tree Classifier
2024-08-18 00:13:15,530:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 5031, 'splitter': 'best'}
2024-08-18 00:13:16,056:INFO:Creating Dashboard logs
2024-08-18 00:13:16,061:INFO:Model: Extra Trees Classifier
2024-08-18 00:13:16,103:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 5031, 'verbose': 0, 'warm_start': False}
2024-08-18 00:13:16,617:INFO:_master_model_container: 8
2024-08-18 00:13:16,617:INFO:_display_container: 2
2024-08-18 00:13:16,617:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5031, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-08-18 00:13:16,618:INFO:compare_models() successfully completed......................................
2024-08-18 00:17:57,074:INFO:Initializing create_model()
2024-08-18 00:17:57,075:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f805e6b7820>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-18 00:17:57,075:INFO:Checking exceptions
2024-08-18 00:17:57,102:INFO:Importing libraries
2024-08-18 00:17:57,102:INFO:Copying training dataset
2024-08-18 00:17:57,191:INFO:Defining folds
2024-08-18 00:17:57,191:INFO:Declaring metric variables
2024-08-18 00:17:57,195:INFO:Importing untrained model
2024-08-18 00:17:57,200:INFO:Light Gradient Boosting Machine Imported successfully
2024-08-18 00:17:57,209:INFO:Starting cross validation
2024-08-18 00:17:57,213:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-08-18 00:17:58,198:INFO:[LightGBM] [Info] Number of positive: 63832, number of negative: 63296
2024-08-18 00:17:58,201:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000840 seconds.
2024-08-18 00:17:58,201:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-18 00:17:58,201:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-18 00:17:58,201:INFO:[LightGBM] [Info] Total Bins 115
2024-08-18 00:17:58,201:INFO:[LightGBM] [Info] Number of data points in the train set: 127128, number of used features: 38
2024-08-18 00:17:58,202:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502108 -> initscore=0.008432
2024-08-18 00:17:58,202:INFO:[LightGBM] [Info] Start training from score 0.008432
2024-08-18 00:17:59,645:INFO:[LightGBM] [Info] Number of positive: 63833, number of negative: 63296
2024-08-18 00:17:59,648:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000710 seconds.
2024-08-18 00:17:59,648:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-18 00:17:59,648:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-18 00:17:59,648:INFO:[LightGBM] [Info] Total Bins 113
2024-08-18 00:17:59,648:INFO:[LightGBM] [Info] Number of data points in the train set: 127129, number of used features: 38
2024-08-18 00:17:59,649:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502112 -> initscore=0.008448
2024-08-18 00:17:59,649:INFO:[LightGBM] [Info] Start training from score 0.008448
2024-08-18 00:18:01,014:INFO:[LightGBM] [Info] Number of positive: 63833, number of negative: 63296
2024-08-18 00:18:01,016:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000699 seconds.
2024-08-18 00:18:01,016:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-18 00:18:01,017:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-18 00:18:01,017:INFO:[LightGBM] [Info] Total Bins 114
2024-08-18 00:18:01,017:INFO:[LightGBM] [Info] Number of data points in the train set: 127129, number of used features: 38
2024-08-18 00:18:01,017:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502112 -> initscore=0.008448
2024-08-18 00:18:01,018:INFO:[LightGBM] [Info] Start training from score 0.008448
2024-08-18 00:18:02,326:INFO:[LightGBM] [Info] Number of positive: 63833, number of negative: 63296
2024-08-18 00:18:02,329:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000802 seconds.
2024-08-18 00:18:02,329:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-18 00:18:02,329:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-18 00:18:02,329:INFO:[LightGBM] [Info] Total Bins 114
2024-08-18 00:18:02,329:INFO:[LightGBM] [Info] Number of data points in the train set: 127129, number of used features: 38
2024-08-18 00:18:02,330:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502112 -> initscore=0.008448
2024-08-18 00:18:02,330:INFO:[LightGBM] [Info] Start training from score 0.008448
2024-08-18 00:18:03,633:INFO:[LightGBM] [Info] Number of positive: 63833, number of negative: 63296
2024-08-18 00:18:03,636:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000742 seconds.
2024-08-18 00:18:03,636:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-18 00:18:03,636:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-18 00:18:03,636:INFO:[LightGBM] [Info] Total Bins 115
2024-08-18 00:18:03,636:INFO:[LightGBM] [Info] Number of data points in the train set: 127129, number of used features: 38
2024-08-18 00:18:03,637:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502112 -> initscore=0.008448
2024-08-18 00:18:03,637:INFO:[LightGBM] [Info] Start training from score 0.008448
2024-08-18 00:18:04,007:INFO:Calculating mean and std
2024-08-18 00:18:04,008:INFO:Creating metrics dataframe
2024-08-18 00:18:04,014:INFO:Finalizing model
2024-08-18 00:18:05,275:INFO:[LightGBM] [Info] Number of positive: 79791, number of negative: 79120
2024-08-18 00:18:05,280:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001251 seconds.
2024-08-18 00:18:05,280:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-18 00:18:05,280:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-18 00:18:05,280:INFO:[LightGBM] [Info] Total Bins 117
2024-08-18 00:18:05,280:INFO:[LightGBM] [Info] Number of data points in the train set: 158911, number of used features: 38
2024-08-18 00:18:05,283:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502111 -> initscore=0.008445
2024-08-18 00:18:05,283:INFO:[LightGBM] [Info] Start training from score 0.008445
2024-08-18 00:18:05,743:INFO:Creating Dashboard logs
2024-08-18 00:18:05,747:INFO:Model: Light Gradient Boosting Machine
2024-08-18 00:18:05,780:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 5031, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2024-08-18 00:18:05,969:INFO:Initializing predict_model()
2024-08-18 00:18:05,969:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f805e6b7820>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5031, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f805e318430>)
2024-08-18 00:18:05,969:INFO:Checking exceptions
2024-08-18 00:18:05,969:INFO:Preloading libraries
2024-08-18 00:18:06,682:INFO:SubProcess plot_model() called ==================================
2024-08-18 00:18:06,683:INFO:Initializing plot_model()
2024-08-18 00:18:06,683:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5031, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmpzw0pjsr8, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f805e6b7820>, system=False)
2024-08-18 00:18:06,683:INFO:Checking exceptions
2024-08-18 00:18:06,703:INFO:Preloading libraries
2024-08-18 00:18:06,708:INFO:Copying training dataset
2024-08-18 00:18:06,708:INFO:Plot type: auc
2024-08-18 00:18:07,131:INFO:Fitting Model
2024-08-18 00:18:07,138:INFO:Scoring test/hold-out set
2024-08-18 00:18:07,355:INFO:Saving '/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmpzw0pjsr8/AUC.png'
2024-08-18 00:18:07,583:INFO:Visual Rendered Successfully
2024-08-18 00:18:07,705:INFO:plot_model() successfully completed......................................
2024-08-18 00:18:07,711:INFO:Initializing plot_model()
2024-08-18 00:18:07,711:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5031, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmpzw0pjsr8, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f805e6b7820>, system=False)
2024-08-18 00:18:07,711:INFO:Checking exceptions
2024-08-18 00:18:07,737:INFO:Preloading libraries
2024-08-18 00:18:07,742:INFO:Copying training dataset
2024-08-18 00:18:07,742:INFO:Plot type: confusion_matrix
2024-08-18 00:18:08,227:INFO:Fitting Model
2024-08-18 00:18:08,231:INFO:Scoring test/hold-out set
2024-08-18 00:18:08,462:INFO:Saving '/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmpzw0pjsr8/Confusion Matrix.png'
2024-08-18 00:18:08,616:INFO:Visual Rendered Successfully
2024-08-18 00:18:08,743:INFO:plot_model() successfully completed......................................
2024-08-18 00:18:08,746:INFO:Initializing plot_model()
2024-08-18 00:18:08,746:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5031, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmpzw0pjsr8, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f805e6b7820>, system=False)
2024-08-18 00:18:08,746:INFO:Checking exceptions
2024-08-18 00:18:08,768:INFO:Preloading libraries
2024-08-18 00:18:08,773:INFO:Copying training dataset
2024-08-18 00:18:08,773:INFO:Plot type: feature
2024-08-18 00:18:08,774:WARNING:No coef_ found. Trying feature_importances_
2024-08-18 00:18:09,015:INFO:Saving '/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmpzw0pjsr8/Feature Importance.png'
2024-08-18 00:18:09,180:INFO:Visual Rendered Successfully
2024-08-18 00:18:09,288:INFO:plot_model() successfully completed......................................
2024-08-18 00:18:09,290:INFO:SubProcess plot_model() end ==================================
2024-08-18 00:18:09,537:INFO:Uploading results into container
2024-08-18 00:18:09,537:INFO:Uploading model into container now
2024-08-18 00:18:09,548:INFO:_master_model_container: 9
2024-08-18 00:18:09,548:INFO:_display_container: 3
2024-08-18 00:18:09,549:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5031, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-08-18 00:18:09,549:INFO:create_model() successfully completed......................................
2024-08-18 00:24:38,403:INFO:Initializing tune_model()
2024-08-18 00:24:38,404:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5031, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=10, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=optuna, search_algorithm=random, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=True, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f805e6b7820>)
2024-08-18 00:24:38,404:INFO:Checking exceptions
2024-08-18 00:24:38,405:ERROR:
'optuna' is a soft dependency and not included in the pycaret installation. Please run: `pip install optuna` to install.
Alternately, you can install this by running `pip install pycaret[tuners]`
NoneType: None
2024-08-18 00:25:24,653:INFO:Initializing tune_model()
2024-08-18 00:25:24,654:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5031, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=10, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=optuna, search_algorithm=random, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=True, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f805e6b7820>)
2024-08-18 00:25:24,654:INFO:Checking exceptions
2024-08-18 00:25:24,654:ERROR:
'optuna' is a soft dependency and not included in the pycaret installation. Please run: `pip install optuna` to install.
Alternately, you can install this by running `pip install pycaret[tuners]`
NoneType: None
2024-08-18 00:26:28,771:INFO:Initializing tune_model()
2024-08-18 00:26:28,772:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5031, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=10, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=optuna, search_algorithm=random, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=True, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f805e6b7820>)
2024-08-18 00:26:28,772:INFO:Checking exceptions
2024-08-18 00:26:28,772:ERROR:
'optuna' is a soft dependency and not included in the pycaret installation. Please run: `pip install optuna` to install.
Alternately, you can install this by running `pip install pycaret[tuners]`
NoneType: None
2024-08-18 00:27:46,672:INFO:Initializing tune_model()
2024-08-18 00:27:46,673:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5031, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=10, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=optuna, search_algorithm=random, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=True, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f805e6b7820>)
2024-08-18 00:27:46,673:INFO:Checking exceptions
2024-08-18 00:27:46,673:ERROR:
'optuna' is a soft dependency and not included in the pycaret installation. Please run: `pip install optuna` to install.
Alternately, you can install this by running `pip install pycaret[tuners]`
NoneType: None
2024-08-18 00:30:16,422:INFO:Initializing tune_model()
2024-08-18 00:30:16,422:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5031, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=10, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=optuna, search_algorithm=random, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=True, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f805e6b7820>)
2024-08-18 00:30:16,422:INFO:Checking exceptions
2024-08-18 00:30:16,423:ERROR:
'optuna' is a soft dependency and not included in the pycaret installation. Please run: `pip install optuna` to install.
Alternately, you can install this by running `pip install pycaret[tuners]`
NoneType: None
2024-08-18 00:33:05,165:INFO:Initializing tune_model()
2024-08-18 00:33:05,165:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5031, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=10, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=optuna, search_algorithm=random, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=True, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f805e6b7820>)
2024-08-18 00:33:05,165:INFO:Checking exceptions
2024-08-18 00:33:05,166:ERROR:
'optuna' is a soft dependency and not included in the pycaret installation. Please run: `pip install optuna` to install.
Alternately, you can install this by running `pip install pycaret[tuners]`
NoneType: None
2024-08-18 00:35:36,127:INFO:Initializing tune_model()
2024-08-18 00:35:36,127:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5031, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=10, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=optuna, search_algorithm=random, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=True, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f805e6b7820>)
2024-08-18 00:35:36,127:INFO:Checking exceptions
2024-08-18 00:35:36,127:ERROR:
'optuna' is a soft dependency and not included in the pycaret installation. Please run: `pip install optuna` to install.
Alternately, you can install this by running `pip install pycaret[tuners]`
NoneType: None
2024-08-18 00:37:22,114:INFO:Initializing tune_model()
2024-08-18 00:37:22,115:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5031, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=10, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=optuna, search_algorithm=random, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=True, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f805e6b7820>)
2024-08-18 00:37:22,115:INFO:Checking exceptions
2024-08-18 00:37:22,116:ERROR:
'optuna' is a soft dependency and not included in the pycaret installation. Please run: `pip install optuna` to install.
Alternately, you can install this by running `pip install pycaret[tuners]`
NoneType: None
2024-08-18 00:46:01,718:INFO:Initializing tune_model()
2024-08-18 00:46:01,719:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5031, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=10, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=optuna, search_algorithm=random, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=True, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f805e6b7820>)
2024-08-18 00:46:01,719:INFO:Checking exceptions
2024-08-18 00:46:01,720:ERROR:
'optuna' is a soft dependency and not included in the pycaret installation. Please run: `pip install optuna` to install.
Alternately, you can install this by running `pip install pycaret[tuners]`
NoneType: None
2024-08-18 00:51:35,731:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:51:35,732:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:51:35,732:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:51:35,732:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:53:47,211:INFO:PyCaret ClassificationExperiment
2024-08-18 00:53:47,211:INFO:Logging name: codepro_model_exp01
2024-08-18 00:53:47,211:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-08-18 00:53:47,211:INFO:version 3.3.2
2024-08-18 00:53:47,211:INFO:Initializing setup()
2024-08-18 00:53:47,211:INFO:self.USI: 6303
2024-08-18 00:53:47,211:INFO:self._variable_keys: {'exp_id', 'exp_name_log', 'html_param', 'fold_groups_param', 'log_plots_param', 'is_multiclass', 'data', '_available_plots', '_ml_usecase', 'X', 'gpu_param', 'idx', 'X_test', 'gpu_n_jobs_param', 'pipeline', 'memory', 'seed', 'y_test', 'USI', 'fold_shuffle_param', 'fold_generator', 'fix_imbalance', 'X_train', 'logging_param', 'n_jobs_param', 'target_param', 'y_train', 'y'}
2024-08-18 00:53:47,211:INFO:Checking environment
2024-08-18 00:53:47,211:INFO:python_version: 3.10.9
2024-08-18 00:53:47,211:INFO:python_build: ('main', 'Mar  1 2023 12:33:47')
2024-08-18 00:53:47,211:INFO:machine: x86_64
2024-08-18 00:53:47,211:INFO:platform: macOS-10.16-x86_64-i386-64bit
2024-08-18 00:53:47,211:INFO:Memory: svmem(total=17179869184, available=6214111232, percent=63.8, used=10332164096, free=111042560, active=6108622848, inactive=6087073792, wired=4223541248)
2024-08-18 00:53:47,211:INFO:Physical Core: 6
2024-08-18 00:53:47,212:INFO:Logical Core: 12
2024-08-18 00:53:47,212:INFO:Checking libraries
2024-08-18 00:53:47,212:INFO:System:
2024-08-18 00:53:47,212:INFO:    python: 3.10.9 (main, Mar  1 2023, 12:33:47) [Clang 14.0.6 ]
2024-08-18 00:53:47,212:INFO:executable: /Users/I500955/anaconda3/bin/python
2024-08-18 00:53:47,212:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2024-08-18 00:53:47,212:INFO:PyCaret required dependencies:
2024-08-18 00:53:47,214:INFO:                 pip: 22.3.1
2024-08-18 00:53:47,214:INFO:          setuptools: 65.6.3
2024-08-18 00:53:47,214:INFO:             pycaret: 3.3.2
2024-08-18 00:53:47,214:INFO:             IPython: 8.10.0
2024-08-18 00:53:47,214:INFO:          ipywidgets: 7.6.5
2024-08-18 00:53:47,214:INFO:                tqdm: 4.64.1
2024-08-18 00:53:47,214:INFO:               numpy: 1.23.5
2024-08-18 00:53:47,214:INFO:              pandas: 2.2.2
2024-08-18 00:53:47,214:INFO:              jinja2: 3.1.2
2024-08-18 00:53:47,214:INFO:               scipy: 1.10.0
2024-08-18 00:53:47,214:INFO:              joblib: 1.3.2
2024-08-18 00:53:47,214:INFO:             sklearn: 1.4.2
2024-08-18 00:53:47,214:INFO:                pyod: 2.0.1
2024-08-18 00:53:47,214:INFO:            imblearn: 0.12.3
2024-08-18 00:53:47,214:INFO:   category_encoders: 2.6.3
2024-08-18 00:53:47,214:INFO:            lightgbm: 4.5.0
2024-08-18 00:53:47,215:INFO:               numba: 0.56.4
2024-08-18 00:53:47,215:INFO:            requests: 2.28.1
2024-08-18 00:53:47,215:INFO:          matplotlib: 3.7.0
2024-08-18 00:53:47,215:INFO:          scikitplot: 0.3.7
2024-08-18 00:53:47,215:INFO:         yellowbrick: 1.5
2024-08-18 00:53:47,215:INFO:              plotly: 5.23.0
2024-08-18 00:53:47,215:INFO:    plotly-resampler: Not installed
2024-08-18 00:53:47,215:INFO:             kaleido: 0.2.1
2024-08-18 00:53:47,215:INFO:           schemdraw: 0.15
2024-08-18 00:53:47,215:INFO:         statsmodels: 0.13.5
2024-08-18 00:53:47,215:INFO:              sktime: 0.26.0
2024-08-18 00:53:47,215:INFO:               tbats: 1.1.3
2024-08-18 00:53:47,215:INFO:            pmdarima: 2.0.4
2024-08-18 00:53:47,215:INFO:              psutil: 5.9.0
2024-08-18 00:53:47,215:INFO:          markupsafe: 2.1.1
2024-08-18 00:53:47,215:INFO:             pickle5: Not installed
2024-08-18 00:53:47,215:INFO:         cloudpickle: 3.0.0
2024-08-18 00:53:47,215:INFO:         deprecation: 2.1.0
2024-08-18 00:53:47,215:INFO:              xxhash: 3.5.0
2024-08-18 00:53:47,215:INFO:           wurlitzer: 3.0.2
2024-08-18 00:53:47,215:INFO:PyCaret optional dependencies:
2024-08-18 00:53:47,229:INFO:                shap: Not installed
2024-08-18 00:53:47,229:INFO:           interpret: Not installed
2024-08-18 00:53:47,229:INFO:                umap: Not installed
2024-08-18 00:53:47,229:INFO:     ydata_profiling: 4.9.0
2024-08-18 00:53:47,230:INFO:  explainerdashboard: Not installed
2024-08-18 00:53:47,230:INFO:             autoviz: Not installed
2024-08-18 00:53:47,230:INFO:           fairlearn: Not installed
2024-08-18 00:53:47,230:INFO:          deepchecks: Not installed
2024-08-18 00:53:47,230:INFO:             xgboost: Not installed
2024-08-18 00:53:47,230:INFO:            catboost: Not installed
2024-08-18 00:53:47,230:INFO:              kmodes: Not installed
2024-08-18 00:53:47,230:INFO:             mlxtend: Not installed
2024-08-18 00:53:47,230:INFO:       statsforecast: Not installed
2024-08-18 00:53:47,230:INFO:        tune_sklearn: 0.5.0
2024-08-18 00:53:47,230:INFO:                 ray: 2.34.0
2024-08-18 00:53:47,230:INFO:            hyperopt: 0.2.7
2024-08-18 00:53:47,230:INFO:              optuna: 3.6.1
2024-08-18 00:53:47,230:INFO:               skopt: 0.10.2
2024-08-18 00:53:47,230:INFO:              mlflow: 2.15.1
2024-08-18 00:53:47,230:INFO:              gradio: Not installed
2024-08-18 00:53:47,230:INFO:             fastapi: Not installed
2024-08-18 00:53:47,230:INFO:             uvicorn: Not installed
2024-08-18 00:53:47,230:INFO:              m2cgen: Not installed
2024-08-18 00:53:47,230:INFO:           evidently: Not installed
2024-08-18 00:53:47,230:INFO:               fugue: Not installed
2024-08-18 00:53:47,230:INFO:           streamlit: Not installed
2024-08-18 00:53:47,230:INFO:             prophet: Not installed
2024-08-18 00:53:47,230:INFO:None
2024-08-18 00:53:47,230:INFO:Set up GPU usage.
2024-08-18 00:53:47,230:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:53:47,231:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2024-08-18 00:53:47,231:INFO:Set up data.
2024-08-18 00:53:47,307:INFO:Set up folding strategy.
2024-08-18 00:53:47,307:INFO:Set up train/test split.
2024-08-18 00:53:47,429:INFO:Set up index.
2024-08-18 00:53:47,438:INFO:Assigning column types.
2024-08-18 00:53:47,493:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-08-18 00:53:47,494:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:53:47,537:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-18 00:53:47,538:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:53:47,565:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:53:47,566:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-18 00:53:47,566:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:53:47,591:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:53:47,596:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:53:47,614:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-18 00:53:47,677:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-18 00:53:47,678:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:53:47,727:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-18 00:53:47,727:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:53:47,727:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:53:47,728:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-18 00:53:47,728:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:53:47,748:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:53:47,752:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:53:47,753:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-18 00:53:47,756:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-18 00:53:47,757:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-08-18 00:53:47,757:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:53:47,797:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:53:47,797:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:53:47,798:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-18 00:53:47,798:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:53:47,818:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:53:47,822:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:53:47,822:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-18 00:53:47,826:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-18 00:53:47,826:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:53:47,872:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:53:47,873:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:53:47,873:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-18 00:53:47,874:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:53:47,898:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:53:47,902:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:53:47,903:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-18 00:53:47,908:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-18 00:53:47,909:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-08-18 00:53:47,909:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:53:47,969:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:53:47,969:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:53:47,970:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:53:47,995:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:53:47,999:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:53:48,001:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-18 00:53:48,004:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-18 00:53:48,005:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:53:48,056:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:53:48,056:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:53:48,057:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:53:48,080:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:53:48,084:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:53:48,085:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-18 00:53:48,088:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-18 00:53:48,113:INFO:Preparing preprocessing pipeline...
2024-08-18 00:53:48,124:INFO:Set up simple imputation.
2024-08-18 00:53:48,156:INFO:Set up encoding of categorical features.
2024-08-18 00:53:48,472:INFO:Finished creating preprocessing pipeline.
2024-08-18 00:53:48,484:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['city_tier',
                                             'total_leads_droppped',
                                             'referred_lead',
                                             'assistance_interaction',
                                             'career_interaction',
                                             'payment_interaction',
                                             'social_interaction',
                                             'syllabus_interaction'],
                                    transformer=SimpleImpute...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-08-18 00:53:48,484:INFO:Creating final display dataframe.
2024-08-18 00:53:50,315:INFO:Setup _display_container:                     Description                Value
0                    Session id                  123
1                        Target    app_complete_flag
2                   Target type               Binary
3           Original data shape         (227016, 12)
4        Transformed data shape         (227016, 44)
5   Transformed train set shape         (158911, 44)
6    Transformed test set shape          (68105, 44)
7              Numeric features                    8
8          Categorical features                    3
9                    Preprocess                 True
10              Imputation type               simple
11           Numeric imputation                 mean
12       Categorical imputation                 mode
13     Maximum one-hot encoding                   25
14              Encoding method                 None
15               Fold Generator      StratifiedKFold
16                  Fold Number                   10
17                     CPU Jobs                   -1
18                      Use GPU                 True
19               Log Experiment         MlflowLogger
20              Experiment Name  codepro_model_exp01
21                          USI                 6303
2024-08-18 00:53:50,323:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:53:50,374:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:53:50,374:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:53:50,374:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:53:50,395:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:53:50,399:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:53:50,399:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-18 00:53:50,403:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-18 00:53:50,404:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:53:50,443:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:53:50,444:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:53:50,445:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:53:50,473:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:53:50,478:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:53:50,480:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-18 00:53:50,483:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-18 00:53:50,484:INFO:Logging experiment in loggers
2024-08-18 00:53:53,319:INFO:SubProcess save_model() called ==================================
2024-08-18 00:53:53,331:INFO:Initializing save_model()
2024-08-18 00:53:53,331:INFO:save_model(model=Pipeline(memory=FastMemory(location=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['city_tier',
                                             'total_leads_droppped',
                                             'referred_lead',
                                             'assistance_interaction',
                                             'career_interaction',
                                             'payment_interaction',
                                             'social_interaction',
                                             'syllabus_interaction'],
                                    transformer=SimpleImpute...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), model_name=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmp3ie_k8w7/Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['city_tier',
                                             'total_leads_droppped',
                                             'referred_lead',
                                             'assistance_interaction',
                                             'career_interaction',
                                             'payment_interaction',
                                             'social_interaction',
                                             'syllabus_interaction'],
                                    transformer=SimpleImpute...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-08-18 00:53:53,331:INFO:Adding model into prep_pipe
2024-08-18 00:53:53,331:WARNING:Only Model saved as it was a pipeline.
2024-08-18 00:53:53,341:INFO:/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmp3ie_k8w7/Transformation Pipeline.pkl saved in current working directory
2024-08-18 00:53:53,347:INFO:Pipeline(memory=FastMemory(location=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['city_tier',
                                             'total_leads_droppped',
                                             'referred_lead',
                                             'assistance_interaction',
                                             'career_interaction',
                                             'payment_interaction',
                                             'social_interaction',
                                             'syllabus_interaction'],
                                    transformer=SimpleImpute...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-08-18 00:53:53,347:INFO:save_model() successfully completed......................................
2024-08-18 00:53:53,504:INFO:SubProcess save_model() end ==================================
2024-08-18 00:53:55,063:INFO:setup() successfully completed in 3.4s...............
2024-08-18 00:55:09,734:INFO:Initializing compare_models()
2024-08-18 00:55:09,734:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd67a2df2e0>, include=None, fold=5, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7fd67a2df2e0>, 'include': None, 'exclude': ['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada'], 'fold': 5, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada'])
2024-08-18 00:55:09,735:INFO:Checking exceptions
2024-08-18 00:55:09,803:INFO:Preparing display monitor
2024-08-18 00:55:09,874:INFO:Initializing Logistic Regression
2024-08-18 00:55:09,874:INFO:Total runtime is 7.351239522298177e-06 minutes
2024-08-18 00:55:09,881:INFO:SubProcess create_model() called ==================================
2024-08-18 00:55:09,881:INFO:Initializing create_model()
2024-08-18 00:55:09,881:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd67a2df2e0>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fd67a812620>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-18 00:55:09,881:INFO:Checking exceptions
2024-08-18 00:55:09,882:INFO:Importing libraries
2024-08-18 00:55:09,882:INFO:Copying training dataset
2024-08-18 00:55:09,981:INFO:Defining folds
2024-08-18 00:55:09,981:INFO:Declaring metric variables
2024-08-18 00:55:09,986:INFO:Importing untrained model
2024-08-18 00:55:09,990:INFO:Logistic Regression Imported successfully
2024-08-18 00:55:09,999:INFO:Starting cross validation
2024-08-18 00:55:10,003:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-08-18 00:55:21,170:INFO:Calculating mean and std
2024-08-18 00:55:21,171:INFO:Creating metrics dataframe
2024-08-18 00:55:21,173:INFO:Uploading results into container
2024-08-18 00:55:21,173:INFO:Uploading model into container now
2024-08-18 00:55:21,174:INFO:_master_model_container: 1
2024-08-18 00:55:21,174:INFO:_display_container: 2
2024-08-18 00:55:21,174:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-08-18 00:55:21,175:INFO:create_model() successfully completed......................................
2024-08-18 00:55:21,321:INFO:SubProcess create_model() end ==================================
2024-08-18 00:55:21,322:INFO:Creating metrics dataframe
2024-08-18 00:55:21,332:INFO:Initializing Naive Bayes
2024-08-18 00:55:21,332:INFO:Total runtime is 0.19097388188044231 minutes
2024-08-18 00:55:21,336:INFO:SubProcess create_model() called ==================================
2024-08-18 00:55:21,337:INFO:Initializing create_model()
2024-08-18 00:55:21,337:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd67a2df2e0>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fd67a812620>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-18 00:55:21,337:INFO:Checking exceptions
2024-08-18 00:55:21,337:INFO:Importing libraries
2024-08-18 00:55:21,337:INFO:Copying training dataset
2024-08-18 00:55:21,430:INFO:Defining folds
2024-08-18 00:55:21,430:INFO:Declaring metric variables
2024-08-18 00:55:21,434:INFO:Importing untrained model
2024-08-18 00:55:21,438:INFO:Naive Bayes Imported successfully
2024-08-18 00:55:21,446:INFO:Starting cross validation
2024-08-18 00:55:21,448:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-08-18 00:55:28,545:INFO:Calculating mean and std
2024-08-18 00:55:28,546:INFO:Creating metrics dataframe
2024-08-18 00:55:28,548:INFO:Uploading results into container
2024-08-18 00:55:28,549:INFO:Uploading model into container now
2024-08-18 00:55:28,549:INFO:_master_model_container: 2
2024-08-18 00:55:28,549:INFO:_display_container: 2
2024-08-18 00:55:28,549:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-08-18 00:55:28,549:INFO:create_model() successfully completed......................................
2024-08-18 00:55:28,679:INFO:SubProcess create_model() end ==================================
2024-08-18 00:55:28,679:INFO:Creating metrics dataframe
2024-08-18 00:55:28,689:INFO:Initializing Decision Tree Classifier
2024-08-18 00:55:28,689:INFO:Total runtime is 0.3135903835296631 minutes
2024-08-18 00:55:28,693:INFO:SubProcess create_model() called ==================================
2024-08-18 00:55:28,693:INFO:Initializing create_model()
2024-08-18 00:55:28,693:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd67a2df2e0>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fd67a812620>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-18 00:55:28,693:INFO:Checking exceptions
2024-08-18 00:55:28,694:INFO:Importing libraries
2024-08-18 00:55:28,694:INFO:Copying training dataset
2024-08-18 00:55:28,779:INFO:Defining folds
2024-08-18 00:55:28,779:INFO:Declaring metric variables
2024-08-18 00:55:28,782:INFO:Importing untrained model
2024-08-18 00:55:28,786:INFO:Decision Tree Classifier Imported successfully
2024-08-18 00:55:28,793:INFO:Starting cross validation
2024-08-18 00:55:28,795:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-08-18 00:55:37,900:INFO:Calculating mean and std
2024-08-18 00:55:37,901:INFO:Creating metrics dataframe
2024-08-18 00:55:37,903:INFO:Uploading results into container
2024-08-18 00:55:37,903:INFO:Uploading model into container now
2024-08-18 00:55:37,904:INFO:_master_model_container: 3
2024-08-18 00:55:37,904:INFO:_display_container: 2
2024-08-18 00:55:37,905:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2024-08-18 00:55:37,905:INFO:create_model() successfully completed......................................
2024-08-18 00:55:38,023:INFO:SubProcess create_model() end ==================================
2024-08-18 00:55:38,023:INFO:Creating metrics dataframe
2024-08-18 00:55:38,034:INFO:Initializing Ridge Classifier
2024-08-18 00:55:38,034:INFO:Total runtime is 0.46933763424555464 minutes
2024-08-18 00:55:38,038:INFO:SubProcess create_model() called ==================================
2024-08-18 00:55:38,038:INFO:Initializing create_model()
2024-08-18 00:55:38,038:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd67a2df2e0>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fd67a812620>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-18 00:55:38,038:INFO:Checking exceptions
2024-08-18 00:55:38,039:INFO:Importing libraries
2024-08-18 00:55:38,039:INFO:Copying training dataset
2024-08-18 00:55:38,126:INFO:Defining folds
2024-08-18 00:55:38,126:INFO:Declaring metric variables
2024-08-18 00:55:38,130:INFO:Importing untrained model
2024-08-18 00:55:38,134:INFO:Ridge Classifier Imported successfully
2024-08-18 00:55:38,141:INFO:Starting cross validation
2024-08-18 00:55:38,143:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-08-18 00:55:45,155:INFO:Calculating mean and std
2024-08-18 00:55:45,156:INFO:Creating metrics dataframe
2024-08-18 00:55:45,158:INFO:Uploading results into container
2024-08-18 00:55:45,159:INFO:Uploading model into container now
2024-08-18 00:55:45,159:INFO:_master_model_container: 4
2024-08-18 00:55:45,160:INFO:_display_container: 2
2024-08-18 00:55:45,160:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-08-18 00:55:45,161:INFO:create_model() successfully completed......................................
2024-08-18 00:55:45,273:INFO:SubProcess create_model() end ==================================
2024-08-18 00:55:45,274:INFO:Creating metrics dataframe
2024-08-18 00:55:45,283:INFO:Initializing Random Forest Classifier
2024-08-18 00:55:45,283:INFO:Total runtime is 0.5901599168777466 minutes
2024-08-18 00:55:45,287:INFO:SubProcess create_model() called ==================================
2024-08-18 00:55:45,288:INFO:Initializing create_model()
2024-08-18 00:55:45,288:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd67a2df2e0>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fd67a812620>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-18 00:55:45,288:INFO:Checking exceptions
2024-08-18 00:55:45,288:INFO:Importing libraries
2024-08-18 00:55:45,288:INFO:Copying training dataset
2024-08-18 00:55:45,369:INFO:Defining folds
2024-08-18 00:55:45,369:INFO:Declaring metric variables
2024-08-18 00:55:45,373:INFO:Importing untrained model
2024-08-18 00:55:45,377:INFO:Random Forest Classifier Imported successfully
2024-08-18 00:55:45,383:INFO:Starting cross validation
2024-08-18 00:55:45,386:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-08-18 00:56:13,886:INFO:Calculating mean and std
2024-08-18 00:56:13,887:INFO:Creating metrics dataframe
2024-08-18 00:56:13,889:INFO:Uploading results into container
2024-08-18 00:56:13,889:INFO:Uploading model into container now
2024-08-18 00:56:13,890:INFO:_master_model_container: 5
2024-08-18 00:56:13,890:INFO:_display_container: 2
2024-08-18 00:56:13,890:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-08-18 00:56:13,890:INFO:create_model() successfully completed......................................
2024-08-18 00:56:14,012:INFO:SubProcess create_model() end ==================================
2024-08-18 00:56:14,012:INFO:Creating metrics dataframe
2024-08-18 00:56:14,023:INFO:Initializing Linear Discriminant Analysis
2024-08-18 00:56:14,023:INFO:Total runtime is 1.0691619992256165 minutes
2024-08-18 00:56:14,028:INFO:SubProcess create_model() called ==================================
2024-08-18 00:56:14,028:INFO:Initializing create_model()
2024-08-18 00:56:14,029:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd67a2df2e0>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fd67a812620>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-18 00:56:14,029:INFO:Checking exceptions
2024-08-18 00:56:14,029:INFO:Importing libraries
2024-08-18 00:56:14,030:INFO:Copying training dataset
2024-08-18 00:56:14,114:INFO:Defining folds
2024-08-18 00:56:14,115:INFO:Declaring metric variables
2024-08-18 00:56:14,118:INFO:Importing untrained model
2024-08-18 00:56:14,122:INFO:Linear Discriminant Analysis Imported successfully
2024-08-18 00:56:14,129:INFO:Starting cross validation
2024-08-18 00:56:14,131:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-08-18 00:56:25,999:INFO:Calculating mean and std
2024-08-18 00:56:26,001:INFO:Creating metrics dataframe
2024-08-18 00:56:26,003:INFO:Uploading results into container
2024-08-18 00:56:26,003:INFO:Uploading model into container now
2024-08-18 00:56:26,004:INFO:_master_model_container: 6
2024-08-18 00:56:26,004:INFO:_display_container: 2
2024-08-18 00:56:26,004:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-08-18 00:56:26,004:INFO:create_model() successfully completed......................................
2024-08-18 00:56:26,116:INFO:SubProcess create_model() end ==================================
2024-08-18 00:56:26,116:INFO:Creating metrics dataframe
2024-08-18 00:56:26,127:INFO:Initializing Extra Trees Classifier
2024-08-18 00:56:26,127:INFO:Total runtime is 1.2708959817886354 minutes
2024-08-18 00:56:26,132:INFO:SubProcess create_model() called ==================================
2024-08-18 00:56:26,133:INFO:Initializing create_model()
2024-08-18 00:56:26,133:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd67a2df2e0>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fd67a812620>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-18 00:56:26,133:INFO:Checking exceptions
2024-08-18 00:56:26,133:INFO:Importing libraries
2024-08-18 00:56:26,133:INFO:Copying training dataset
2024-08-18 00:56:26,216:INFO:Defining folds
2024-08-18 00:56:26,216:INFO:Declaring metric variables
2024-08-18 00:56:26,220:INFO:Importing untrained model
2024-08-18 00:56:26,223:INFO:Extra Trees Classifier Imported successfully
2024-08-18 00:56:26,231:INFO:Starting cross validation
2024-08-18 00:56:26,234:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-08-18 00:56:55,596:INFO:Calculating mean and std
2024-08-18 00:56:55,598:INFO:Creating metrics dataframe
2024-08-18 00:56:55,599:INFO:Uploading results into container
2024-08-18 00:56:55,600:INFO:Uploading model into container now
2024-08-18 00:56:55,600:INFO:_master_model_container: 7
2024-08-18 00:56:55,600:INFO:_display_container: 2
2024-08-18 00:56:55,601:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2024-08-18 00:56:55,601:INFO:create_model() successfully completed......................................
2024-08-18 00:56:55,719:INFO:SubProcess create_model() end ==================================
2024-08-18 00:56:55,719:INFO:Creating metrics dataframe
2024-08-18 00:56:55,730:INFO:Initializing Light Gradient Boosting Machine
2024-08-18 00:56:55,730:INFO:Total runtime is 1.7642731507619223 minutes
2024-08-18 00:56:55,734:INFO:SubProcess create_model() called ==================================
2024-08-18 00:56:55,734:INFO:Initializing create_model()
2024-08-18 00:56:55,734:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd67a2df2e0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fd67a812620>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-18 00:56:55,734:INFO:Checking exceptions
2024-08-18 00:56:55,734:INFO:Importing libraries
2024-08-18 00:56:55,734:INFO:Copying training dataset
2024-08-18 00:56:55,815:INFO:Defining folds
2024-08-18 00:56:55,815:INFO:Declaring metric variables
2024-08-18 00:56:55,818:INFO:Importing untrained model
2024-08-18 00:56:55,822:INFO:Light Gradient Boosting Machine Imported successfully
2024-08-18 00:56:55,829:INFO:Starting cross validation
2024-08-18 00:56:55,832:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-08-18 00:56:56,908:INFO:[LightGBM] [Info] Number of positive: 63832, number of negative: 63296
2024-08-18 00:56:56,919:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003185 seconds.
2024-08-18 00:56:56,919:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-18 00:56:56,919:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-18 00:56:56,919:INFO:[LightGBM] [Info] Total Bins 149
2024-08-18 00:56:56,920:INFO:[LightGBM] [Info] Number of data points in the train set: 127128, number of used features: 41
2024-08-18 00:56:56,923:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502108 -> initscore=0.008432
2024-08-18 00:56:56,923:INFO:[LightGBM] [Info] Start training from score 0.008432
2024-08-18 00:56:58,914:INFO:[LightGBM] [Info] Number of positive: 63833, number of negative: 63296
2024-08-18 00:56:58,923:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001903 seconds.
2024-08-18 00:56:58,923:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-18 00:56:58,923:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-18 00:56:58,923:INFO:[LightGBM] [Info] Total Bins 152
2024-08-18 00:56:58,923:INFO:[LightGBM] [Info] Number of data points in the train set: 127129, number of used features: 41
2024-08-18 00:56:58,925:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502112 -> initscore=0.008448
2024-08-18 00:56:58,925:INFO:[LightGBM] [Info] Start training from score 0.008448
2024-08-18 00:57:00,409:INFO:[LightGBM] [Info] Number of positive: 63833, number of negative: 63296
2024-08-18 00:57:00,417:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001744 seconds.
2024-08-18 00:57:00,417:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-18 00:57:00,417:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-18 00:57:00,417:INFO:[LightGBM] [Info] Total Bins 159
2024-08-18 00:57:00,417:INFO:[LightGBM] [Info] Number of data points in the train set: 127129, number of used features: 42
2024-08-18 00:57:00,419:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502112 -> initscore=0.008448
2024-08-18 00:57:00,419:INFO:[LightGBM] [Info] Start training from score 0.008448
2024-08-18 00:57:01,923:INFO:[LightGBM] [Info] Number of positive: 63833, number of negative: 63296
2024-08-18 00:57:01,932:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002727 seconds.
2024-08-18 00:57:01,932:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-18 00:57:01,933:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-18 00:57:01,933:INFO:[LightGBM] [Info] Total Bins 162
2024-08-18 00:57:01,933:INFO:[LightGBM] [Info] Number of data points in the train set: 127129, number of used features: 42
2024-08-18 00:57:01,934:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502112 -> initscore=0.008448
2024-08-18 00:57:01,934:INFO:[LightGBM] [Info] Start training from score 0.008448
2024-08-18 00:57:03,556:INFO:[LightGBM] [Info] Number of positive: 63833, number of negative: 63296
2024-08-18 00:57:03,565:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002275 seconds.
2024-08-18 00:57:03,565:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-18 00:57:03,565:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-18 00:57:03,565:INFO:[LightGBM] [Info] Total Bins 152
2024-08-18 00:57:03,565:INFO:[LightGBM] [Info] Number of data points in the train set: 127129, number of used features: 41
2024-08-18 00:57:03,567:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502112 -> initscore=0.008448
2024-08-18 00:57:03,567:INFO:[LightGBM] [Info] Start training from score 0.008448
2024-08-18 00:57:04,194:INFO:Calculating mean and std
2024-08-18 00:57:04,195:INFO:Creating metrics dataframe
2024-08-18 00:57:04,198:INFO:Uploading results into container
2024-08-18 00:57:04,198:INFO:Uploading model into container now
2024-08-18 00:57:04,199:INFO:_master_model_container: 8
2024-08-18 00:57:04,199:INFO:_display_container: 2
2024-08-18 00:57:04,200:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-08-18 00:57:04,200:INFO:create_model() successfully completed......................................
2024-08-18 00:57:04,317:INFO:SubProcess create_model() end ==================================
2024-08-18 00:57:04,317:INFO:Creating metrics dataframe
2024-08-18 00:57:04,339:INFO:Initializing create_model()
2024-08-18 00:57:04,339:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd67a2df2e0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-18 00:57:04,339:INFO:Checking exceptions
2024-08-18 00:57:04,342:INFO:Importing libraries
2024-08-18 00:57:04,342:INFO:Copying training dataset
2024-08-18 00:57:04,422:INFO:Defining folds
2024-08-18 00:57:04,422:INFO:Declaring metric variables
2024-08-18 00:57:04,422:INFO:Importing untrained model
2024-08-18 00:57:04,422:INFO:Declaring custom model
2024-08-18 00:57:04,423:INFO:Random Forest Classifier Imported successfully
2024-08-18 00:57:04,424:INFO:Cross validation set to False
2024-08-18 00:57:04,425:INFO:Fitting Model
2024-08-18 00:57:11,309:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-08-18 00:57:11,309:INFO:create_model() successfully completed......................................
2024-08-18 00:57:11,437:INFO:Creating Dashboard logs
2024-08-18 00:57:11,442:INFO:Model: Random Forest Classifier
2024-08-18 00:57:11,490:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2024-08-18 00:57:11,726:INFO:Initializing predict_model()
2024-08-18 00:57:11,726:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd67a2df2e0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fd67b39f5b0>)
2024-08-18 00:57:11,726:INFO:Checking exceptions
2024-08-18 00:57:11,726:INFO:Preloading libraries
2024-08-18 00:57:12,732:INFO:SubProcess plot_model() called ==================================
2024-08-18 00:57:12,733:INFO:Initializing plot_model()
2024-08-18 00:57:12,733:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmpmxt3dorq, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd67a2df2e0>, system=False)
2024-08-18 00:57:12,733:INFO:Checking exceptions
2024-08-18 00:57:12,795:INFO:Preloading libraries
2024-08-18 00:57:12,861:INFO:Copying training dataset
2024-08-18 00:57:12,862:INFO:Plot type: auc
2024-08-18 00:57:13,413:INFO:Fitting Model
2024-08-18 00:57:13,420:INFO:Scoring test/hold-out set
2024-08-18 00:57:13,891:INFO:Saving '/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmpmxt3dorq/AUC.png'
2024-08-18 00:57:14,196:INFO:Visual Rendered Successfully
2024-08-18 00:57:14,317:INFO:plot_model() successfully completed......................................
2024-08-18 00:57:14,331:INFO:Initializing plot_model()
2024-08-18 00:57:14,331:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmpmxt3dorq, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd67a2df2e0>, system=False)
2024-08-18 00:57:14,331:INFO:Checking exceptions
2024-08-18 00:57:14,389:INFO:Preloading libraries
2024-08-18 00:57:14,452:INFO:Copying training dataset
2024-08-18 00:57:14,452:INFO:Plot type: confusion_matrix
2024-08-18 00:57:14,934:INFO:Fitting Model
2024-08-18 00:57:14,938:INFO:Scoring test/hold-out set
2024-08-18 00:57:15,286:INFO:Saving '/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmpmxt3dorq/Confusion Matrix.png'
2024-08-18 00:57:15,401:INFO:Visual Rendered Successfully
2024-08-18 00:57:15,522:INFO:plot_model() successfully completed......................................
2024-08-18 00:57:15,538:INFO:Initializing plot_model()
2024-08-18 00:57:15,538:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmpmxt3dorq, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd67a2df2e0>, system=False)
2024-08-18 00:57:15,538:INFO:Checking exceptions
2024-08-18 00:57:15,600:INFO:Preloading libraries
2024-08-18 00:57:15,663:INFO:Copying training dataset
2024-08-18 00:57:15,663:INFO:Plot type: feature
2024-08-18 00:57:15,663:WARNING:No coef_ found. Trying feature_importances_
2024-08-18 00:57:15,861:INFO:Saving '/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmpmxt3dorq/Feature Importance.png'
2024-08-18 00:57:16,039:INFO:Visual Rendered Successfully
2024-08-18 00:57:16,156:INFO:plot_model() successfully completed......................................
2024-08-18 00:57:16,169:INFO:SubProcess plot_model() end ==================================
2024-08-18 00:57:18,785:INFO:Creating Dashboard logs
2024-08-18 00:57:18,789:INFO:Model: Naive Bayes
2024-08-18 00:57:18,832:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2024-08-18 00:57:19,308:INFO:Creating Dashboard logs
2024-08-18 00:57:19,313:INFO:Model: Extra Trees Classifier
2024-08-18 00:57:19,361:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2024-08-18 00:57:19,853:INFO:Creating Dashboard logs
2024-08-18 00:57:19,858:INFO:Model: Decision Tree Classifier
2024-08-18 00:57:19,912:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 123, 'splitter': 'best'}
2024-08-18 00:57:20,380:INFO:Creating Dashboard logs
2024-08-18 00:57:20,385:INFO:Model: Logistic Regression
2024-08-18 00:57:20,460:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 123, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2024-08-18 00:57:20,952:INFO:Creating Dashboard logs
2024-08-18 00:57:20,957:INFO:Model: Light Gradient Boosting Machine
2024-08-18 00:57:20,991:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2024-08-18 00:57:21,485:INFO:Creating Dashboard logs
2024-08-18 00:57:21,489:INFO:Model: Ridge Classifier
2024-08-18 00:57:21,532:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 123, 'solver': 'auto', 'tol': 0.0001}
2024-08-18 00:57:22,049:INFO:Creating Dashboard logs
2024-08-18 00:57:22,054:INFO:Model: Linear Discriminant Analysis
2024-08-18 00:57:22,085:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2024-08-18 00:57:22,608:INFO:_master_model_container: 8
2024-08-18 00:57:22,608:INFO:_display_container: 2
2024-08-18 00:57:22,609:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-08-18 00:57:22,609:INFO:compare_models() successfully completed......................................
2024-08-18 00:57:38,574:INFO:Initializing create_model()
2024-08-18 00:57:38,574:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd67a2df2e0>, estimator=rf, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-18 00:57:38,574:INFO:Checking exceptions
2024-08-18 00:57:38,600:INFO:Importing libraries
2024-08-18 00:57:38,600:INFO:Copying training dataset
2024-08-18 00:57:38,712:INFO:Defining folds
2024-08-18 00:57:38,712:INFO:Declaring metric variables
2024-08-18 00:57:38,717:INFO:Importing untrained model
2024-08-18 00:57:38,721:INFO:Random Forest Classifier Imported successfully
2024-08-18 00:57:38,730:INFO:Starting cross validation
2024-08-18 00:57:38,733:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-08-18 00:58:05,550:INFO:Calculating mean and std
2024-08-18 00:58:05,551:INFO:Creating metrics dataframe
2024-08-18 00:58:05,557:INFO:Finalizing model
2024-08-18 00:58:12,375:INFO:Creating Dashboard logs
2024-08-18 00:58:12,381:INFO:Model: Random Forest Classifier
2024-08-18 00:58:12,410:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2024-08-18 00:58:12,611:INFO:Initializing predict_model()
2024-08-18 00:58:12,611:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd67a2df2e0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fd67acc7910>)
2024-08-18 00:58:12,611:INFO:Checking exceptions
2024-08-18 00:58:12,611:INFO:Preloading libraries
2024-08-18 00:58:13,537:INFO:SubProcess plot_model() called ==================================
2024-08-18 00:58:13,537:INFO:Initializing plot_model()
2024-08-18 00:58:13,538:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmpq9ft9jev, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd67a2df2e0>, system=False)
2024-08-18 00:58:13,538:INFO:Checking exceptions
2024-08-18 00:58:13,599:INFO:Preloading libraries
2024-08-18 00:58:13,664:INFO:Copying training dataset
2024-08-18 00:58:13,664:INFO:Plot type: auc
2024-08-18 00:58:14,193:INFO:Fitting Model
2024-08-18 00:58:14,201:INFO:Scoring test/hold-out set
2024-08-18 00:58:14,611:INFO:Saving '/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmpq9ft9jev/AUC.png'
2024-08-18 00:58:14,844:INFO:Visual Rendered Successfully
2024-08-18 00:58:14,972:INFO:plot_model() successfully completed......................................
2024-08-18 00:58:14,985:INFO:Initializing plot_model()
2024-08-18 00:58:14,985:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmpq9ft9jev, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd67a2df2e0>, system=False)
2024-08-18 00:58:14,985:INFO:Checking exceptions
2024-08-18 00:58:15,037:INFO:Preloading libraries
2024-08-18 00:58:15,102:INFO:Copying training dataset
2024-08-18 00:58:15,102:INFO:Plot type: confusion_matrix
2024-08-18 00:58:15,637:INFO:Fitting Model
2024-08-18 00:58:15,641:INFO:Scoring test/hold-out set
2024-08-18 00:58:16,082:INFO:Saving '/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmpq9ft9jev/Confusion Matrix.png'
2024-08-18 00:58:16,205:INFO:Visual Rendered Successfully
2024-08-18 00:58:16,364:INFO:plot_model() successfully completed......................................
2024-08-18 00:58:16,383:INFO:Initializing plot_model()
2024-08-18 00:58:16,384:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmpq9ft9jev, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd67a2df2e0>, system=False)
2024-08-18 00:58:16,384:INFO:Checking exceptions
2024-08-18 00:58:16,457:INFO:Preloading libraries
2024-08-18 00:58:16,575:INFO:Copying training dataset
2024-08-18 00:58:16,575:INFO:Plot type: feature
2024-08-18 00:58:16,576:WARNING:No coef_ found. Trying feature_importances_
2024-08-18 00:58:16,961:INFO:Saving '/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmpq9ft9jev/Feature Importance.png'
2024-08-18 00:58:17,233:INFO:Visual Rendered Successfully
2024-08-18 00:58:17,370:INFO:plot_model() successfully completed......................................
2024-08-18 00:58:17,390:INFO:SubProcess plot_model() end ==================================
2024-08-18 00:58:17,757:INFO:Uploading results into container
2024-08-18 00:58:17,758:INFO:Uploading model into container now
2024-08-18 00:58:17,770:INFO:_master_model_container: 9
2024-08-18 00:58:17,771:INFO:_display_container: 3
2024-08-18 00:58:17,771:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-08-18 00:58:17,772:INFO:create_model() successfully completed......................................
2024-08-18 00:59:02,358:INFO:Initializing plot_model()
2024-08-18 00:59:02,358:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd67a2df2e0>, system=True)
2024-08-18 00:59:02,358:INFO:Checking exceptions
2024-08-18 00:59:02,420:INFO:Preloading libraries
2024-08-18 00:59:02,496:INFO:Copying training dataset
2024-08-18 00:59:02,496:INFO:Plot type: feature
2024-08-18 00:59:02,497:WARNING:No coef_ found. Trying feature_importances_
2024-08-18 00:59:02,847:INFO:Visual Rendered Successfully
2024-08-18 00:59:02,973:INFO:plot_model() successfully completed......................................
2024-08-18 00:59:08,617:INFO:PyCaret ClassificationExperiment
2024-08-18 00:59:08,617:INFO:Logging name: codepro_model_exp02
2024-08-18 00:59:08,617:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-08-18 00:59:08,617:INFO:version 3.3.2
2024-08-18 00:59:08,617:INFO:Initializing setup()
2024-08-18 00:59:08,617:INFO:self.USI: 189a
2024-08-18 00:59:08,617:INFO:self._variable_keys: {'exp_id', 'exp_name_log', 'html_param', 'fold_groups_param', 'log_plots_param', 'is_multiclass', 'data', '_available_plots', '_ml_usecase', 'X', 'gpu_param', 'idx', 'X_test', 'gpu_n_jobs_param', 'pipeline', 'memory', 'seed', 'y_test', 'USI', 'fold_shuffle_param', 'fold_generator', 'fix_imbalance', 'X_train', 'logging_param', 'n_jobs_param', 'target_param', 'y_train', 'y'}
2024-08-18 00:59:08,617:INFO:Checking environment
2024-08-18 00:59:08,617:INFO:python_version: 3.10.9
2024-08-18 00:59:08,617:INFO:python_build: ('main', 'Mar  1 2023 12:33:47')
2024-08-18 00:59:08,618:INFO:machine: x86_64
2024-08-18 00:59:08,618:INFO:platform: macOS-10.16-x86_64-i386-64bit
2024-08-18 00:59:08,618:INFO:Memory: svmem(total=17179869184, available=6108520448, percent=64.4, used=10149376000, free=180703232, active=5932969984, inactive=5917888512, wired=4216406016)
2024-08-18 00:59:08,618:INFO:Physical Core: 6
2024-08-18 00:59:08,618:INFO:Logical Core: 12
2024-08-18 00:59:08,618:INFO:Checking libraries
2024-08-18 00:59:08,618:INFO:System:
2024-08-18 00:59:08,618:INFO:    python: 3.10.9 (main, Mar  1 2023, 12:33:47) [Clang 14.0.6 ]
2024-08-18 00:59:08,618:INFO:executable: /Users/I500955/anaconda3/bin/python
2024-08-18 00:59:08,618:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2024-08-18 00:59:08,618:INFO:PyCaret required dependencies:
2024-08-18 00:59:08,618:INFO:                 pip: 22.3.1
2024-08-18 00:59:08,618:INFO:          setuptools: 65.6.3
2024-08-18 00:59:08,618:INFO:             pycaret: 3.3.2
2024-08-18 00:59:08,618:INFO:             IPython: 8.10.0
2024-08-18 00:59:08,618:INFO:          ipywidgets: 7.6.5
2024-08-18 00:59:08,618:INFO:                tqdm: 4.64.1
2024-08-18 00:59:08,618:INFO:               numpy: 1.23.5
2024-08-18 00:59:08,618:INFO:              pandas: 2.2.2
2024-08-18 00:59:08,619:INFO:              jinja2: 3.1.2
2024-08-18 00:59:08,619:INFO:               scipy: 1.10.0
2024-08-18 00:59:08,619:INFO:              joblib: 1.3.2
2024-08-18 00:59:08,619:INFO:             sklearn: 1.4.2
2024-08-18 00:59:08,619:INFO:                pyod: 2.0.1
2024-08-18 00:59:08,619:INFO:            imblearn: 0.12.3
2024-08-18 00:59:08,619:INFO:   category_encoders: 2.6.3
2024-08-18 00:59:08,619:INFO:            lightgbm: 4.5.0
2024-08-18 00:59:08,619:INFO:               numba: 0.56.4
2024-08-18 00:59:08,619:INFO:            requests: 2.28.1
2024-08-18 00:59:08,619:INFO:          matplotlib: 3.7.0
2024-08-18 00:59:08,619:INFO:          scikitplot: 0.3.7
2024-08-18 00:59:08,619:INFO:         yellowbrick: 1.5
2024-08-18 00:59:08,619:INFO:              plotly: 5.23.0
2024-08-18 00:59:08,619:INFO:    plotly-resampler: Not installed
2024-08-18 00:59:08,619:INFO:             kaleido: 0.2.1
2024-08-18 00:59:08,619:INFO:           schemdraw: 0.15
2024-08-18 00:59:08,619:INFO:         statsmodels: 0.13.5
2024-08-18 00:59:08,619:INFO:              sktime: 0.26.0
2024-08-18 00:59:08,619:INFO:               tbats: 1.1.3
2024-08-18 00:59:08,619:INFO:            pmdarima: 2.0.4
2024-08-18 00:59:08,619:INFO:              psutil: 5.9.0
2024-08-18 00:59:08,619:INFO:          markupsafe: 2.1.1
2024-08-18 00:59:08,619:INFO:             pickle5: Not installed
2024-08-18 00:59:08,619:INFO:         cloudpickle: 3.0.0
2024-08-18 00:59:08,619:INFO:         deprecation: 2.1.0
2024-08-18 00:59:08,620:INFO:              xxhash: 3.5.0
2024-08-18 00:59:08,620:INFO:           wurlitzer: 3.0.2
2024-08-18 00:59:08,620:INFO:PyCaret optional dependencies:
2024-08-18 00:59:08,620:INFO:                shap: Not installed
2024-08-18 00:59:08,620:INFO:           interpret: Not installed
2024-08-18 00:59:08,620:INFO:                umap: Not installed
2024-08-18 00:59:08,620:INFO:     ydata_profiling: 4.9.0
2024-08-18 00:59:08,620:INFO:  explainerdashboard: Not installed
2024-08-18 00:59:08,620:INFO:             autoviz: Not installed
2024-08-18 00:59:08,620:INFO:           fairlearn: Not installed
2024-08-18 00:59:08,620:INFO:          deepchecks: Not installed
2024-08-18 00:59:08,620:INFO:             xgboost: Not installed
2024-08-18 00:59:08,620:INFO:            catboost: Not installed
2024-08-18 00:59:08,620:INFO:              kmodes: Not installed
2024-08-18 00:59:08,620:INFO:             mlxtend: Not installed
2024-08-18 00:59:08,620:INFO:       statsforecast: Not installed
2024-08-18 00:59:08,620:INFO:        tune_sklearn: 0.5.0
2024-08-18 00:59:08,620:INFO:                 ray: 2.34.0
2024-08-18 00:59:08,620:INFO:            hyperopt: 0.2.7
2024-08-18 00:59:08,620:INFO:              optuna: 3.6.1
2024-08-18 00:59:08,620:INFO:               skopt: 0.10.2
2024-08-18 00:59:08,620:INFO:              mlflow: 2.15.1
2024-08-18 00:59:08,620:INFO:              gradio: Not installed
2024-08-18 00:59:08,620:INFO:             fastapi: Not installed
2024-08-18 00:59:08,621:INFO:             uvicorn: Not installed
2024-08-18 00:59:08,621:INFO:              m2cgen: Not installed
2024-08-18 00:59:08,621:INFO:           evidently: Not installed
2024-08-18 00:59:08,621:INFO:               fugue: Not installed
2024-08-18 00:59:08,621:INFO:           streamlit: Not installed
2024-08-18 00:59:08,621:INFO:             prophet: Not installed
2024-08-18 00:59:08,621:INFO:None
2024-08-18 00:59:08,621:INFO:Set up GPU usage.
2024-08-18 00:59:08,621:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:59:08,621:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2024-08-18 00:59:08,621:INFO:Set up data.
2024-08-18 00:59:08,675:INFO:Set up folding strategy.
2024-08-18 00:59:08,675:INFO:Set up train/test split.
2024-08-18 00:59:08,760:INFO:Set up index.
2024-08-18 00:59:08,769:INFO:Assigning column types.
2024-08-18 00:59:08,788:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-08-18 00:59:08,788:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:59:08,831:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-18 00:59:08,831:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:59:08,831:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:59:08,831:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-18 00:59:08,832:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:59:08,851:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:59:08,855:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:59:08,856:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-18 00:59:08,860:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-18 00:59:08,861:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:59:08,901:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-18 00:59:08,901:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:59:08,901:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:59:08,902:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-18 00:59:08,902:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:59:08,922:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:59:08,926:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:59:08,927:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-18 00:59:08,930:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-18 00:59:08,930:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-08-18 00:59:08,930:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:59:08,970:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:59:08,970:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:59:08,970:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-18 00:59:08,970:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:59:08,990:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:59:08,994:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:59:08,995:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-18 00:59:08,998:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-18 00:59:08,998:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:59:09,040:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:59:09,040:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:59:09,041:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-18 00:59:09,041:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:59:09,062:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:59:09,067:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:59:09,068:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-18 00:59:09,072:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-18 00:59:09,073:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-08-18 00:59:09,073:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:59:09,117:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:59:09,117:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:59:09,118:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:59:09,138:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:59:09,142:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:59:09,143:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-18 00:59:09,147:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-18 00:59:09,147:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:59:09,189:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:59:09,189:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:59:09,189:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:59:09,210:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:59:09,214:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:59:09,215:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-18 00:59:09,219:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-18 00:59:09,219:INFO:Preparing preprocessing pipeline...
2024-08-18 00:59:09,223:INFO:Set up simple imputation.
2024-08-18 00:59:09,240:INFO:Set up encoding of categorical features.
2024-08-18 00:59:09,890:INFO:Finished creating preprocessing pipeline.
2024-08-18 00:59:09,896:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_droppped',
                                             'city_tier', 'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-08-18 00:59:09,896:INFO:Creating final display dataframe.
2024-08-18 00:59:11,501:INFO:Setup _display_container:                     Description                Value
0                    Session id                 3263
1                        Target    app_complete_flag
2                   Target type               Binary
3           Original data shape          (227016, 7)
4        Transformed data shape         (227016, 39)
5   Transformed train set shape         (158911, 39)
6    Transformed test set shape          (68105, 39)
7              Numeric features                    3
8          Categorical features                    3
9                    Preprocess                 True
10              Imputation type               simple
11           Numeric imputation                 mean
12       Categorical imputation                 mode
13     Maximum one-hot encoding                   25
14              Encoding method                 None
15               Fold Generator      StratifiedKFold
16                  Fold Number                   10
17                     CPU Jobs                   -1
18                      Use GPU                 True
19               Log Experiment         MlflowLogger
20              Experiment Name  codepro_model_exp02
21                          USI                 189a
2024-08-18 00:59:11,507:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:59:11,556:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:59:11,556:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:59:11,557:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:59:11,580:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:59:11,584:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:59:11,585:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-18 00:59:11,589:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-18 00:59:11,589:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:59:11,636:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:59:11,637:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:59:11,637:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:59:11,659:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:59:11,664:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-18 00:59:11,665:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-18 00:59:11,668:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-18 00:59:11,669:INFO:Logging experiment in loggers
2024-08-18 00:59:11,834:INFO:SubProcess save_model() called ==================================
2024-08-18 00:59:11,843:INFO:Initializing save_model()
2024-08-18 00:59:11,843:INFO:save_model(model=Pipeline(memory=FastMemory(location=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_droppped',
                                             'city_tier', 'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), model_name=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmpz8f15gmc/Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_droppped',
                                             'city_tier', 'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-08-18 00:59:11,843:INFO:Adding model into prep_pipe
2024-08-18 00:59:11,843:WARNING:Only Model saved as it was a pipeline.
2024-08-18 00:59:11,869:INFO:/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmpz8f15gmc/Transformation Pipeline.pkl saved in current working directory
2024-08-18 00:59:11,873:INFO:Pipeline(memory=FastMemory(location=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_droppped',
                                             'city_tier', 'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-08-18 00:59:11,873:INFO:save_model() successfully completed......................................
2024-08-18 00:59:11,983:INFO:SubProcess save_model() end ==================================
2024-08-18 00:59:12,717:INFO:setup() successfully completed in 3.17s...............
2024-08-18 00:59:21,615:INFO:Initializing compare_models()
2024-08-18 00:59:21,616:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd67a7ee290>, include=None, fold=5, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7fd67a7ee290>, 'include': None, 'exclude': ['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada'], 'fold': 5, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada'])
2024-08-18 00:59:21,616:INFO:Checking exceptions
2024-08-18 00:59:21,647:INFO:Preparing display monitor
2024-08-18 00:59:21,681:INFO:Initializing Logistic Regression
2024-08-18 00:59:21,682:INFO:Total runtime is 5.185604095458984e-06 minutes
2024-08-18 00:59:21,686:INFO:SubProcess create_model() called ==================================
2024-08-18 00:59:21,687:INFO:Initializing create_model()
2024-08-18 00:59:21,687:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd67a7ee290>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fd67a243e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-18 00:59:21,687:INFO:Checking exceptions
2024-08-18 00:59:21,687:INFO:Importing libraries
2024-08-18 00:59:21,687:INFO:Copying training dataset
2024-08-18 00:59:21,742:INFO:Defining folds
2024-08-18 00:59:21,742:INFO:Declaring metric variables
2024-08-18 00:59:21,747:INFO:Importing untrained model
2024-08-18 00:59:21,751:INFO:Logistic Regression Imported successfully
2024-08-18 00:59:21,759:INFO:Starting cross validation
2024-08-18 00:59:21,762:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-08-18 00:59:29,237:INFO:Calculating mean and std
2024-08-18 00:59:29,239:INFO:Creating metrics dataframe
2024-08-18 00:59:29,242:INFO:Uploading results into container
2024-08-18 00:59:29,242:INFO:Uploading model into container now
2024-08-18 00:59:29,243:INFO:_master_model_container: 1
2024-08-18 00:59:29,243:INFO:_display_container: 2
2024-08-18 00:59:29,243:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3263, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-08-18 00:59:29,244:INFO:create_model() successfully completed......................................
2024-08-18 00:59:29,387:INFO:SubProcess create_model() end ==================================
2024-08-18 00:59:29,387:INFO:Creating metrics dataframe
2024-08-18 00:59:29,397:INFO:Initializing Naive Bayes
2024-08-18 00:59:29,398:INFO:Total runtime is 0.12860400279362996 minutes
2024-08-18 00:59:29,404:INFO:SubProcess create_model() called ==================================
2024-08-18 00:59:29,404:INFO:Initializing create_model()
2024-08-18 00:59:29,404:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd67a7ee290>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fd67a243e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-18 00:59:29,404:INFO:Checking exceptions
2024-08-18 00:59:29,404:INFO:Importing libraries
2024-08-18 00:59:29,405:INFO:Copying training dataset
2024-08-18 00:59:29,466:INFO:Defining folds
2024-08-18 00:59:29,467:INFO:Declaring metric variables
2024-08-18 00:59:29,471:INFO:Importing untrained model
2024-08-18 00:59:29,474:INFO:Naive Bayes Imported successfully
2024-08-18 00:59:29,482:INFO:Starting cross validation
2024-08-18 00:59:29,485:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-08-18 00:59:36,362:INFO:Calculating mean and std
2024-08-18 00:59:36,363:INFO:Creating metrics dataframe
2024-08-18 00:59:36,365:INFO:Uploading results into container
2024-08-18 00:59:36,366:INFO:Uploading model into container now
2024-08-18 00:59:36,367:INFO:_master_model_container: 2
2024-08-18 00:59:36,367:INFO:_display_container: 2
2024-08-18 00:59:36,367:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-08-18 00:59:36,367:INFO:create_model() successfully completed......................................
2024-08-18 00:59:36,488:INFO:SubProcess create_model() end ==================================
2024-08-18 00:59:36,488:INFO:Creating metrics dataframe
2024-08-18 00:59:36,499:INFO:Initializing Decision Tree Classifier
2024-08-18 00:59:36,499:INFO:Total runtime is 0.24696815013885498 minutes
2024-08-18 00:59:36,504:INFO:SubProcess create_model() called ==================================
2024-08-18 00:59:36,504:INFO:Initializing create_model()
2024-08-18 00:59:36,504:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd67a7ee290>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fd67a243e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-18 00:59:36,504:INFO:Checking exceptions
2024-08-18 00:59:36,504:INFO:Importing libraries
2024-08-18 00:59:36,504:INFO:Copying training dataset
2024-08-18 00:59:36,553:INFO:Defining folds
2024-08-18 00:59:36,553:INFO:Declaring metric variables
2024-08-18 00:59:36,557:INFO:Importing untrained model
2024-08-18 00:59:36,561:INFO:Decision Tree Classifier Imported successfully
2024-08-18 00:59:36,569:INFO:Starting cross validation
2024-08-18 00:59:36,571:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-08-18 00:59:44,217:INFO:Calculating mean and std
2024-08-18 00:59:44,218:INFO:Creating metrics dataframe
2024-08-18 00:59:44,220:INFO:Uploading results into container
2024-08-18 00:59:44,220:INFO:Uploading model into container now
2024-08-18 00:59:44,221:INFO:_master_model_container: 3
2024-08-18 00:59:44,221:INFO:_display_container: 2
2024-08-18 00:59:44,221:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=3263, splitter='best')
2024-08-18 00:59:44,222:INFO:create_model() successfully completed......................................
2024-08-18 00:59:44,339:INFO:SubProcess create_model() end ==================================
2024-08-18 00:59:44,339:INFO:Creating metrics dataframe
2024-08-18 00:59:44,347:INFO:Initializing Ridge Classifier
2024-08-18 00:59:44,347:INFO:Total runtime is 0.3777608315149943 minutes
2024-08-18 00:59:44,351:INFO:SubProcess create_model() called ==================================
2024-08-18 00:59:44,351:INFO:Initializing create_model()
2024-08-18 00:59:44,351:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd67a7ee290>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fd67a243e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-18 00:59:44,351:INFO:Checking exceptions
2024-08-18 00:59:44,352:INFO:Importing libraries
2024-08-18 00:59:44,352:INFO:Copying training dataset
2024-08-18 00:59:44,398:INFO:Defining folds
2024-08-18 00:59:44,398:INFO:Declaring metric variables
2024-08-18 00:59:44,402:INFO:Importing untrained model
2024-08-18 00:59:44,406:INFO:Ridge Classifier Imported successfully
2024-08-18 00:59:44,413:INFO:Starting cross validation
2024-08-18 00:59:44,416:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-08-18 00:59:50,595:INFO:Calculating mean and std
2024-08-18 00:59:50,596:INFO:Creating metrics dataframe
2024-08-18 00:59:50,599:INFO:Uploading results into container
2024-08-18 00:59:50,600:INFO:Uploading model into container now
2024-08-18 00:59:50,600:INFO:_master_model_container: 4
2024-08-18 00:59:50,600:INFO:_display_container: 2
2024-08-18 00:59:50,601:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=3263, solver='auto',
                tol=0.0001)
2024-08-18 00:59:50,601:INFO:create_model() successfully completed......................................
2024-08-18 00:59:50,719:INFO:SubProcess create_model() end ==================================
2024-08-18 00:59:50,720:INFO:Creating metrics dataframe
2024-08-18 00:59:50,729:INFO:Initializing Random Forest Classifier
2024-08-18 00:59:50,729:INFO:Total runtime is 0.48413468599319454 minutes
2024-08-18 00:59:50,734:INFO:SubProcess create_model() called ==================================
2024-08-18 00:59:50,734:INFO:Initializing create_model()
2024-08-18 00:59:50,735:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd67a7ee290>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fd67a243e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-18 00:59:50,735:INFO:Checking exceptions
2024-08-18 00:59:50,735:INFO:Importing libraries
2024-08-18 00:59:50,735:INFO:Copying training dataset
2024-08-18 00:59:50,786:INFO:Defining folds
2024-08-18 00:59:50,786:INFO:Declaring metric variables
2024-08-18 00:59:50,790:INFO:Importing untrained model
2024-08-18 00:59:50,794:INFO:Random Forest Classifier Imported successfully
2024-08-18 00:59:50,802:INFO:Starting cross validation
2024-08-18 00:59:50,805:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-08-18 01:00:15,388:INFO:Calculating mean and std
2024-08-18 01:00:15,389:INFO:Creating metrics dataframe
2024-08-18 01:00:15,391:INFO:Uploading results into container
2024-08-18 01:00:15,392:INFO:Uploading model into container now
2024-08-18 01:00:15,392:INFO:_master_model_container: 5
2024-08-18 01:00:15,392:INFO:_display_container: 2
2024-08-18 01:00:15,393:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=3263, verbose=0,
                       warm_start=False)
2024-08-18 01:00:15,393:INFO:create_model() successfully completed......................................
2024-08-18 01:00:15,532:INFO:SubProcess create_model() end ==================================
2024-08-18 01:00:15,532:INFO:Creating metrics dataframe
2024-08-18 01:00:15,542:INFO:Initializing Linear Discriminant Analysis
2024-08-18 01:00:15,542:INFO:Total runtime is 0.8976824323336283 minutes
2024-08-18 01:00:15,548:INFO:SubProcess create_model() called ==================================
2024-08-18 01:00:15,548:INFO:Initializing create_model()
2024-08-18 01:00:15,549:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd67a7ee290>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fd67a243e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-18 01:00:15,549:INFO:Checking exceptions
2024-08-18 01:00:15,549:INFO:Importing libraries
2024-08-18 01:00:15,550:INFO:Copying training dataset
2024-08-18 01:00:15,605:INFO:Defining folds
2024-08-18 01:00:15,605:INFO:Declaring metric variables
2024-08-18 01:00:15,610:INFO:Importing untrained model
2024-08-18 01:00:15,617:INFO:Linear Discriminant Analysis Imported successfully
2024-08-18 01:00:15,626:INFO:Starting cross validation
2024-08-18 01:00:15,628:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-08-18 01:00:26,437:INFO:Calculating mean and std
2024-08-18 01:00:26,439:INFO:Creating metrics dataframe
2024-08-18 01:00:26,440:INFO:Uploading results into container
2024-08-18 01:00:26,441:INFO:Uploading model into container now
2024-08-18 01:00:26,441:INFO:_master_model_container: 6
2024-08-18 01:00:26,442:INFO:_display_container: 2
2024-08-18 01:00:26,442:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-08-18 01:00:26,442:INFO:create_model() successfully completed......................................
2024-08-18 01:00:26,565:INFO:SubProcess create_model() end ==================================
2024-08-18 01:00:26,565:INFO:Creating metrics dataframe
2024-08-18 01:00:26,576:INFO:Initializing Extra Trees Classifier
2024-08-18 01:00:26,576:INFO:Total runtime is 1.0815847675005594 minutes
2024-08-18 01:00:26,581:INFO:SubProcess create_model() called ==================================
2024-08-18 01:00:26,582:INFO:Initializing create_model()
2024-08-18 01:00:26,582:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd67a7ee290>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fd67a243e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-18 01:00:26,582:INFO:Checking exceptions
2024-08-18 01:00:26,582:INFO:Importing libraries
2024-08-18 01:00:26,582:INFO:Copying training dataset
2024-08-18 01:00:26,633:INFO:Defining folds
2024-08-18 01:00:26,634:INFO:Declaring metric variables
2024-08-18 01:00:26,638:INFO:Importing untrained model
2024-08-18 01:00:26,642:INFO:Extra Trees Classifier Imported successfully
2024-08-18 01:00:26,650:INFO:Starting cross validation
2024-08-18 01:00:26,652:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-08-18 01:00:53,911:INFO:Calculating mean and std
2024-08-18 01:00:53,912:INFO:Creating metrics dataframe
2024-08-18 01:00:53,914:INFO:Uploading results into container
2024-08-18 01:00:53,914:INFO:Uploading model into container now
2024-08-18 01:00:53,915:INFO:_master_model_container: 7
2024-08-18 01:00:53,915:INFO:_display_container: 2
2024-08-18 01:00:53,916:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=3263, verbose=0,
                     warm_start=False)
2024-08-18 01:00:53,916:INFO:create_model() successfully completed......................................
2024-08-18 01:00:54,039:INFO:SubProcess create_model() end ==================================
2024-08-18 01:00:54,039:INFO:Creating metrics dataframe
2024-08-18 01:00:54,049:INFO:Initializing Light Gradient Boosting Machine
2024-08-18 01:00:54,049:INFO:Total runtime is 1.5394625504811605 minutes
2024-08-18 01:00:54,053:INFO:SubProcess create_model() called ==================================
2024-08-18 01:00:54,053:INFO:Initializing create_model()
2024-08-18 01:00:54,054:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd67a7ee290>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fd67a243e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-18 01:00:54,054:INFO:Checking exceptions
2024-08-18 01:00:54,054:INFO:Importing libraries
2024-08-18 01:00:54,054:INFO:Copying training dataset
2024-08-18 01:00:54,105:INFO:Defining folds
2024-08-18 01:00:54,105:INFO:Declaring metric variables
2024-08-18 01:00:54,109:INFO:Importing untrained model
2024-08-18 01:00:54,114:INFO:Light Gradient Boosting Machine Imported successfully
2024-08-18 01:00:54,122:INFO:Starting cross validation
2024-08-18 01:00:54,126:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-08-18 01:00:55,203:INFO:[LightGBM] [Info] Number of positive: 63832, number of negative: 63296
2024-08-18 01:00:55,206:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000788 seconds.
2024-08-18 01:00:55,206:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-18 01:00:55,207:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-18 01:00:55,207:INFO:[LightGBM] [Info] Total Bins 112
2024-08-18 01:00:55,207:INFO:[LightGBM] [Info] Number of data points in the train set: 127128, number of used features: 38
2024-08-18 01:00:55,208:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502108 -> initscore=0.008432
2024-08-18 01:00:55,208:INFO:[LightGBM] [Info] Start training from score 0.008432
2024-08-18 01:00:56,873:INFO:[LightGBM] [Info] Number of positive: 63833, number of negative: 63296
2024-08-18 01:00:56,877:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001001 seconds.
2024-08-18 01:00:56,877:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-18 01:00:56,877:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-18 01:00:56,877:INFO:[LightGBM] [Info] Total Bins 114
2024-08-18 01:00:56,877:INFO:[LightGBM] [Info] Number of data points in the train set: 127129, number of used features: 38
2024-08-18 01:00:56,878:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502112 -> initscore=0.008448
2024-08-18 01:00:56,879:INFO:[LightGBM] [Info] Start training from score 0.008448
2024-08-18 01:00:58,672:INFO:[LightGBM] [Info] Number of positive: 63833, number of negative: 63296
2024-08-18 01:00:58,675:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000873 seconds.
2024-08-18 01:00:58,675:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-18 01:00:58,675:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-18 01:00:58,675:INFO:[LightGBM] [Info] Total Bins 114
2024-08-18 01:00:58,675:INFO:[LightGBM] [Info] Number of data points in the train set: 127129, number of used features: 38
2024-08-18 01:00:58,676:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502112 -> initscore=0.008448
2024-08-18 01:00:58,676:INFO:[LightGBM] [Info] Start training from score 0.008448
2024-08-18 01:01:00,159:INFO:[LightGBM] [Info] Number of positive: 63833, number of negative: 63296
2024-08-18 01:01:00,163:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000794 seconds.
2024-08-18 01:01:00,163:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-18 01:01:00,163:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-18 01:01:00,163:INFO:[LightGBM] [Info] Total Bins 114
2024-08-18 01:01:00,163:INFO:[LightGBM] [Info] Number of data points in the train set: 127129, number of used features: 38
2024-08-18 01:01:00,165:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502112 -> initscore=0.008448
2024-08-18 01:01:00,165:INFO:[LightGBM] [Info] Start training from score 0.008448
2024-08-18 01:01:01,685:INFO:[LightGBM] [Info] Number of positive: 63833, number of negative: 63296
2024-08-18 01:01:01,688:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000850 seconds.
2024-08-18 01:01:01,688:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-18 01:01:01,689:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-18 01:01:01,689:INFO:[LightGBM] [Info] Total Bins 115
2024-08-18 01:01:01,689:INFO:[LightGBM] [Info] Number of data points in the train set: 127129, number of used features: 38
2024-08-18 01:01:01,690:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502112 -> initscore=0.008448
2024-08-18 01:01:01,690:INFO:[LightGBM] [Info] Start training from score 0.008448
2024-08-18 01:01:02,141:INFO:Calculating mean and std
2024-08-18 01:01:02,142:INFO:Creating metrics dataframe
2024-08-18 01:01:02,144:INFO:Uploading results into container
2024-08-18 01:01:02,145:INFO:Uploading model into container now
2024-08-18 01:01:02,145:INFO:_master_model_container: 8
2024-08-18 01:01:02,145:INFO:_display_container: 2
2024-08-18 01:01:02,146:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3263, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-08-18 01:01:02,146:INFO:create_model() successfully completed......................................
2024-08-18 01:01:02,276:INFO:SubProcess create_model() end ==================================
2024-08-18 01:01:02,277:INFO:Creating metrics dataframe
2024-08-18 01:01:02,298:INFO:Initializing create_model()
2024-08-18 01:01:02,298:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd67a7ee290>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3263, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-18 01:01:02,298:INFO:Checking exceptions
2024-08-18 01:01:02,300:INFO:Importing libraries
2024-08-18 01:01:02,300:INFO:Copying training dataset
2024-08-18 01:01:02,348:INFO:Defining folds
2024-08-18 01:01:02,348:INFO:Declaring metric variables
2024-08-18 01:01:02,349:INFO:Importing untrained model
2024-08-18 01:01:02,349:INFO:Declaring custom model
2024-08-18 01:01:02,350:INFO:Light Gradient Boosting Machine Imported successfully
2024-08-18 01:01:02,352:INFO:Cross validation set to False
2024-08-18 01:01:02,352:INFO:Fitting Model
2024-08-18 01:01:03,680:INFO:[LightGBM] [Info] Number of positive: 79791, number of negative: 79120
2024-08-18 01:01:03,686:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001355 seconds.
2024-08-18 01:01:03,686:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-18 01:01:03,686:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-18 01:01:03,686:INFO:[LightGBM] [Info] Total Bins 117
2024-08-18 01:01:03,686:INFO:[LightGBM] [Info] Number of data points in the train set: 158911, number of used features: 38
2024-08-18 01:01:03,688:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502111 -> initscore=0.008445
2024-08-18 01:01:03,688:INFO:[LightGBM] [Info] Start training from score 0.008445
2024-08-18 01:01:04,271:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3263, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-08-18 01:01:04,271:INFO:create_model() successfully completed......................................
2024-08-18 01:01:04,406:INFO:Creating Dashboard logs
2024-08-18 01:01:04,410:INFO:Model: Light Gradient Boosting Machine
2024-08-18 01:01:04,462:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 3263, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2024-08-18 01:01:04,711:INFO:Initializing predict_model()
2024-08-18 01:01:04,711:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd67a7ee290>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3263, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fd65645b5b0>)
2024-08-18 01:01:04,712:INFO:Checking exceptions
2024-08-18 01:01:04,712:INFO:Preloading libraries
2024-08-18 01:01:05,412:INFO:SubProcess plot_model() called ==================================
2024-08-18 01:01:05,413:INFO:Initializing plot_model()
2024-08-18 01:01:05,413:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3263, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmpihzzqypx, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd67a7ee290>, system=False)
2024-08-18 01:01:05,413:INFO:Checking exceptions
2024-08-18 01:01:05,435:INFO:Preloading libraries
2024-08-18 01:01:05,439:INFO:Copying training dataset
2024-08-18 01:01:05,439:INFO:Plot type: auc
2024-08-18 01:01:05,875:INFO:Fitting Model
2024-08-18 01:01:05,883:INFO:Scoring test/hold-out set
2024-08-18 01:01:06,143:INFO:Saving '/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmpihzzqypx/AUC.png'
2024-08-18 01:01:06,394:INFO:Visual Rendered Successfully
2024-08-18 01:01:06,528:INFO:plot_model() successfully completed......................................
2024-08-18 01:01:06,536:INFO:Initializing plot_model()
2024-08-18 01:01:06,536:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3263, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmpihzzqypx, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd67a7ee290>, system=False)
2024-08-18 01:01:06,536:INFO:Checking exceptions
2024-08-18 01:01:06,559:INFO:Preloading libraries
2024-08-18 01:01:06,562:INFO:Copying training dataset
2024-08-18 01:01:06,563:INFO:Plot type: confusion_matrix
2024-08-18 01:01:06,977:INFO:Fitting Model
2024-08-18 01:01:06,981:INFO:Scoring test/hold-out set
2024-08-18 01:01:07,178:INFO:Saving '/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmpihzzqypx/Confusion Matrix.png'
2024-08-18 01:01:07,324:INFO:Visual Rendered Successfully
2024-08-18 01:01:07,451:INFO:plot_model() successfully completed......................................
2024-08-18 01:01:07,462:INFO:Initializing plot_model()
2024-08-18 01:01:07,462:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3263, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmpihzzqypx, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd67a7ee290>, system=False)
2024-08-18 01:01:07,462:INFO:Checking exceptions
2024-08-18 01:01:07,488:INFO:Preloading libraries
2024-08-18 01:01:07,492:INFO:Copying training dataset
2024-08-18 01:01:07,492:INFO:Plot type: feature
2024-08-18 01:01:07,493:WARNING:No coef_ found. Trying feature_importances_
2024-08-18 01:01:07,670:INFO:Saving '/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmpihzzqypx/Feature Importance.png'
2024-08-18 01:01:07,867:INFO:Visual Rendered Successfully
2024-08-18 01:01:07,992:INFO:plot_model() successfully completed......................................
2024-08-18 01:01:08,012:INFO:SubProcess plot_model() end ==================================
2024-08-18 01:01:08,303:INFO:Creating Dashboard logs
2024-08-18 01:01:08,308:INFO:Model: Logistic Regression
2024-08-18 01:01:08,362:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 3263, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2024-08-18 01:01:08,840:INFO:Creating Dashboard logs
2024-08-18 01:01:08,844:INFO:Model: Ridge Classifier
2024-08-18 01:01:08,883:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 3263, 'solver': 'auto', 'tol': 0.0001}
2024-08-18 01:01:09,341:INFO:Creating Dashboard logs
2024-08-18 01:01:09,346:INFO:Model: Linear Discriminant Analysis
2024-08-18 01:01:09,381:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2024-08-18 01:01:09,885:INFO:Creating Dashboard logs
2024-08-18 01:01:09,890:INFO:Model: Naive Bayes
2024-08-18 01:01:09,933:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2024-08-18 01:01:10,416:INFO:Creating Dashboard logs
2024-08-18 01:01:10,421:INFO:Model: Extra Trees Classifier
2024-08-18 01:01:10,463:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 3263, 'verbose': 0, 'warm_start': False}
2024-08-18 01:01:10,953:INFO:Creating Dashboard logs
2024-08-18 01:01:10,958:INFO:Model: Decision Tree Classifier
2024-08-18 01:01:10,988:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 3263, 'splitter': 'best'}
2024-08-18 01:01:11,462:INFO:Creating Dashboard logs
2024-08-18 01:01:11,469:INFO:Model: Random Forest Classifier
2024-08-18 01:01:11,511:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 3263, 'verbose': 0, 'warm_start': False}
2024-08-18 01:01:12,007:INFO:_master_model_container: 8
2024-08-18 01:01:12,008:INFO:_display_container: 2
2024-08-18 01:01:12,009:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3263, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-08-18 01:01:12,009:INFO:compare_models() successfully completed......................................
2024-08-18 01:01:49,813:INFO:Initializing create_model()
2024-08-18 01:01:49,814:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd67a7ee290>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-18 01:01:49,814:INFO:Checking exceptions
2024-08-18 01:01:49,838:INFO:Importing libraries
2024-08-18 01:01:49,838:INFO:Copying training dataset
2024-08-18 01:01:49,910:INFO:Defining folds
2024-08-18 01:01:49,910:INFO:Declaring metric variables
2024-08-18 01:01:49,915:INFO:Importing untrained model
2024-08-18 01:01:49,920:INFO:Light Gradient Boosting Machine Imported successfully
2024-08-18 01:01:49,928:INFO:Starting cross validation
2024-08-18 01:01:49,931:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-08-18 01:01:50,909:INFO:[LightGBM] [Info] Number of positive: 63832, number of negative: 63296
2024-08-18 01:01:50,912:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000791 seconds.
2024-08-18 01:01:50,912:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-18 01:01:50,912:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-18 01:01:50,913:INFO:[LightGBM] [Info] Total Bins 112
2024-08-18 01:01:50,913:INFO:[LightGBM] [Info] Number of data points in the train set: 127128, number of used features: 38
2024-08-18 01:01:50,914:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502108 -> initscore=0.008432
2024-08-18 01:01:50,914:INFO:[LightGBM] [Info] Start training from score 0.008432
2024-08-18 01:01:52,433:INFO:[LightGBM] [Info] Number of positive: 63833, number of negative: 63296
2024-08-18 01:01:52,437:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000808 seconds.
2024-08-18 01:01:52,437:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-18 01:01:52,437:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-18 01:01:52,437:INFO:[LightGBM] [Info] Total Bins 114
2024-08-18 01:01:52,437:INFO:[LightGBM] [Info] Number of data points in the train set: 127129, number of used features: 38
2024-08-18 01:01:52,438:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502112 -> initscore=0.008448
2024-08-18 01:01:52,438:INFO:[LightGBM] [Info] Start training from score 0.008448
2024-08-18 01:01:53,930:INFO:[LightGBM] [Info] Number of positive: 63833, number of negative: 63296
2024-08-18 01:01:53,932:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000763 seconds.
2024-08-18 01:01:53,932:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-18 01:01:53,932:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-18 01:01:53,933:INFO:[LightGBM] [Info] Total Bins 114
2024-08-18 01:01:53,933:INFO:[LightGBM] [Info] Number of data points in the train set: 127129, number of used features: 38
2024-08-18 01:01:53,933:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502112 -> initscore=0.008448
2024-08-18 01:01:53,933:INFO:[LightGBM] [Info] Start training from score 0.008448
2024-08-18 01:01:55,335:INFO:[LightGBM] [Info] Number of positive: 63833, number of negative: 63296
2024-08-18 01:01:55,338:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000795 seconds.
2024-08-18 01:01:55,338:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-18 01:01:55,338:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-18 01:01:55,338:INFO:[LightGBM] [Info] Total Bins 114
2024-08-18 01:01:55,338:INFO:[LightGBM] [Info] Number of data points in the train set: 127129, number of used features: 38
2024-08-18 01:01:55,339:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502112 -> initscore=0.008448
2024-08-18 01:01:55,339:INFO:[LightGBM] [Info] Start training from score 0.008448
2024-08-18 01:01:56,806:INFO:[LightGBM] [Info] Number of positive: 63833, number of negative: 63296
2024-08-18 01:01:56,809:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000668 seconds.
2024-08-18 01:01:56,809:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-18 01:01:56,809:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-18 01:01:56,809:INFO:[LightGBM] [Info] Total Bins 115
2024-08-18 01:01:56,809:INFO:[LightGBM] [Info] Number of data points in the train set: 127129, number of used features: 38
2024-08-18 01:01:56,810:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502112 -> initscore=0.008448
2024-08-18 01:01:56,810:INFO:[LightGBM] [Info] Start training from score 0.008448
2024-08-18 01:01:57,219:INFO:Calculating mean and std
2024-08-18 01:01:57,220:INFO:Creating metrics dataframe
2024-08-18 01:01:57,228:INFO:Finalizing model
2024-08-18 01:01:58,445:INFO:[LightGBM] [Info] Number of positive: 79791, number of negative: 79120
2024-08-18 01:01:58,449:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001232 seconds.
2024-08-18 01:01:58,449:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-18 01:01:58,449:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-18 01:01:58,449:INFO:[LightGBM] [Info] Total Bins 117
2024-08-18 01:01:58,449:INFO:[LightGBM] [Info] Number of data points in the train set: 158911, number of used features: 38
2024-08-18 01:01:58,451:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502111 -> initscore=0.008445
2024-08-18 01:01:58,451:INFO:[LightGBM] [Info] Start training from score 0.008445
2024-08-18 01:01:58,622:INFO:Creating Dashboard logs
2024-08-18 01:01:58,626:INFO:Model: Light Gradient Boosting Machine
2024-08-18 01:01:58,661:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 3263, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2024-08-18 01:01:58,864:INFO:Initializing predict_model()
2024-08-18 01:01:58,865:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd67a7ee290>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3263, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fd65645be20>)
2024-08-18 01:01:58,865:INFO:Checking exceptions
2024-08-18 01:01:58,865:INFO:Preloading libraries
2024-08-18 01:01:59,520:INFO:SubProcess plot_model() called ==================================
2024-08-18 01:01:59,521:INFO:Initializing plot_model()
2024-08-18 01:01:59,521:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3263, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmpviu_eh27, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd67a7ee290>, system=False)
2024-08-18 01:01:59,521:INFO:Checking exceptions
2024-08-18 01:01:59,542:INFO:Preloading libraries
2024-08-18 01:01:59,546:INFO:Copying training dataset
2024-08-18 01:01:59,546:INFO:Plot type: auc
2024-08-18 01:01:59,939:INFO:Fitting Model
2024-08-18 01:01:59,947:INFO:Scoring test/hold-out set
2024-08-18 01:02:00,192:INFO:Saving '/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmpviu_eh27/AUC.png'
2024-08-18 01:02:00,443:INFO:Visual Rendered Successfully
2024-08-18 01:02:00,568:INFO:plot_model() successfully completed......................................
2024-08-18 01:02:00,574:INFO:Initializing plot_model()
2024-08-18 01:02:00,574:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3263, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmpviu_eh27, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd67a7ee290>, system=False)
2024-08-18 01:02:00,574:INFO:Checking exceptions
2024-08-18 01:02:00,600:INFO:Preloading libraries
2024-08-18 01:02:00,604:INFO:Copying training dataset
2024-08-18 01:02:00,604:INFO:Plot type: confusion_matrix
2024-08-18 01:02:01,043:INFO:Fitting Model
2024-08-18 01:02:01,047:INFO:Scoring test/hold-out set
2024-08-18 01:02:01,464:INFO:Saving '/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmpviu_eh27/Confusion Matrix.png'
2024-08-18 01:02:01,642:INFO:Visual Rendered Successfully
2024-08-18 01:02:01,803:INFO:plot_model() successfully completed......................................
2024-08-18 01:02:01,812:INFO:Initializing plot_model()
2024-08-18 01:02:01,812:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3263, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmpviu_eh27, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd67a7ee290>, system=False)
2024-08-18 01:02:01,813:INFO:Checking exceptions
2024-08-18 01:02:01,839:INFO:Preloading libraries
2024-08-18 01:02:01,843:INFO:Copying training dataset
2024-08-18 01:02:01,843:INFO:Plot type: feature
2024-08-18 01:02:01,844:WARNING:No coef_ found. Trying feature_importances_
2024-08-18 01:02:02,120:INFO:Saving '/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmpviu_eh27/Feature Importance.png'
2024-08-18 01:02:02,380:INFO:Visual Rendered Successfully
2024-08-18 01:02:02,525:INFO:plot_model() successfully completed......................................
2024-08-18 01:02:02,527:INFO:SubProcess plot_model() end ==================================
2024-08-18 01:02:02,801:INFO:Uploading results into container
2024-08-18 01:02:02,802:INFO:Uploading model into container now
2024-08-18 01:02:02,814:INFO:_master_model_container: 9
2024-08-18 01:02:02,815:INFO:_display_container: 3
2024-08-18 01:02:02,815:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3263, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-08-18 01:02:02,816:INFO:create_model() successfully completed......................................
2024-08-18 01:03:47,322:INFO:Initializing tune_model()
2024-08-18 01:03:47,323:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3263, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=10, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=optuna, search_algorithm=random, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=True, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd67a7ee290>)
2024-08-18 01:03:47,323:INFO:Checking exceptions
2024-08-18 01:03:47,324:INFO:Soft dependency imported: optuna: 3.6.1
2024-08-18 01:03:47,378:INFO:Copying training dataset
2024-08-18 01:03:47,416:INFO:Checking base model
2024-08-18 01:03:47,416:INFO:Base model : Light Gradient Boosting Machine
2024-08-18 01:03:47,423:INFO:Declaring metric variables
2024-08-18 01:03:47,429:INFO:Defining Hyperparameters
2024-08-18 01:03:47,583:INFO:Tuning with n_jobs=-1
2024-08-18 01:03:47,584:INFO:Initializing optuna.integration.OptunaSearchCV
2024-08-18 01:06:37,631:INFO:best_params: {'actual_estimator__num_leaves': 242, 'actual_estimator__learning_rate': 3.798279158743105e-05, 'actual_estimator__n_estimators': 66, 'actual_estimator__min_split_gain': 0.8063740623524571, 'actual_estimator__reg_alpha': 0.4114597473175342, 'actual_estimator__reg_lambda': 3.922346098322018e-10, 'actual_estimator__feature_fraction': 0.4664538818609959, 'actual_estimator__bagging_fraction': 0.4210553556985497, 'actual_estimator__bagging_freq': 7, 'actual_estimator__min_child_samples': 76}
2024-08-18 01:06:37,635:INFO:Hyperparameter search completed
2024-08-18 01:06:37,635:INFO:SubProcess create_model() called ==================================
2024-08-18 01:06:37,636:INFO:Initializing create_model()
2024-08-18 01:06:37,636:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd67a7ee290>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3263, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fd67a243e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'num_leaves': 242, 'learning_rate': 3.798279158743105e-05, 'n_estimators': 66, 'min_split_gain': 0.8063740623524571, 'reg_alpha': 0.4114597473175342, 'reg_lambda': 3.922346098322018e-10, 'feature_fraction': 0.4664538818609959, 'bagging_fraction': 0.4210553556985497, 'bagging_freq': 7, 'min_child_samples': 76})
2024-08-18 01:06:37,637:INFO:Checking exceptions
2024-08-18 01:06:37,637:INFO:Importing libraries
2024-08-18 01:06:37,637:INFO:Copying training dataset
2024-08-18 01:06:37,720:INFO:Defining folds
2024-08-18 01:06:37,720:INFO:Declaring metric variables
2024-08-18 01:06:37,726:INFO:Importing untrained model
2024-08-18 01:06:37,726:INFO:Declaring custom model
2024-08-18 01:06:37,734:INFO:Light Gradient Boosting Machine Imported successfully
2024-08-18 01:06:37,784:INFO:Starting cross validation
2024-08-18 01:06:37,788:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-08-18 01:06:38,989:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2024-08-18 01:06:38,990:INFO:[LightGBM] [Warning] feature_fraction is set=0.4664538818609959, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4664538818609959
2024-08-18 01:06:38,990:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4210553556985497, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4210553556985497
2024-08-18 01:06:39,078:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2024-08-18 01:06:39,078:INFO:[LightGBM] [Warning] feature_fraction is set=0.4664538818609959, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4664538818609959
2024-08-18 01:06:39,078:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4210553556985497, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4210553556985497
2024-08-18 01:06:39,078:INFO:[LightGBM] [Info] Number of positive: 71811, number of negative: 71208
2024-08-18 01:06:39,083:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000824 seconds.
2024-08-18 01:06:39,083:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-18 01:06:39,083:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-18 01:06:39,083:INFO:[LightGBM] [Info] Total Bins 115
2024-08-18 01:06:39,083:INFO:[LightGBM] [Info] Number of data points in the train set: 143019, number of used features: 38
2024-08-18 01:06:39,086:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502108 -> initscore=0.008432
2024-08-18 01:06:39,086:INFO:[LightGBM] [Info] Start training from score 0.008432
2024-08-18 01:06:39,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:39,387:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2024-08-18 01:06:39,387:INFO:[LightGBM] [Warning] feature_fraction is set=0.4664538818609959, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4664538818609959
2024-08-18 01:06:39,387:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4210553556985497, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4210553556985497
2024-08-18 01:06:39,403:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2024-08-18 01:06:39,403:INFO:[LightGBM] [Warning] feature_fraction is set=0.4664538818609959, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4664538818609959
2024-08-18 01:06:39,403:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4210553556985497, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4210553556985497
2024-08-18 01:06:40,606:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2024-08-18 01:06:40,606:INFO:[LightGBM] [Warning] feature_fraction is set=0.4664538818609959, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4664538818609959
2024-08-18 01:06:40,606:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4210553556985497, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4210553556985497
2024-08-18 01:06:40,689:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2024-08-18 01:06:40,689:INFO:[LightGBM] [Warning] feature_fraction is set=0.4664538818609959, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4664538818609959
2024-08-18 01:06:40,689:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4210553556985497, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4210553556985497
2024-08-18 01:06:40,690:INFO:[LightGBM] [Info] Number of positive: 71812, number of negative: 71208
2024-08-18 01:06:40,694:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000828 seconds.
2024-08-18 01:06:40,694:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-18 01:06:40,694:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-18 01:06:40,694:INFO:[LightGBM] [Info] Total Bins 115
2024-08-18 01:06:40,694:INFO:[LightGBM] [Info] Number of data points in the train set: 143020, number of used features: 38
2024-08-18 01:06:40,696:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502112 -> initscore=0.008446
2024-08-18 01:06:40,696:INFO:[LightGBM] [Info] Start training from score 0.008446
2024-08-18 01:06:40,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:40,970:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2024-08-18 01:06:40,970:INFO:[LightGBM] [Warning] feature_fraction is set=0.4664538818609959, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4664538818609959
2024-08-18 01:06:40,970:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4210553556985497, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4210553556985497
2024-08-18 01:06:40,990:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2024-08-18 01:06:40,991:INFO:[LightGBM] [Warning] feature_fraction is set=0.4664538818609959, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4664538818609959
2024-08-18 01:06:40,991:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4210553556985497, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4210553556985497
2024-08-18 01:06:42,151:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2024-08-18 01:06:42,151:INFO:[LightGBM] [Warning] feature_fraction is set=0.4664538818609959, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4664538818609959
2024-08-18 01:06:42,151:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4210553556985497, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4210553556985497
2024-08-18 01:06:42,235:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2024-08-18 01:06:42,235:INFO:[LightGBM] [Warning] feature_fraction is set=0.4664538818609959, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4664538818609959
2024-08-18 01:06:42,235:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4210553556985497, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4210553556985497
2024-08-18 01:06:42,236:INFO:[LightGBM] [Info] Number of positive: 71812, number of negative: 71208
2024-08-18 01:06:42,239:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000790 seconds.
2024-08-18 01:06:42,239:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-18 01:06:42,239:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-18 01:06:42,239:INFO:[LightGBM] [Info] Total Bins 117
2024-08-18 01:06:42,239:INFO:[LightGBM] [Info] Number of data points in the train set: 143020, number of used features: 38
2024-08-18 01:06:42,241:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502112 -> initscore=0.008446
2024-08-18 01:06:42,241:INFO:[LightGBM] [Info] Start training from score 0.008446
2024-08-18 01:06:42,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:42,528:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2024-08-18 01:06:42,528:INFO:[LightGBM] [Warning] feature_fraction is set=0.4664538818609959, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4664538818609959
2024-08-18 01:06:42,528:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4210553556985497, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4210553556985497
2024-08-18 01:06:42,544:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2024-08-18 01:06:42,544:INFO:[LightGBM] [Warning] feature_fraction is set=0.4664538818609959, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4664538818609959
2024-08-18 01:06:42,544:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4210553556985497, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4210553556985497
2024-08-18 01:06:43,730:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2024-08-18 01:06:43,731:INFO:[LightGBM] [Warning] feature_fraction is set=0.4664538818609959, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4664538818609959
2024-08-18 01:06:43,731:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4210553556985497, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4210553556985497
2024-08-18 01:06:43,812:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2024-08-18 01:06:43,813:INFO:[LightGBM] [Warning] feature_fraction is set=0.4664538818609959, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4664538818609959
2024-08-18 01:06:43,813:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4210553556985497, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4210553556985497
2024-08-18 01:06:43,813:INFO:[LightGBM] [Info] Number of positive: 71812, number of negative: 71208
2024-08-18 01:06:43,817:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000936 seconds.
2024-08-18 01:06:43,817:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-18 01:06:43,817:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-18 01:06:43,818:INFO:[LightGBM] [Info] Total Bins 116
2024-08-18 01:06:43,818:INFO:[LightGBM] [Info] Number of data points in the train set: 143020, number of used features: 38
2024-08-18 01:06:43,820:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502112 -> initscore=0.008446
2024-08-18 01:06:43,820:INFO:[LightGBM] [Info] Start training from score 0.008446
2024-08-18 01:06:43,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:43,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:43,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:43,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:43,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:43,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:43,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:43,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:43,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:43,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:43,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:43,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:43,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:43,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:43,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:43,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:43,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:43,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:43,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:43,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:43,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:43,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:43,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:43,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:43,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:43,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:43,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:43,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:43,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:43,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:43,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:43,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:43,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:43,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:43,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:43,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:43,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:43,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:43,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:43,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:43,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:43,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:43,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:43,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:43,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:43,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:43,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:43,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:43,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:43,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:43,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:44,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:44,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:44,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:44,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:44,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:44,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:44,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:44,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:44,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:44,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:44,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:44,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:44,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:44,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:44,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:44,182:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2024-08-18 01:06:44,182:INFO:[LightGBM] [Warning] feature_fraction is set=0.4664538818609959, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4664538818609959
2024-08-18 01:06:44,182:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4210553556985497, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4210553556985497
2024-08-18 01:06:44,198:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2024-08-18 01:06:44,199:INFO:[LightGBM] [Warning] feature_fraction is set=0.4664538818609959, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4664538818609959
2024-08-18 01:06:44,199:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4210553556985497, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4210553556985497
2024-08-18 01:06:45,383:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2024-08-18 01:06:45,383:INFO:[LightGBM] [Warning] feature_fraction is set=0.4664538818609959, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4664538818609959
2024-08-18 01:06:45,383:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4210553556985497, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4210553556985497
2024-08-18 01:06:45,468:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2024-08-18 01:06:45,468:INFO:[LightGBM] [Warning] feature_fraction is set=0.4664538818609959, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4664538818609959
2024-08-18 01:06:45,468:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4210553556985497, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4210553556985497
2024-08-18 01:06:45,469:INFO:[LightGBM] [Info] Number of positive: 71812, number of negative: 71208
2024-08-18 01:06:45,473:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000991 seconds.
2024-08-18 01:06:45,473:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-18 01:06:45,473:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-18 01:06:45,473:INFO:[LightGBM] [Info] Total Bins 115
2024-08-18 01:06:45,474:INFO:[LightGBM] [Info] Number of data points in the train set: 143020, number of used features: 38
2024-08-18 01:06:45,477:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502112 -> initscore=0.008446
2024-08-18 01:06:45,477:INFO:[LightGBM] [Info] Start training from score 0.008446
2024-08-18 01:06:45,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:45,836:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2024-08-18 01:06:45,836:INFO:[LightGBM] [Warning] feature_fraction is set=0.4664538818609959, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4664538818609959
2024-08-18 01:06:45,836:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4210553556985497, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4210553556985497
2024-08-18 01:06:45,856:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2024-08-18 01:06:45,857:INFO:[LightGBM] [Warning] feature_fraction is set=0.4664538818609959, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4664538818609959
2024-08-18 01:06:45,857:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4210553556985497, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4210553556985497
2024-08-18 01:06:47,077:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2024-08-18 01:06:47,078:INFO:[LightGBM] [Warning] feature_fraction is set=0.4664538818609959, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4664538818609959
2024-08-18 01:06:47,078:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4210553556985497, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4210553556985497
2024-08-18 01:06:47,164:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2024-08-18 01:06:47,164:INFO:[LightGBM] [Warning] feature_fraction is set=0.4664538818609959, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4664538818609959
2024-08-18 01:06:47,164:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4210553556985497, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4210553556985497
2024-08-18 01:06:47,164:INFO:[LightGBM] [Info] Number of positive: 71812, number of negative: 71208
2024-08-18 01:06:47,168:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000954 seconds.
2024-08-18 01:06:47,168:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-18 01:06:47,168:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-18 01:06:47,168:INFO:[LightGBM] [Info] Total Bins 116
2024-08-18 01:06:47,168:INFO:[LightGBM] [Info] Number of data points in the train set: 143020, number of used features: 38
2024-08-18 01:06:47,170:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502112 -> initscore=0.008446
2024-08-18 01:06:47,170:INFO:[LightGBM] [Info] Start training from score 0.008446
2024-08-18 01:06:47,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:47,436:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2024-08-18 01:06:47,436:INFO:[LightGBM] [Warning] feature_fraction is set=0.4664538818609959, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4664538818609959
2024-08-18 01:06:47,436:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4210553556985497, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4210553556985497
2024-08-18 01:06:47,452:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2024-08-18 01:06:47,452:INFO:[LightGBM] [Warning] feature_fraction is set=0.4664538818609959, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4664538818609959
2024-08-18 01:06:47,452:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4210553556985497, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4210553556985497
2024-08-18 01:06:48,644:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2024-08-18 01:06:48,644:INFO:[LightGBM] [Warning] feature_fraction is set=0.4664538818609959, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4664538818609959
2024-08-18 01:06:48,644:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4210553556985497, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4210553556985497
2024-08-18 01:06:48,731:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2024-08-18 01:06:48,731:INFO:[LightGBM] [Warning] feature_fraction is set=0.4664538818609959, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4664538818609959
2024-08-18 01:06:48,731:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4210553556985497, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4210553556985497
2024-08-18 01:06:48,731:INFO:[LightGBM] [Info] Number of positive: 71812, number of negative: 71208
2024-08-18 01:06:48,735:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000869 seconds.
2024-08-18 01:06:48,735:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-18 01:06:48,735:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-18 01:06:48,735:INFO:[LightGBM] [Info] Total Bins 117
2024-08-18 01:06:48,735:INFO:[LightGBM] [Info] Number of data points in the train set: 143020, number of used features: 38
2024-08-18 01:06:48,737:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502112 -> initscore=0.008446
2024-08-18 01:06:48,737:INFO:[LightGBM] [Info] Start training from score 0.008446
2024-08-18 01:06:48,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:48,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:48,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:48,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:48,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:48,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:48,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:48,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:48,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:48,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:48,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:48,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:48,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:48,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:48,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:48,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:48,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:48,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:48,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:48,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:48,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:48,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:48,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:48,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:48,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:48,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:48,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:48,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:48,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:48,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:48,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:48,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:48,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:48,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:48,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:48,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:48,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:48,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:48,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:48,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:48,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:48,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:48,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:48,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:48,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:48,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:48,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:48,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:48,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:48,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:48,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:48,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:48,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:48,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:48,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:48,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:48,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:48,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:48,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:48,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:48,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:48,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:48,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:48,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:48,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:48,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:49,044:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2024-08-18 01:06:49,044:INFO:[LightGBM] [Warning] feature_fraction is set=0.4664538818609959, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4664538818609959
2024-08-18 01:06:49,044:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4210553556985497, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4210553556985497
2024-08-18 01:06:49,070:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2024-08-18 01:06:49,070:INFO:[LightGBM] [Warning] feature_fraction is set=0.4664538818609959, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4664538818609959
2024-08-18 01:06:49,070:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4210553556985497, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4210553556985497
2024-08-18 01:06:50,328:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2024-08-18 01:06:50,328:INFO:[LightGBM] [Warning] feature_fraction is set=0.4664538818609959, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4664538818609959
2024-08-18 01:06:50,328:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4210553556985497, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4210553556985497
2024-08-18 01:06:50,444:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2024-08-18 01:06:50,444:INFO:[LightGBM] [Warning] feature_fraction is set=0.4664538818609959, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4664538818609959
2024-08-18 01:06:50,444:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4210553556985497, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4210553556985497
2024-08-18 01:06:50,445:INFO:[LightGBM] [Info] Number of positive: 71812, number of negative: 71208
2024-08-18 01:06:50,451:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001028 seconds.
2024-08-18 01:06:50,451:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-18 01:06:50,452:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-18 01:06:50,452:INFO:[LightGBM] [Info] Total Bins 115
2024-08-18 01:06:50,452:INFO:[LightGBM] [Info] Number of data points in the train set: 143020, number of used features: 38
2024-08-18 01:06:50,454:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502112 -> initscore=0.008446
2024-08-18 01:06:50,454:INFO:[LightGBM] [Info] Start training from score 0.008446
2024-08-18 01:06:50,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:50,966:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2024-08-18 01:06:50,967:INFO:[LightGBM] [Warning] feature_fraction is set=0.4664538818609959, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4664538818609959
2024-08-18 01:06:50,967:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4210553556985497, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4210553556985497
2024-08-18 01:06:50,991:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2024-08-18 01:06:50,991:INFO:[LightGBM] [Warning] feature_fraction is set=0.4664538818609959, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4664538818609959
2024-08-18 01:06:50,991:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4210553556985497, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4210553556985497
2024-08-18 01:06:52,167:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2024-08-18 01:06:52,167:INFO:[LightGBM] [Warning] feature_fraction is set=0.4664538818609959, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4664538818609959
2024-08-18 01:06:52,167:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4210553556985497, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4210553556985497
2024-08-18 01:06:52,248:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2024-08-18 01:06:52,248:INFO:[LightGBM] [Warning] feature_fraction is set=0.4664538818609959, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4664538818609959
2024-08-18 01:06:52,248:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4210553556985497, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4210553556985497
2024-08-18 01:06:52,248:INFO:[LightGBM] [Info] Number of positive: 71812, number of negative: 71208
2024-08-18 01:06:52,252:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000790 seconds.
2024-08-18 01:06:52,252:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-18 01:06:52,252:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-18 01:06:52,252:INFO:[LightGBM] [Info] Total Bins 117
2024-08-18 01:06:52,252:INFO:[LightGBM] [Info] Number of data points in the train set: 143020, number of used features: 38
2024-08-18 01:06:52,254:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502112 -> initscore=0.008446
2024-08-18 01:06:52,254:INFO:[LightGBM] [Info] Start training from score 0.008446
2024-08-18 01:06:52,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:52,502:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2024-08-18 01:06:52,503:INFO:[LightGBM] [Warning] feature_fraction is set=0.4664538818609959, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4664538818609959
2024-08-18 01:06:52,503:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4210553556985497, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4210553556985497
2024-08-18 01:06:52,516:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2024-08-18 01:06:52,516:INFO:[LightGBM] [Warning] feature_fraction is set=0.4664538818609959, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4664538818609959
2024-08-18 01:06:52,516:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4210553556985497, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4210553556985497
2024-08-18 01:06:53,611:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2024-08-18 01:06:53,611:INFO:[LightGBM] [Warning] feature_fraction is set=0.4664538818609959, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4664538818609959
2024-08-18 01:06:53,611:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4210553556985497, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4210553556985497
2024-08-18 01:06:53,685:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2024-08-18 01:06:53,686:INFO:[LightGBM] [Warning] feature_fraction is set=0.4664538818609959, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4664538818609959
2024-08-18 01:06:53,686:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4210553556985497, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4210553556985497
2024-08-18 01:06:53,686:INFO:[LightGBM] [Info] Number of positive: 71812, number of negative: 71208
2024-08-18 01:06:53,689:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000743 seconds.
2024-08-18 01:06:53,689:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-18 01:06:53,689:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-18 01:06:53,690:INFO:[LightGBM] [Info] Total Bins 115
2024-08-18 01:06:53,690:INFO:[LightGBM] [Info] Number of data points in the train set: 143020, number of used features: 38
2024-08-18 01:06:53,691:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502112 -> initscore=0.008446
2024-08-18 01:06:53,692:INFO:[LightGBM] [Info] Start training from score 0.008446
2024-08-18 01:06:53,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:53,947:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2024-08-18 01:06:53,947:INFO:[LightGBM] [Warning] feature_fraction is set=0.4664538818609959, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4664538818609959
2024-08-18 01:06:53,947:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4210553556985497, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4210553556985497
2024-08-18 01:06:53,962:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2024-08-18 01:06:53,962:INFO:[LightGBM] [Warning] feature_fraction is set=0.4664538818609959, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4664538818609959
2024-08-18 01:06:53,962:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4210553556985497, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4210553556985497
2024-08-18 01:06:54,019:INFO:Calculating mean and std
2024-08-18 01:06:54,021:INFO:Creating metrics dataframe
2024-08-18 01:06:54,028:INFO:Finalizing model
2024-08-18 01:06:55,165:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2024-08-18 01:06:55,165:INFO:[LightGBM] [Warning] feature_fraction is set=0.4664538818609959, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4664538818609959
2024-08-18 01:06:55,165:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4210553556985497, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4210553556985497
2024-08-18 01:06:55,251:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2024-08-18 01:06:55,251:INFO:[LightGBM] [Warning] feature_fraction is set=0.4664538818609959, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4664538818609959
2024-08-18 01:06:55,251:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4210553556985497, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4210553556985497
2024-08-18 01:06:55,252:INFO:[LightGBM] [Info] Number of positive: 79791, number of negative: 79120
2024-08-18 01:06:55,256:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000988 seconds.
2024-08-18 01:06:55,256:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-18 01:06:55,256:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-18 01:06:55,256:INFO:[LightGBM] [Info] Total Bins 117
2024-08-18 01:06:55,256:INFO:[LightGBM] [Info] Number of data points in the train set: 158911, number of used features: 38
2024-08-18 01:06:55,258:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502111 -> initscore=0.008445
2024-08-18 01:06:55,258:INFO:[LightGBM] [Info] Start training from score 0.008445
2024-08-18 01:06:55,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-18 01:06:55,429:INFO:Uploading results into container
2024-08-18 01:06:55,430:INFO:Uploading model into container now
2024-08-18 01:06:55,431:INFO:_master_model_container: 10
2024-08-18 01:06:55,431:INFO:_display_container: 4
2024-08-18 01:06:55,432:INFO:LGBMClassifier(bagging_fraction=0.4210553556985497, bagging_freq=7,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.4664538818609959, importance_type='split',
               learning_rate=3.798279158743105e-05, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001,
               min_split_gain=0.8063740623524571, n_estimators=66, n_jobs=-1,
               num_leaves=242, objective=None, random_state=3263,
               reg_alpha=0.4114597473175342, reg_lambda=3.922346098322018e-10,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-08-18 01:06:55,432:INFO:create_model() successfully completed......................................
2024-08-18 01:06:55,567:INFO:SubProcess create_model() end ==================================
2024-08-18 01:06:55,567:INFO:choose_better activated
2024-08-18 01:06:55,572:INFO:SubProcess create_model() called ==================================
2024-08-18 01:06:55,572:INFO:Initializing create_model()
2024-08-18 01:06:55,573:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd67a7ee290>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3263, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-18 01:06:55,573:INFO:Checking exceptions
2024-08-18 01:06:55,575:INFO:Importing libraries
2024-08-18 01:06:55,575:INFO:Copying training dataset
2024-08-18 01:06:55,629:INFO:Defining folds
2024-08-18 01:06:55,629:INFO:Declaring metric variables
2024-08-18 01:06:55,630:INFO:Importing untrained model
2024-08-18 01:06:55,630:INFO:Declaring custom model
2024-08-18 01:06:55,630:INFO:Light Gradient Boosting Machine Imported successfully
2024-08-18 01:06:55,631:INFO:Starting cross validation
2024-08-18 01:06:55,632:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-08-18 01:06:56,696:INFO:[LightGBM] [Info] Number of positive: 71811, number of negative: 71208
2024-08-18 01:06:56,699:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000968 seconds.
2024-08-18 01:06:56,700:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-18 01:06:56,700:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-18 01:06:56,700:INFO:[LightGBM] [Info] Total Bins 115
2024-08-18 01:06:56,700:INFO:[LightGBM] [Info] Number of data points in the train set: 143019, number of used features: 38
2024-08-18 01:06:56,701:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502108 -> initscore=0.008432
2024-08-18 01:06:56,701:INFO:[LightGBM] [Info] Start training from score 0.008432
2024-08-18 01:06:58,168:INFO:[LightGBM] [Info] Number of positive: 71812, number of negative: 71208
2024-08-18 01:06:58,173:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001106 seconds.
2024-08-18 01:06:58,173:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-18 01:06:58,173:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-18 01:06:58,173:INFO:[LightGBM] [Info] Total Bins 115
2024-08-18 01:06:58,173:INFO:[LightGBM] [Info] Number of data points in the train set: 143020, number of used features: 38
2024-08-18 01:06:58,175:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502112 -> initscore=0.008446
2024-08-18 01:06:58,175:INFO:[LightGBM] [Info] Start training from score 0.008446
2024-08-18 01:07:00,527:INFO:[LightGBM] [Info] Number of positive: 71812, number of negative: 71208
2024-08-18 01:07:00,532:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001291 seconds.
2024-08-18 01:07:00,533:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-18 01:07:00,533:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-18 01:07:00,533:INFO:[LightGBM] [Info] Total Bins 117
2024-08-18 01:07:00,533:INFO:[LightGBM] [Info] Number of data points in the train set: 143020, number of used features: 38
2024-08-18 01:07:00,534:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502112 -> initscore=0.008446
2024-08-18 01:07:00,534:INFO:[LightGBM] [Info] Start training from score 0.008446
2024-08-18 01:07:02,544:INFO:[LightGBM] [Info] Number of positive: 71812, number of negative: 71208
2024-08-18 01:07:02,548:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000915 seconds.
2024-08-18 01:07:02,548:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-18 01:07:02,548:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-18 01:07:02,548:INFO:[LightGBM] [Info] Total Bins 116
2024-08-18 01:07:02,548:INFO:[LightGBM] [Info] Number of data points in the train set: 143020, number of used features: 38
2024-08-18 01:07:02,549:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502112 -> initscore=0.008446
2024-08-18 01:07:02,549:INFO:[LightGBM] [Info] Start training from score 0.008446
2024-08-18 01:07:04,353:INFO:[LightGBM] [Info] Number of positive: 71812, number of negative: 71208
2024-08-18 01:07:04,357:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001042 seconds.
2024-08-18 01:07:04,357:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-18 01:07:04,357:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-18 01:07:04,357:INFO:[LightGBM] [Info] Total Bins 115
2024-08-18 01:07:04,358:INFO:[LightGBM] [Info] Number of data points in the train set: 143020, number of used features: 38
2024-08-18 01:07:04,359:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502112 -> initscore=0.008446
2024-08-18 01:07:04,359:INFO:[LightGBM] [Info] Start training from score 0.008446
2024-08-18 01:07:06,017:INFO:[LightGBM] [Info] Number of positive: 71812, number of negative: 71208
2024-08-18 01:07:06,021:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000931 seconds.
2024-08-18 01:07:06,021:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-18 01:07:06,021:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-18 01:07:06,021:INFO:[LightGBM] [Info] Total Bins 116
2024-08-18 01:07:06,021:INFO:[LightGBM] [Info] Number of data points in the train set: 143020, number of used features: 38
2024-08-18 01:07:06,022:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502112 -> initscore=0.008446
2024-08-18 01:07:06,022:INFO:[LightGBM] [Info] Start training from score 0.008446
2024-08-18 01:07:07,589:INFO:[LightGBM] [Info] Number of positive: 71812, number of negative: 71208
2024-08-18 01:07:07,593:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001304 seconds.
2024-08-18 01:07:07,593:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-18 01:07:07,593:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-18 01:07:07,593:INFO:[LightGBM] [Info] Total Bins 117
2024-08-18 01:07:07,593:INFO:[LightGBM] [Info] Number of data points in the train set: 143020, number of used features: 38
2024-08-18 01:07:07,594:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502112 -> initscore=0.008446
2024-08-18 01:07:07,595:INFO:[LightGBM] [Info] Start training from score 0.008446
2024-08-18 01:07:09,145:INFO:[LightGBM] [Info] Number of positive: 71812, number of negative: 71208
2024-08-18 01:07:09,149:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000969 seconds.
2024-08-18 01:07:09,149:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-18 01:07:09,149:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-18 01:07:09,149:INFO:[LightGBM] [Info] Total Bins 115
2024-08-18 01:07:09,149:INFO:[LightGBM] [Info] Number of data points in the train set: 143020, number of used features: 38
2024-08-18 01:07:09,150:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502112 -> initscore=0.008446
2024-08-18 01:07:09,150:INFO:[LightGBM] [Info] Start training from score 0.008446
2024-08-18 01:07:10,696:INFO:[LightGBM] [Info] Number of positive: 71812, number of negative: 71208
2024-08-18 01:07:10,701:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001234 seconds.
2024-08-18 01:07:10,701:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-18 01:07:10,701:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-18 01:07:10,701:INFO:[LightGBM] [Info] Total Bins 117
2024-08-18 01:07:10,701:INFO:[LightGBM] [Info] Number of data points in the train set: 143020, number of used features: 38
2024-08-18 01:07:10,702:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502112 -> initscore=0.008446
2024-08-18 01:07:10,702:INFO:[LightGBM] [Info] Start training from score 0.008446
2024-08-18 01:07:12,256:INFO:[LightGBM] [Info] Number of positive: 71812, number of negative: 71208
2024-08-18 01:07:12,260:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001160 seconds.
2024-08-18 01:07:12,260:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-18 01:07:12,260:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-18 01:07:12,260:INFO:[LightGBM] [Info] Total Bins 115
2024-08-18 01:07:12,263:INFO:[LightGBM] [Info] Number of data points in the train set: 143020, number of used features: 38
2024-08-18 01:07:12,265:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502112 -> initscore=0.008446
2024-08-18 01:07:12,265:INFO:[LightGBM] [Info] Start training from score 0.008446
2024-08-18 01:07:12,850:INFO:Calculating mean and std
2024-08-18 01:07:12,851:INFO:Creating metrics dataframe
2024-08-18 01:07:12,853:INFO:Finalizing model
2024-08-18 01:07:14,170:INFO:[LightGBM] [Info] Number of positive: 79791, number of negative: 79120
2024-08-18 01:07:14,176:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001391 seconds.
2024-08-18 01:07:14,176:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-18 01:07:14,176:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-18 01:07:14,176:INFO:[LightGBM] [Info] Total Bins 117
2024-08-18 01:07:14,176:INFO:[LightGBM] [Info] Number of data points in the train set: 158911, number of used features: 38
2024-08-18 01:07:14,177:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502111 -> initscore=0.008445
2024-08-18 01:07:14,178:INFO:[LightGBM] [Info] Start training from score 0.008445
2024-08-18 01:07:14,561:INFO:Uploading results into container
2024-08-18 01:07:14,561:INFO:Uploading model into container now
2024-08-18 01:07:14,562:INFO:_master_model_container: 11
2024-08-18 01:07:14,562:INFO:_display_container: 5
2024-08-18 01:07:14,563:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3263, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-08-18 01:07:14,563:INFO:create_model() successfully completed......................................
2024-08-18 01:07:14,704:INFO:SubProcess create_model() end ==================================
2024-08-18 01:07:14,705:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3263, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.5
2024-08-18 01:07:14,706:INFO:LGBMClassifier(bagging_fraction=0.4210553556985497, bagging_freq=7,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.4664538818609959, importance_type='split',
               learning_rate=3.798279158743105e-05, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001,
               min_split_gain=0.8063740623524571, n_estimators=66, n_jobs=-1,
               num_leaves=242, objective=None, random_state=3263,
               reg_alpha=0.4114597473175342, reg_lambda=3.922346098322018e-10,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.5018
2024-08-18 01:07:14,706:INFO:LGBMClassifier(bagging_fraction=0.4210553556985497, bagging_freq=7,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.4664538818609959, importance_type='split',
               learning_rate=3.798279158743105e-05, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001,
               min_split_gain=0.8063740623524571, n_estimators=66, n_jobs=-1,
               num_leaves=242, objective=None, random_state=3263,
               reg_alpha=0.4114597473175342, reg_lambda=3.922346098322018e-10,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2024-08-18 01:07:14,706:INFO:choose_better completed
2024-08-18 01:07:14,707:INFO:Creating Dashboard logs
2024-08-18 01:07:14,712:INFO:Model: Light Gradient Boosting Machine
2024-08-18 01:07:14,755:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 3.798279158743105e-05, 'max_depth': -1, 'min_child_samples': 76, 'min_child_weight': 0.001, 'min_split_gain': 0.8063740623524571, 'n_estimators': 66, 'n_jobs': -1, 'num_leaves': 242, 'objective': None, 'random_state': 3263, 'reg_alpha': 0.4114597473175342, 'reg_lambda': 3.922346098322018e-10, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.4664538818609959, 'bagging_fraction': 0.4210553556985497, 'bagging_freq': 7}
2024-08-18 01:07:14,977:INFO:Initializing predict_model()
2024-08-18 01:07:14,977:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd67a7ee290>, estimator=LGBMClassifier(bagging_fraction=0.4210553556985497, bagging_freq=7,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.4664538818609959, importance_type='split',
               learning_rate=3.798279158743105e-05, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001,
               min_split_gain=0.8063740623524571, n_estimators=66, n_jobs=-1,
               num_leaves=242, objective=None, random_state=3263,
               reg_alpha=0.4114597473175342, reg_lambda=3.922346098322018e-10,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fd67acc6320>)
2024-08-18 01:07:14,977:INFO:Checking exceptions
2024-08-18 01:07:14,977:INFO:Preloading libraries
2024-08-18 01:07:15,666:INFO:SubProcess plot_model() called ==================================
2024-08-18 01:07:15,667:INFO:Initializing plot_model()
2024-08-18 01:07:15,667:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.4210553556985497, bagging_freq=7,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.4664538818609959, importance_type='split',
               learning_rate=3.798279158743105e-05, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001,
               min_split_gain=0.8063740623524571, n_estimators=66, n_jobs=-1,
               num_leaves=242, objective=None, random_state=3263,
               reg_alpha=0.4114597473175342, reg_lambda=3.922346098322018e-10,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmp7089rkgu, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd67a7ee290>, system=False)
2024-08-18 01:07:15,667:INFO:Checking exceptions
2024-08-18 01:07:15,691:INFO:Preloading libraries
2024-08-18 01:07:15,693:INFO:Copying training dataset
2024-08-18 01:07:15,695:INFO:Plot type: auc
2024-08-18 01:07:16,162:INFO:Fitting Model
2024-08-18 01:07:16,170:INFO:Scoring test/hold-out set
2024-08-18 01:07:16,199:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2024-08-18 01:07:16,199:INFO:[LightGBM] [Warning] feature_fraction is set=0.4664538818609959, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4664538818609959
2024-08-18 01:07:16,199:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4210553556985497, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4210553556985497
2024-08-18 01:07:16,274:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2024-08-18 01:07:16,274:INFO:[LightGBM] [Warning] feature_fraction is set=0.4664538818609959, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4664538818609959
2024-08-18 01:07:16,274:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4210553556985497, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4210553556985497
2024-08-18 01:07:16,412:INFO:Saving '/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmp7089rkgu/AUC.png'
2024-08-18 01:07:16,699:INFO:Visual Rendered Successfully
2024-08-18 01:07:16,842:INFO:plot_model() successfully completed......................................
2024-08-18 01:07:16,856:INFO:Initializing plot_model()
2024-08-18 01:07:16,856:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.4210553556985497, bagging_freq=7,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.4664538818609959, importance_type='split',
               learning_rate=3.798279158743105e-05, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001,
               min_split_gain=0.8063740623524571, n_estimators=66, n_jobs=-1,
               num_leaves=242, objective=None, random_state=3263,
               reg_alpha=0.4114597473175342, reg_lambda=3.922346098322018e-10,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmp7089rkgu, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd67a7ee290>, system=False)
2024-08-18 01:07:16,856:INFO:Checking exceptions
2024-08-18 01:07:16,881:INFO:Preloading libraries
2024-08-18 01:07:16,883:INFO:Copying training dataset
2024-08-18 01:07:16,884:INFO:Plot type: confusion_matrix
2024-08-18 01:07:17,348:INFO:Fitting Model
2024-08-18 01:07:17,352:INFO:Scoring test/hold-out set
2024-08-18 01:07:17,379:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2024-08-18 01:07:17,379:INFO:[LightGBM] [Warning] feature_fraction is set=0.4664538818609959, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4664538818609959
2024-08-18 01:07:17,379:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4210553556985497, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4210553556985497
2024-08-18 01:07:17,442:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2024-08-18 01:07:17,442:INFO:[LightGBM] [Warning] feature_fraction is set=0.4664538818609959, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4664538818609959
2024-08-18 01:07:17,442:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4210553556985497, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4210553556985497
2024-08-18 01:07:17,519:INFO:Saving '/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmp7089rkgu/Confusion Matrix.png'
2024-08-18 01:07:17,683:INFO:Visual Rendered Successfully
2024-08-18 01:07:17,822:INFO:plot_model() successfully completed......................................
2024-08-18 01:07:17,829:INFO:Initializing plot_model()
2024-08-18 01:07:17,829:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.4210553556985497, bagging_freq=7,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.4664538818609959, importance_type='split',
               learning_rate=3.798279158743105e-05, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001,
               min_split_gain=0.8063740623524571, n_estimators=66, n_jobs=-1,
               num_leaves=242, objective=None, random_state=3263,
               reg_alpha=0.4114597473175342, reg_lambda=3.922346098322018e-10,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmp7089rkgu, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd67a7ee290>, system=False)
2024-08-18 01:07:17,829:INFO:Checking exceptions
2024-08-18 01:07:17,855:INFO:Preloading libraries
2024-08-18 01:07:17,857:INFO:Copying training dataset
2024-08-18 01:07:17,858:INFO:Plot type: feature
2024-08-18 01:07:17,859:WARNING:No coef_ found. Trying feature_importances_
2024-08-18 01:07:18,057:INFO:Saving '/var/folders/_9/glj65w5s5hqcn07cxtv0gzj40000gn/T/tmp7089rkgu/Feature Importance.png'
2024-08-18 01:07:18,280:INFO:Visual Rendered Successfully
2024-08-18 01:07:18,409:INFO:plot_model() successfully completed......................................
2024-08-18 01:07:18,411:INFO:SubProcess plot_model() end ==================================
2024-08-18 01:07:18,712:INFO:_master_model_container: 11
2024-08-18 01:07:18,712:INFO:_display_container: 4
2024-08-18 01:07:18,713:INFO:LGBMClassifier(bagging_fraction=0.4210553556985497, bagging_freq=7,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.4664538818609959, importance_type='split',
               learning_rate=3.798279158743105e-05, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001,
               min_split_gain=0.8063740623524571, n_estimators=66, n_jobs=-1,
               num_leaves=242, objective=None, random_state=3263,
               reg_alpha=0.4114597473175342, reg_lambda=3.922346098322018e-10,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-08-18 01:07:18,713:INFO:tune_model() successfully completed......................................
